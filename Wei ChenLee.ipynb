{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score, recall_score, precision_score\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Embedding\n",
    "import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "stopword = {\"URL\"}|set(stopwords.words(\"english\"))|set(stopwords.words(\"spanish\"))|set(stopwords.words(\"portuguese\"))|set(stopwords.words(\"french\"))|set(stopwords.words(\"german\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, all of linear, tree based, and NN models would be used to evaluate the text to classfy whether the text is complaint or not. Here, we'll set 1 as noncomplaint and 0 as complaint. The main target for us is to identify more noncomplaint texts without too many false positive in our final dataset. As some of models do not perform well in our data, they wil be removed from this report to limit the page size. Here, logistic regression, SVM, Decision Tree, Random Forest, Boosting, Bagging, DNN, RNN, LSTM models were mainly used in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    s=[x.strip().lower() for x in s]\n",
    "    #s=[re.sub(\"http[^\\s]+|www\\[^\\s]+\",\"url\",x) for x in s]\n",
    "    s=[re.sub('[^a-z]',' ',x) for x in s]\n",
    "    return(s)\n",
    "def doc2vec(text,wordlist):\n",
    "    worddic=dict(zip(wordlist,range(len(wordlist))))\n",
    "    cleaned = np.zeros((len(text),len(wordlist)))\n",
    "    i=0\n",
    "    for i in range(len(text)):\n",
    "        for word in text[i].split():\n",
    "            if word in wordlist:\n",
    "                cleaned[i,worddic[word]]+=1\n",
    "    return(cleaned)\n",
    "\n",
    "def create_model(layer=1,layer_activation=\"relu\",dense=16,optimizer='rmsprop'):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(dense,activation=layer_activation, input_shape=(5260,)))\n",
    "    if layer>1:\n",
    "        for i in range(layer-1):\n",
    "            model.add(layers.Dense(dense, activation=layer_activation))\n",
    "    model.add(layers.Dense(2,activation='sigmoid'))\n",
    "    model.compile( optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"complaint.txt\",encoding=\"latin1\")\n",
    "negative = f.readlines()\n",
    "f.close()\n",
    "f = open(\"nocomplaint.txt\",encoding=\"latin1\")\n",
    "positive = f.readlines()\n",
    "f.close()\n",
    "a = pd.DataFrame(zip(list(positive)),np.ones(1000))\n",
    "b = pd.DataFrame(zip(list(negative)),np.zeros(1000))\n",
    "df = pd.concat([a,b])\n",
    "df[\"sentiment\"] = df.index.values\n",
    "df.columns = [\"text\",\"sentiment\"]\n",
    "data =df.reset_index(drop= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, the RNN model wound be used. The Simple RNN, LSTM and Bidirectional models had been tried. Only the last two model performed aacceptable result. However, the val accuracy is only around 65%. This may because the lack of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "max_len = 30\n",
    "words =  clean(data[\"text\"].tolist())\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(words)\n",
    "sequences = tokenizer.texts_to_sequences(words)\n",
    "train = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train, data[\"sentiment\"], test_size=0.2, random_state=23)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= to_categorical(y_train, 2)\n",
    "y_test = to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "50/50 [==============================] - 3s 28ms/step - loss: 0.7194 - accuracy: 0.5071 - val_loss: 0.7101 - val_accuracy: 0.4650\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.46500, saving model to best_model1.hdf5\n",
      "Epoch 2/70\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.6934 - accuracy: 0.5252 - val_loss: 0.7001 - val_accuracy: 0.4650\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.46500\n",
      "Epoch 3/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6935 - accuracy: 0.5107 - val_loss: 0.6922 - val_accuracy: 0.4650\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.46500\n",
      "Epoch 4/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6841 - accuracy: 0.5062 - val_loss: 0.6797 - val_accuracy: 0.4650\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.46500\n",
      "Epoch 5/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6687 - accuracy: 0.6055 - val_loss: 0.6841 - val_accuracy: 0.5525\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.46500 to 0.55250, saving model to best_model1.hdf5\n",
      "Epoch 6/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6563 - accuracy: 0.7587 - val_loss: 0.6737 - val_accuracy: 0.6125\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.55250 to 0.61250, saving model to best_model1.hdf5\n",
      "Epoch 7/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6382 - accuracy: 0.7942 - val_loss: 0.6468 - val_accuracy: 0.7275\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.61250 to 0.72750, saving model to best_model1.hdf5\n",
      "Epoch 8/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.6202 - accuracy: 0.8207 - val_loss: 0.6529 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.72750\n",
      "Epoch 9/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5948 - accuracy: 0.8520 - val_loss: 0.6276 - val_accuracy: 0.7225\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.72750\n",
      "Epoch 10/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5714 - accuracy: 0.8560 - val_loss: 0.6266 - val_accuracy: 0.6925\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.72750\n",
      "Epoch 11/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.8948 - val_loss: 0.6112 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.72750\n",
      "Epoch 12/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.5049 - accuracy: 0.8965 - val_loss: 0.6059 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.72750\n",
      "Epoch 13/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.9149 - val_loss: 0.5871 - val_accuracy: 0.7200\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.72750\n",
      "Epoch 14/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.4354 - accuracy: 0.9118 - val_loss: 0.5665 - val_accuracy: 0.7400\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.72750 to 0.74000, saving model to best_model1.hdf5\n",
      "Epoch 15/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3834 - accuracy: 0.9444 - val_loss: 0.5825 - val_accuracy: 0.7100\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74000\n",
      "Epoch 16/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3638 - accuracy: 0.9364 - val_loss: 0.5669 - val_accuracy: 0.7275\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74000\n",
      "Epoch 17/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3317 - accuracy: 0.9435 - val_loss: 0.5696 - val_accuracy: 0.7275\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74000\n",
      "Epoch 18/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.3107 - accuracy: 0.9384 - val_loss: 0.5969 - val_accuracy: 0.7125\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74000\n",
      "Epoch 19/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.2864 - accuracy: 0.9492 - val_loss: 0.5710 - val_accuracy: 0.7275\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74000\n",
      "Epoch 20/70\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.2539 - accuracy: 0.9578 - val_loss: 0.6144 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74000\n",
      "Epoch 21/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.2396 - accuracy: 0.9591 - val_loss: 0.6314 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74000\n",
      "Epoch 22/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.2279 - accuracy: 0.9582 - val_loss: 0.6192 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74000\n",
      "Epoch 23/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.1987 - accuracy: 0.9670 - val_loss: 0.6486 - val_accuracy: 0.7025\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74000\n",
      "Epoch 24/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.1888 - accuracy: 0.9657 - val_loss: 0.6475 - val_accuracy: 0.7225\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74000\n",
      "Epoch 25/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.1735 - accuracy: 0.9676 - val_loss: 0.6893 - val_accuracy: 0.7025\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74000\n",
      "Epoch 26/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.1490 - accuracy: 0.9755 - val_loss: 0.6967 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74000\n",
      "Epoch 27/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.1489 - accuracy: 0.9720 - val_loss: 0.6947 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74000\n",
      "Epoch 28/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.1447 - accuracy: 0.9734 - val_loss: 0.7785 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74000\n",
      "Epoch 29/70\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.1291 - accuracy: 0.9739 - val_loss: 0.8284 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74000\n",
      "Epoch 30/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.1076 - accuracy: 0.9843 - val_loss: 0.7846 - val_accuracy: 0.7025\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74000\n",
      "Epoch 31/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.1012 - accuracy: 0.9829 - val_loss: 0.8340 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74000\n",
      "Epoch 32/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.1078 - accuracy: 0.9804 - val_loss: 0.8661 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74000\n",
      "Epoch 33/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0971 - accuracy: 0.9832 - val_loss: 0.8187 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74000\n",
      "Epoch 34/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0924 - accuracy: 0.9824 - val_loss: 0.8400 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74000\n",
      "Epoch 35/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0836 - accuracy: 0.9845 - val_loss: 0.8601 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74000\n",
      "Epoch 36/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0658 - accuracy: 0.9909 - val_loss: 0.8997 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74000\n",
      "Epoch 37/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0690 - accuracy: 0.9885 - val_loss: 0.9683 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74000\n",
      "Epoch 38/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0703 - accuracy: 0.9877 - val_loss: 0.9609 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74000\n",
      "Epoch 39/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0605 - accuracy: 0.9899 - val_loss: 0.9695 - val_accuracy: 0.6825\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74000\n",
      "Epoch 40/70\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0541 - accuracy: 0.9930 - val_loss: 1.0886 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74000\n",
      "Epoch 41/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0561 - accuracy: 0.9884 - val_loss: 1.0667 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74000\n",
      "Epoch 42/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0539 - accuracy: 0.9876 - val_loss: 1.0577 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74000\n",
      "Epoch 43/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0644 - accuracy: 0.9880 - val_loss: 1.1792 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74000\n",
      "Epoch 44/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0456 - accuracy: 0.9928 - val_loss: 1.0691 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74000\n",
      "Epoch 45/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0431 - accuracy: 0.9933 - val_loss: 1.1038 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74000\n",
      "Epoch 46/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0385 - accuracy: 0.9951 - val_loss: 1.1557 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74000\n",
      "Epoch 47/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9949 - val_loss: 1.1745 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74000\n",
      "Epoch 48/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0360 - accuracy: 0.9948 - val_loss: 1.2065 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74000\n",
      "Epoch 49/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0568 - accuracy: 0.9869 - val_loss: 1.2430 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74000\n",
      "Epoch 50/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0428 - accuracy: 0.9916 - val_loss: 1.2629 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74000\n",
      "Epoch 51/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0339 - accuracy: 0.9949 - val_loss: 1.2988 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.74000\n",
      "Epoch 52/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0419 - accuracy: 0.9908 - val_loss: 1.3173 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.74000\n",
      "Epoch 53/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 0.9956 - val_loss: 1.2973 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.74000\n",
      "Epoch 54/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0490 - accuracy: 0.9901 - val_loss: 1.3346 - val_accuracy: 0.6625\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.74000\n",
      "Epoch 55/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0234 - accuracy: 0.9964 - val_loss: 1.3415 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.74000\n",
      "Epoch 56/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0233 - accuracy: 0.9966 - val_loss: 1.3774 - val_accuracy: 0.6525\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.74000\n",
      "Epoch 57/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0232 - accuracy: 0.9971 - val_loss: 1.3685 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.74000\n",
      "Epoch 58/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0333 - accuracy: 0.9946 - val_loss: 1.4336 - val_accuracy: 0.6525\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.74000\n",
      "Epoch 59/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0304 - accuracy: 0.9956 - val_loss: 1.4256 - val_accuracy: 0.6625\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.74000\n",
      "Epoch 60/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0154 - accuracy: 0.9983 - val_loss: 1.4569 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.74000\n",
      "Epoch 61/70\n",
      "50/50 [==============================] - 0s 7ms/step - loss: 0.0192 - accuracy: 0.9973 - val_loss: 1.5018 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.74000\n",
      "Epoch 62/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0157 - accuracy: 0.9984 - val_loss: 1.4937 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.74000\n",
      "Epoch 63/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 0.9977 - val_loss: 1.4746 - val_accuracy: 0.6625\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.74000\n",
      "Epoch 64/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0195 - accuracy: 0.9972 - val_loss: 1.5236 - val_accuracy: 0.6550\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.74000\n",
      "Epoch 65/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0206 - accuracy: 0.9969 - val_loss: 1.5126 - val_accuracy: 0.6625\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.74000\n",
      "Epoch 66/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0191 - accuracy: 0.9972 - val_loss: 1.5353 - val_accuracy: 0.6625\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.74000\n",
      "Epoch 67/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0151 - accuracy: 0.9978 - val_loss: 1.5939 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.74000\n",
      "Epoch 68/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 0.9961 - val_loss: 1.5774 - val_accuracy: 0.6475\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.74000\n",
      "Epoch 69/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 0.9976 - val_loss: 1.5627 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.74000\n",
      "Epoch 70/70\n",
      "50/50 [==============================] - 0s 6ms/step - loss: 0.0233 - accuracy: 0.9963 - val_loss: 1.6132 - val_accuracy: 0.6550\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.74000\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(layers.Embedding(max_words, 25)) #The embedding layer\n",
    "model1.add(layers.LSTM(20,dropout=0.5)) #Our LSTM layer\n",
    "model1.add(layers.Dense(10,activation='softmax'))\n",
    "model1.add(layers.Dense(5,activation='softmax'))\n",
    "model1.add(layers.Dense(2,activation='softmax'))\n",
    "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model1.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.655"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.around(model1.predict(X_test),decimals=0).argmax(axis=1)\n",
    "accuracy_score(x,y_test.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "50/50 [==============================] - 4s 25ms/step - loss: 0.6893 - accuracy: 0.5470 - val_loss: 0.6657 - val_accuracy: 0.6275\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62750, saving model to best_model2.hdf5\n",
      "Epoch 2/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.6205 - accuracy: 0.6821 - val_loss: 0.5451 - val_accuracy: 0.7325\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.62750 to 0.73250, saving model to best_model2.hdf5\n",
      "Epoch 3/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.4435 - accuracy: 0.7890 - val_loss: 0.5474 - val_accuracy: 0.7475\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.73250 to 0.74750, saving model to best_model2.hdf5\n",
      "Epoch 4/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.3512 - accuracy: 0.8542 - val_loss: 0.5499 - val_accuracy: 0.7425\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74750\n",
      "Epoch 5/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2845 - accuracy: 0.8825 - val_loss: 0.6056 - val_accuracy: 0.7125\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74750\n",
      "Epoch 6/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.2253 - accuracy: 0.9116 - val_loss: 0.6495 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74750\n",
      "Epoch 7/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.1852 - accuracy: 0.9357 - val_loss: 0.7352 - val_accuracy: 0.7100\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74750\n",
      "Epoch 8/70\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.1543 - accuracy: 0.9477 - val_loss: 0.7496 - val_accuracy: 0.6875\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74750\n",
      "Epoch 9/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.1343 - accuracy: 0.9470 - val_loss: 0.8042 - val_accuracy: 0.7175\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74750\n",
      "Epoch 10/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.1048 - accuracy: 0.9619 - val_loss: 0.9259 - val_accuracy: 0.6950\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74750\n",
      "Epoch 11/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0987 - accuracy: 0.9676 - val_loss: 0.9673 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74750\n",
      "Epoch 12/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0697 - accuracy: 0.9781 - val_loss: 0.9893 - val_accuracy: 0.7050\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74750\n",
      "Epoch 13/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0583 - accuracy: 0.9784 - val_loss: 1.1054 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74750\n",
      "Epoch 14/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0552 - accuracy: 0.9811 - val_loss: 1.1964 - val_accuracy: 0.7075\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74750\n",
      "Epoch 15/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0656 - accuracy: 0.9781 - val_loss: 1.1558 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74750\n",
      "Epoch 16/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0377 - accuracy: 0.9873 - val_loss: 1.1474 - val_accuracy: 0.6950\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74750\n",
      "Epoch 17/70\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0394 - accuracy: 0.9894 - val_loss: 1.1797 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74750\n",
      "Epoch 18/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0300 - accuracy: 0.9929 - val_loss: 1.2801 - val_accuracy: 0.6875\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74750\n",
      "Epoch 19/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0229 - accuracy: 0.9933 - val_loss: 1.3399 - val_accuracy: 0.6925\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74750\n",
      "Epoch 20/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0259 - accuracy: 0.9904 - val_loss: 1.4248 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74750\n",
      "Epoch 21/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0310 - accuracy: 0.9880 - val_loss: 1.3608 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74750\n",
      "Epoch 22/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0280 - accuracy: 0.9928 - val_loss: 1.6014 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74750\n",
      "Epoch 23/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0186 - accuracy: 0.9960 - val_loss: 1.7117 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74750\n",
      "Epoch 24/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0236 - accuracy: 0.9949 - val_loss: 1.5526 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74750\n",
      "Epoch 25/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0276 - accuracy: 0.9887 - val_loss: 1.6999 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74750\n",
      "Epoch 26/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 1.6978 - val_accuracy: 0.6625\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74750\n",
      "Epoch 27/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0141 - accuracy: 0.9966 - val_loss: 1.7814 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74750\n",
      "Epoch 28/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0247 - accuracy: 0.9925 - val_loss: 1.6534 - val_accuracy: 0.6475\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74750\n",
      "Epoch 29/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 1.7321 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74750\n",
      "Epoch 30/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0116 - accuracy: 0.9970 - val_loss: 1.7675 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74750\n",
      "Epoch 31/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0093 - accuracy: 0.9966 - val_loss: 1.8708 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74750\n",
      "Epoch 32/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0054 - accuracy: 0.9975 - val_loss: 1.8355 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74750\n",
      "Epoch 33/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 1.9188 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74750\n",
      "Epoch 34/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0074 - accuracy: 0.9952 - val_loss: 2.1142 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74750\n",
      "Epoch 35/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0069 - accuracy: 0.9969 - val_loss: 1.9972 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74750\n",
      "Epoch 36/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 2.3749 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74750\n",
      "Epoch 37/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 0.9968 - val_loss: 2.2033 - val_accuracy: 0.6450\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74750\n",
      "Epoch 38/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 0.9978 - val_loss: 2.1548 - val_accuracy: 0.6425\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74750\n",
      "Epoch 39/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 2.2566 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74750\n",
      "Epoch 40/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0041 - accuracy: 0.9981 - val_loss: 2.3682 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74750\n",
      "Epoch 41/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0107 - accuracy: 0.9975 - val_loss: 2.3227 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74750\n",
      "Epoch 42/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0060 - accuracy: 0.9967 - val_loss: 2.2905 - val_accuracy: 0.6475\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74750\n",
      "Epoch 43/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0028 - accuracy: 0.9990 - val_loss: 2.3167 - val_accuracy: 0.6450\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74750\n",
      "Epoch 44/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 2.5732 - val_accuracy: 0.6425\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74750\n",
      "Epoch 45/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 2.4682 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74750\n",
      "Epoch 46/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0034 - accuracy: 0.9977 - val_loss: 2.6558 - val_accuracy: 0.6550\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74750\n",
      "Epoch 47/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 2.3145 - val_accuracy: 0.6375\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74750\n",
      "Epoch 48/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 0.9986 - val_loss: 2.4961 - val_accuracy: 0.6550\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74750\n",
      "Epoch 49/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 0.9983 - val_loss: 2.5482 - val_accuracy: 0.6350\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74750\n",
      "Epoch 50/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 0.9993 - val_loss: 2.2611 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74750\n",
      "Epoch 51/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 0.9980 - val_loss: 2.4335 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.74750\n",
      "Epoch 52/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0033 - accuracy: 0.9981 - val_loss: 2.6673 - val_accuracy: 0.6475\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.74750\n",
      "Epoch 53/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 2.3977 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.74750\n",
      "Epoch 54/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 8.8740e-04 - accuracy: 0.9999 - val_loss: 2.6304 - val_accuracy: 0.6425\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.74750\n",
      "Epoch 55/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0030 - accuracy: 0.9985 - val_loss: 2.7046 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.74750\n",
      "Epoch 56/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 4.3163e-04 - accuracy: 1.0000 - val_loss: 2.6050 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.74750\n",
      "Epoch 57/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 2.6984 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.74750\n",
      "Epoch 58/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0102 - accuracy: 0.9960 - val_loss: 2.5455 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.74750\n",
      "Epoch 59/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 0.9974 - val_loss: 2.4130 - val_accuracy: 0.6625\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.74750\n",
      "Epoch 60/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 2.3716 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.74750\n",
      "Epoch 61/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 2.4510 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.74750\n",
      "Epoch 62/70\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 0.9986 - val_loss: 2.7005 - val_accuracy: 0.6375\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.74750\n",
      "Epoch 63/70\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 0.9991 - val_loss: 2.6332 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.74750\n",
      "Epoch 64/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 2.7922 - val_accuracy: 0.6400\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.74750\n",
      "Epoch 65/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 2.7037 - val_accuracy: 0.6350\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.74750\n",
      "Epoch 66/70\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 0.9979 - val_loss: 2.7152 - val_accuracy: 0.6325\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.74750\n",
      "Epoch 67/70\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0056 - accuracy: 0.9961 - val_loss: 2.4813 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.74750\n",
      "Epoch 68/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 6.3180e-04 - accuracy: 0.9994 - val_loss: 2.4760 - val_accuracy: 0.6550\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.74750\n",
      "Epoch 69/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 2.4031 - val_accuracy: 0.6625\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.74750\n",
      "Epoch 70/70\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 2.5316 - val_accuracy: 0.6650\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.74750\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "model2.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
    "model2.add(layers.Dense(2,activation='softmax'))\n",
    "model2.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model2.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.665"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.around(model2.predict(X_test),decimals=0).argmax(axis=1)\n",
    "accuracy_score(x,y_test.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the DNN and some traditional classfication model would be used using the term frequency matrix.Firstly the word list would be created from our whole training dataset and then used as variables for future training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (pd.Series(words).apply(lambda z :\" \".join([x for x in z.split() if x not in stopword]))).tolist()\n",
    "\n",
    "wordlist = []\n",
    "for x in a:\n",
    "    for word in x.split():\n",
    "        if word not in wordlist:\n",
    "            wordlist.append(word)\n",
    "\n",
    "\n",
    "train = pd.DataFrame(doc2vec(a,wordlist))    \n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(train, data[\"sentiment\"], test_size=0.2, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6938 - acc: 0.4877\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6811 - acc: 0.7490\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6711 - acc: 0.8388\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6616 - acc: 0.8878\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6522 - acc: 0.9222\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6421 - acc: 0.9338\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6330 - acc: 0.9457\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6249 - acc: 0.9462\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6158 - acc: 0.9587\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6071 - acc: 0.9553\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5979 - acc: 0.9632\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5896 - acc: 0.9615\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5809 - acc: 0.9637\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5727 - acc: 0.9630\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5636 - acc: 0.9688\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5559 - acc: 0.9677\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5470 - acc: 0.9685\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5379 - acc: 0.9697\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5310 - acc: 0.9703\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5240 - acc: 0.9750\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5149 - acc: 0.9707\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5058 - acc: 0.9730\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4967 - acc: 0.9772\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4917 - acc: 0.9745\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4839 - acc: 0.9753\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4751 - acc: 0.9752\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4682 - acc: 0.9782\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4595 - acc: 0.9762\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4504 - acc: 0.9768\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4452 - acc: 0.9785\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4387 - acc: 0.9765\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4296 - acc: 0.9780\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4234 - acc: 0.9813\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4161 - acc: 0.9808\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4092 - acc: 0.9822\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4010 - acc: 0.9800\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3931 - acc: 0.9837\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3863 - acc: 0.9815\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3810 - acc: 0.9817\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3729 - acc: 0.9843\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3700 - acc: 0.9832\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3601 - acc: 0.9837\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3544 - acc: 0.9837\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3476 - acc: 0.9823\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3408 - acc: 0.9823\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3373 - acc: 0.9812\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3296 - acc: 0.9858\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3240 - acc: 0.9818\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3187 - acc: 0.9840\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3118 - acc: 0.9847\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3072 - acc: 0.9853\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2990 - acc: 0.9860\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2922 - acc: 0.9833\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2889 - acc: 0.9853\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2823 - acc: 0.9862\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2762 - acc: 0.9867\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2727 - acc: 0.9870\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2674 - acc: 0.9877\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2633 - acc: 0.9877\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2577 - acc: 0.9870\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5576 - acc: 0.7225\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6918 - acc: 0.5063\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6745 - acc: 0.7087\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6618 - acc: 0.7818\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6482 - acc: 0.8118\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6362 - acc: 0.8493\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6245 - acc: 0.8727\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6136 - acc: 0.8923\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6039 - acc: 0.8983\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5936 - acc: 0.9113\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5832 - acc: 0.9108\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5744 - acc: 0.9105\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5637 - acc: 0.9242\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5542 - acc: 0.9237\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5444 - acc: 0.9310\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5335 - acc: 0.9352\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5249 - acc: 0.9360\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5162 - acc: 0.9425\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5082 - acc: 0.9463\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4996 - acc: 0.9457\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4900 - acc: 0.9467\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4806 - acc: 0.9528\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4727 - acc: 0.9523\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4640 - acc: 0.9525\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4552 - acc: 0.9510\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4484 - acc: 0.9545\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4382 - acc: 0.9513\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4320 - acc: 0.9592\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4224 - acc: 0.9592\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4145 - acc: 0.9572\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4071 - acc: 0.9638\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3991 - acc: 0.9642\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3923 - acc: 0.9677\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3840 - acc: 0.9655\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3798 - acc: 0.9668\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3729 - acc: 0.9678\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3650 - acc: 0.9707\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3568 - acc: 0.9708\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3491 - acc: 0.9715\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3453 - acc: 0.9690\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3353 - acc: 0.9728\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3302 - acc: 0.9758\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3244 - acc: 0.9727\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3193 - acc: 0.9747\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3096 - acc: 0.9773\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3045 - acc: 0.9832\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3002 - acc: 0.9775\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2948 - acc: 0.9800\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2894 - acc: 0.9793\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2832 - acc: 0.9813\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2784 - acc: 0.9810\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2754 - acc: 0.9838\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2669 - acc: 0.9825\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2612 - acc: 0.9832\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2550 - acc: 0.9852\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2524 - acc: 0.9862\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2491 - acc: 0.9848\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2401 - acc: 0.9868\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2370 - acc: 0.9855\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2326 - acc: 0.9855\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2260 - acc: 0.9882\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5656 - acc: 0.7125\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6950 - acc: 0.5083\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6705 - acc: 0.7857\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6533 - acc: 0.8617\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6402 - acc: 0.8937\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6269 - acc: 0.9215\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6151 - acc: 0.9292\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6027 - acc: 0.9405\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5923 - acc: 0.9548\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5841 - acc: 0.9523\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5734 - acc: 0.9515\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5630 - acc: 0.9558\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5533 - acc: 0.9550\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5451 - acc: 0.9572\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5356 - acc: 0.9572\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5263 - acc: 0.9572\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5194 - acc: 0.9622\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5102 - acc: 0.9588\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5006 - acc: 0.9607\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4905 - acc: 0.9648\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4856 - acc: 0.9677\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4759 - acc: 0.9707\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4676 - acc: 0.9715\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4601 - acc: 0.9702\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4530 - acc: 0.9763\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4457 - acc: 0.9733\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4382 - acc: 0.9748\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4302 - acc: 0.9765\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4233 - acc: 0.9760\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4166 - acc: 0.9760\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4102 - acc: 0.9762\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4035 - acc: 0.9747\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3968 - acc: 0.9770\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3886 - acc: 0.9770\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3831 - acc: 0.9770\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3758 - acc: 0.9763\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3701 - acc: 0.9765\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3661 - acc: 0.9772\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3582 - acc: 0.9785\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3509 - acc: 0.9778\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3462 - acc: 0.9787\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3410 - acc: 0.9780\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3345 - acc: 0.9798\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3273 - acc: 0.9827\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3249 - acc: 0.9802\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3195 - acc: 0.9810\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3105 - acc: 0.9837\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3074 - acc: 0.9832\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3013 - acc: 0.9858\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2965 - acc: 0.9832\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2897 - acc: 0.9825\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2868 - acc: 0.9832\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2820 - acc: 0.9840\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2779 - acc: 0.9832\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2735 - acc: 0.9848\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2694 - acc: 0.9868\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2626 - acc: 0.9862\n",
      "Epoch 57/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2611 - acc: 0.9835\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2547 - acc: 0.9855\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2501 - acc: 0.9848\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2444 - acc: 0.9868\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5550 - acc: 0.7325\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6920 - acc: 0.5497\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6630 - acc: 0.7748\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6431 - acc: 0.8510\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6283 - acc: 0.8862\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6122 - acc: 0.9012\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5987 - acc: 0.9168\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5869 - acc: 0.9232\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5758 - acc: 0.9262\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5644 - acc: 0.9315\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5530 - acc: 0.9302\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5431 - acc: 0.9310\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5321 - acc: 0.9347\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5202 - acc: 0.9305\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5113 - acc: 0.9382\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5017 - acc: 0.9418\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4927 - acc: 0.9417\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4822 - acc: 0.9477\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4765 - acc: 0.9465\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4668 - acc: 0.9462\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4589 - acc: 0.9445\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4504 - acc: 0.9470\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4398 - acc: 0.9477\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4326 - acc: 0.9468\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4228 - acc: 0.9595\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4171 - acc: 0.9517\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4072 - acc: 0.9562\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4016 - acc: 0.9585\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3937 - acc: 0.9605\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3845 - acc: 0.9603\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3795 - acc: 0.9593\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3745 - acc: 0.9588\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3659 - acc: 0.9595\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3599 - acc: 0.9623\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3517 - acc: 0.9637\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3436 - acc: 0.9683\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3394 - acc: 0.9677\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3309 - acc: 0.9677\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3297 - acc: 0.9693\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3205 - acc: 0.9707\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3142 - acc: 0.9720\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3086 - acc: 0.9707\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3016 - acc: 0.9723\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2967 - acc: 0.9732\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2907 - acc: 0.9752\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2869 - acc: 0.9740\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2778 - acc: 0.9832\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2759 - acc: 0.9778\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2716 - acc: 0.9785\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2645 - acc: 0.9807\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2611 - acc: 0.9792\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2557 - acc: 0.9800\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2490 - acc: 0.9822\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2442 - acc: 0.9817\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2418 - acc: 0.9823\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2372 - acc: 0.9830\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2308 - acc: 0.9843\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2284 - acc: 0.9838\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2250 - acc: 0.9875\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2180 - acc: 0.9867\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2178 - acc: 0.9848\n",
      "WARNING:tensorflow:5 out of the last 917 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D6716820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5583 - acc: 0.6975\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6924 - acc: 0.5373\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6818 - acc: 0.7593\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6735 - acc: 0.8302\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6652 - acc: 0.8833\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6569 - acc: 0.9105\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6484 - acc: 0.9278\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6401 - acc: 0.9370\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6316 - acc: 0.9433\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6236 - acc: 0.9522\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6144 - acc: 0.9565\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6065 - acc: 0.9587\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5987 - acc: 0.9622\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5888 - acc: 0.9615\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5812 - acc: 0.9630\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5728 - acc: 0.9655\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5655 - acc: 0.9655\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5566 - acc: 0.9643\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5478 - acc: 0.964 - 0s 8ms/step - loss: 0.5485 - acc: 0.9630\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5413 - acc: 0.9582\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5323 - acc: 0.9652\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5244 - acc: 0.9662\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5173 - acc: 0.9660\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5103 - acc: 0.9678\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5022 - acc: 0.9718\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4937 - acc: 0.9690\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4858 - acc: 0.9678\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4789 - acc: 0.9707\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4713 - acc: 0.9700\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4645 - acc: 0.9723\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4562 - acc: 0.9750\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4514 - acc: 0.9725\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4424 - acc: 0.9737\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4332 - acc: 0.9730\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4267 - acc: 0.9753\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4207 - acc: 0.9755\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4126 - acc: 0.9797\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4080 - acc: 0.9757\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3987 - acc: 0.9768\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3957 - acc: 0.9753\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3868 - acc: 0.9742\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3799 - acc: 0.9790\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3729 - acc: 0.9805\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3667 - acc: 0.9813\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3612 - acc: 0.9780\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3542 - acc: 0.9795\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3465 - acc: 0.9807\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3431 - acc: 0.9802\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3348 - acc: 0.9815\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3285 - acc: 0.9793\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3242 - acc: 0.9815\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3185 - acc: 0.9800\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3116 - acc: 0.9817\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3050 - acc: 0.9852\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3001 - acc: 0.9837\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2958 - acc: 0.9838\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2908 - acc: 0.9858\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2852 - acc: 0.9818\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2785 - acc: 0.9845\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2722 - acc: 0.9867\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2681 - acc: 0.9867\n",
      "WARNING:tensorflow:6 out of the last 919 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F77591F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5610 - acc: 0.7325\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6930 - acc: 0.5157\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6783 - acc: 0.7438\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6671 - acc: 0.8225\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6551 - acc: 0.8457\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6451 - acc: 0.8635\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6338 - acc: 0.8718\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6234 - acc: 0.8872\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6131 - acc: 0.9047\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6024 - acc: 0.9043\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5920 - acc: 0.9097\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5827 - acc: 0.9165\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5723 - acc: 0.9208\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5627 - acc: 0.9298\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5536 - acc: 0.9300\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5440 - acc: 0.9363\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5357 - acc: 0.9373\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5264 - acc: 0.9365\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5179 - acc: 0.9367\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5090 - acc: 0.9453\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5006 - acc: 0.9433\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4921 - acc: 0.9432\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4829 - acc: 0.9468\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4722 - acc: 0.9527\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4673 - acc: 0.9485\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4586 - acc: 0.9482\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4510 - acc: 0.9545\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4444 - acc: 0.9532\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4355 - acc: 0.9530\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4282 - acc: 0.9540\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4204 - acc: 0.9555\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4118 - acc: 0.9583\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4056 - acc: 0.9602\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3994 - acc: 0.9617\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3918 - acc: 0.9645\n",
      "Epoch 35/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3825 - acc: 0.9668\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3774 - acc: 0.9668\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3701 - acc: 0.9677\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3632 - acc: 0.9668\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3578 - acc: 0.9677\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3507 - acc: 0.9698\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3467 - acc: 0.9678\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3396 - acc: 0.9680\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3328 - acc: 0.9705\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3249 - acc: 0.9723\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3183 - acc: 0.9738\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3117 - acc: 0.9752\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3056 - acc: 0.9738\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3007 - acc: 0.9725\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2970 - acc: 0.9725\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2885 - acc: 0.9752\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2827 - acc: 0.9760\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2802 - acc: 0.9757\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2746 - acc: 0.9792\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2679 - acc: 0.9778\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2621 - acc: 0.9800\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2585 - acc: 0.9828\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2506 - acc: 0.9838\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2478 - acc: 0.9838\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2445 - acc: 0.9858\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2389 - acc: 0.9860\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F25A89D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5695 - acc: 0.7013\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6930 - acc: 0.5218\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6649 - acc: 0.7915\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6460 - acc: 0.8795\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6306 - acc: 0.9023\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6159 - acc: 0.9257\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6026 - acc: 0.9298\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5912 - acc: 0.9342\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5801 - acc: 0.9392\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5701 - acc: 0.9448\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5590 - acc: 0.9507\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5486 - acc: 0.9522\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5386 - acc: 0.9482\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5289 - acc: 0.9538\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5193 - acc: 0.9642\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5116 - acc: 0.9628\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5036 - acc: 0.9602\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4940 - acc: 0.9652\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4832 - acc: 0.9665\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4774 - acc: 0.9705\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4687 - acc: 0.9690\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4615 - acc: 0.9705\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4531 - acc: 0.9677\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4463 - acc: 0.9730\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4363 - acc: 0.9672\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4292 - acc: 0.9757\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4226 - acc: 0.9738\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4171 - acc: 0.9747\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4099 - acc: 0.9738\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4004 - acc: 0.9737\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3951 - acc: 0.9765\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3906 - acc: 0.9747\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3813 - acc: 0.9790\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3751 - acc: 0.9760\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3710 - acc: 0.9785\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3631 - acc: 0.9778\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3578 - acc: 0.9770\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3477 - acc: 0.9803\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3437 - acc: 0.9768\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3378 - acc: 0.9798\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3337 - acc: 0.9772\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3283 - acc: 0.9800\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3230 - acc: 0.9787\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3164 - acc: 0.9793\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3097 - acc: 0.9787\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3050 - acc: 0.9822\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3021 - acc: 0.9825\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2932 - acc: 0.9845\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2900 - acc: 0.9838\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2841 - acc: 0.9845\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2793 - acc: 0.9840\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2738 - acc: 0.9862\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2725 - acc: 0.9863\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2671 - acc: 0.9883\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2603 - acc: 0.9862\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2564 - acc: 0.9883\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2559 - acc: 0.9878\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2473 - acc: 0.9898\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2439 - acc: 0.9885\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2409 - acc: 0.9893\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2348 - acc: 0.9907\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EBFAD8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5565 - acc: 0.7312\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6913 - acc: 0.5597\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6578 - acc: 0.7993\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6341 - acc: 0.8572\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6166 - acc: 0.9012\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6001 - acc: 0.9057\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5857 - acc: 0.9138\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5698 - acc: 0.9302\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5573 - acc: 0.9360\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5471 - acc: 0.9388\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5336 - acc: 0.9402\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5229 - acc: 0.9372\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5121 - acc: 0.9417\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4994 - acc: 0.9517\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4886 - acc: 0.9492\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4786 - acc: 0.9513\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4710 - acc: 0.9527\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4596 - acc: 0.9608\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4495 - acc: 0.9605\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4433 - acc: 0.9552\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4337 - acc: 0.9565\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4223 - acc: 0.9585\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4207 - acc: 0.954 - 0s 9ms/step - loss: 0.4168 - acc: 0.9572\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4060 - acc: 0.9603\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3984 - acc: 0.9612\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3879 - acc: 0.9645\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3814 - acc: 0.9632\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3743 - acc: 0.9657\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3697 - acc: 0.9642\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3600 - acc: 0.9662\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3541 - acc: 0.9657\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3465 - acc: 0.9713\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3375 - acc: 0.9698\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3303 - acc: 0.9727\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3271 - acc: 0.9667\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3193 - acc: 0.9693\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3102 - acc: 0.9720\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3039 - acc: 0.9733\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3004 - acc: 0.9760\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2932 - acc: 0.9808\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2873 - acc: 0.9762\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2830 - acc: 0.9783\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2779 - acc: 0.9800\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2738 - acc: 0.9793\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2683 - acc: 0.9778\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2611 - acc: 0.9802\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2555 - acc: 0.9802\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2502 - acc: 0.9828\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2462 - acc: 0.9817\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2389 - acc: 0.9858\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2367 - acc: 0.9823\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2278 - acc: 0.9852\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2259 - acc: 0.9840\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2236 - acc: 0.9840\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2180 - acc: 0.9847\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2165 - acc: 0.980 - 0s 8ms/step - loss: 0.2146 - acc: 0.9833\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2122 - acc: 0.9842\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2070 - acc: 0.9855\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2018 - acc: 0.9870\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1957 - acc: 0.9890\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1922 - acc: 0.9898\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED733160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5600 - acc: 0.7050\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6924 - acc: 0.5188\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6809 - acc: 0.6575\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6707 - acc: 0.7035\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6609 - acc: 0.7487\n",
      "Epoch 5/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6505 - acc: 0.7883\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6403 - acc: 0.8213\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6292 - acc: 0.8383\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6186 - acc: 0.8688\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6067 - acc: 0.8813\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5959 - acc: 0.8933\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5822 - acc: 0.9057\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5719 - acc: 0.9130\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5600 - acc: 0.9238\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5467 - acc: 0.9253\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5359 - acc: 0.9423\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5261 - acc: 0.9453\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5170 - acc: 0.9493\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5043 - acc: 0.9538\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4926 - acc: 0.9583\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4841 - acc: 0.9638\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4724 - acc: 0.9680\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4610 - acc: 0.9715\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4531 - acc: 0.9710\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4414 - acc: 0.9712\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4309 - acc: 0.9762\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4190 - acc: 0.9757\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4107 - acc: 0.9792\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4036 - acc: 0.9778\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3885 - acc: 0.9812\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3798 - acc: 0.9822\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3732 - acc: 0.9838\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3613 - acc: 0.9853\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3532 - acc: 0.9862\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3461 - acc: 0.9862\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3382 - acc: 0.9855\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3253 - acc: 0.9868\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3153 - acc: 0.9862\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3092 - acc: 0.9877\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2982 - acc: 0.9885\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2908 - acc: 0.9883\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2839 - acc: 0.9887\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2735 - acc: 0.9920\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2672 - acc: 0.9908\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2590 - acc: 0.9900\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2515 - acc: 0.9922\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2423 - acc: 0.9908\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2381 - acc: 0.9915\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2280 - acc: 0.9915\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2214 - acc: 0.9928\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2138 - acc: 0.9937\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2070 - acc: 0.9932\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2010 - acc: 0.9938\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1938 - acc: 0.9925\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1869 - acc: 0.9938\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1811 - acc: 0.9938\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1758 - acc: 0.9945\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1679 - acc: 0.9925\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1605 - acc: 0.9938\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1576 - acc: 0.9953\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1516 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED84F8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5776 - acc: 0.7013\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6931 - acc: 0.5143\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6871 - acc: 0.6930\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6819 - acc: 0.7833\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6764 - acc: 0.8247\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6706 - acc: 0.8683\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6645 - acc: 0.8802\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6583 - acc: 0.9010\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6508 - acc: 0.9290\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6434 - acc: 0.9428\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6361 - acc: 0.9470\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6284 - acc: 0.9503\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6200 - acc: 0.9582\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6120 - acc: 0.9572\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6032 - acc: 0.9625\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5942 - acc: 0.9630\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5853 - acc: 0.9693\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5769 - acc: 0.9702\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5681 - acc: 0.9703\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5572 - acc: 0.9717\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5476 - acc: 0.9723\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5371 - acc: 0.9762\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5281 - acc: 0.9760\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5194 - acc: 0.9748\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5088 - acc: 0.9753\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4983 - acc: 0.9805\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4881 - acc: 0.9790\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4791 - acc: 0.9800\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4693 - acc: 0.9770\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4576 - acc: 0.9798\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4491 - acc: 0.9800\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4390 - acc: 0.9820\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4277 - acc: 0.9800\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4211 - acc: 0.9795\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4097 - acc: 0.9812\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3993 - acc: 0.9828\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3920 - acc: 0.9822\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3817 - acc: 0.9823\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3722 - acc: 0.9830\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3615 - acc: 0.9837\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3532 - acc: 0.9808\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3450 - acc: 0.9838\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3349 - acc: 0.9815\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3282 - acc: 0.9832\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3180 - acc: 0.9845\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3089 - acc: 0.9828\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3012 - acc: 0.9867\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2914 - acc: 0.9848\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2849 - acc: 0.9890\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2822 - acc: 0.982 - 0s 8ms/step - loss: 0.2783 - acc: 0.9857\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2691 - acc: 0.9877\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2612 - acc: 0.9855\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2534 - acc: 0.9883\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2450 - acc: 0.9870\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2351 - acc: 0.9877\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2290 - acc: 0.9892\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2200 - acc: 0.9900\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2128 - acc: 0.9900\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2081 - acc: 0.9893\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1999 - acc: 0.9900\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1935 - acc: 0.9893\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDC3F4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5651 - acc: 0.6938\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6946 - acc: 0.4853\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6723 - acc: 0.7913\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6547 - acc: 0.8582\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6390 - acc: 0.8910\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6231 - acc: 0.9200\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6088 - acc: 0.9177\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5944 - acc: 0.9245\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5807 - acc: 0.9340\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5695 - acc: 0.9330\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5566 - acc: 0.9435\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5426 - acc: 0.9535\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5321 - acc: 0.9560\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5195 - acc: 0.9602\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5084 - acc: 0.9635\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4984 - acc: 0.964 - 0s 8ms/step - loss: 0.4971 - acc: 0.9647\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4872 - acc: 0.9648\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4748 - acc: 0.9677\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4640 - acc: 0.9713\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4538 - acc: 0.9717\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4439 - acc: 0.9737\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4332 - acc: 0.9732\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4225 - acc: 0.9732\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4145 - acc: 0.9733\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4053 - acc: 0.9787\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3972 - acc: 0.9798\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3882 - acc: 0.9767\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3771 - acc: 0.9787\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3702 - acc: 0.9787\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3609 - acc: 0.9828\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3523 - acc: 0.9820\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3444 - acc: 0.9817\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3353 - acc: 0.9823\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3252 - acc: 0.9865\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3196 - acc: 0.9845\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3125 - acc: 0.9840\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3049 - acc: 0.9840\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2981 - acc: 0.9847\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2911 - acc: 0.9862\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2831 - acc: 0.9882\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2761 - acc: 0.9883\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2694 - acc: 0.9877\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2623 - acc: 0.9897\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2554 - acc: 0.9900\n",
      "Epoch 44/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2512 - acc: 0.9893\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2431 - acc: 0.9908\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2379 - acc: 0.9938\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2299 - acc: 0.9938\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2253 - acc: 0.9953\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2190 - acc: 0.9955\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2138 - acc: 0.9955\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2087 - acc: 0.9968\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2039 - acc: 0.9977\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1984 - acc: 0.9962\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1933 - acc: 0.9970\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1885 - acc: 0.9970\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1828 - acc: 0.9977\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1790 - acc: 0.9970\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1728 - acc: 0.9977\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1698 - acc: 0.9970\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1638 - acc: 0.9970\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0DA780AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5590 - acc: 0.7200\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6935 - acc: 0.5165\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6715 - acc: 0.7358\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6559 - acc: 0.8162\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6389 - acc: 0.8707\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6251 - acc: 0.9007\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6109 - acc: 0.9133\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5974 - acc: 0.9255\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5837 - acc: 0.9318\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5691 - acc: 0.9418\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5559 - acc: 0.9428\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5440 - acc: 0.9498\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5320 - acc: 0.9507\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5192 - acc: 0.9530\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5077 - acc: 0.9522\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4957 - acc: 0.9545\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4854 - acc: 0.9552\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4726 - acc: 0.9575\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4618 - acc: 0.9572\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4516 - acc: 0.9637\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4389 - acc: 0.9685\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4306 - acc: 0.9638\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4190 - acc: 0.9647\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4091 - acc: 0.9660\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3984 - acc: 0.9662\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3897 - acc: 0.9687\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3785 - acc: 0.9733\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3708 - acc: 0.9773\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3606 - acc: 0.9753\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3528 - acc: 0.9762\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3436 - acc: 0.9805\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3347 - acc: 0.9807\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3305 - acc: 0.9802\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3197 - acc: 0.9800\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3105 - acc: 0.9792\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3020 - acc: 0.9800\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2945 - acc: 0.9795\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2846 - acc: 0.9823\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2790 - acc: 0.9840\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2712 - acc: 0.9883\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2674 - acc: 0.9862\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2590 - acc: 0.9877\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2528 - acc: 0.9893\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2451 - acc: 0.9900\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2387 - acc: 0.9885\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2333 - acc: 0.9902\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2258 - acc: 0.9907\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2217 - acc: 0.9902\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2129 - acc: 0.9913\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2101 - acc: 0.9908\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2013 - acc: 0.9928\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1962 - acc: 0.9930\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1917 - acc: 0.9932\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1874 - acc: 0.9917\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1795 - acc: 0.9945\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1769 - acc: 0.9938\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1702 - acc: 0.9945\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1665 - acc: 0.9945\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1612 - acc: 0.9930\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1607 - acc: 0.9917\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1545 - acc: 0.9938\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E897C8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5601 - acc: 0.7013\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 10ms/step - loss: 0.6927 - acc: 0.4937\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6867 - acc: 0.6805\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6807 - acc: 0.6847\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6744 - acc: 0.8260\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6673 - acc: 0.8188\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6608 - acc: 0.8857\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6532 - acc: 0.8718\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6440 - acc: 0.8800\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6347 - acc: 0.9070\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6272 - acc: 0.9127\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6175 - acc: 0.9147\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6080 - acc: 0.9150\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5986 - acc: 0.9235\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5869 - acc: 0.9365\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5801 - acc: 0.9427\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5719 - acc: 0.9358\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5610 - acc: 0.9318\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5501 - acc: 0.9420\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5425 - acc: 0.9472\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5322 - acc: 0.9425\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5214 - acc: 0.9435\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5125 - acc: 0.9497\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5012 - acc: 0.9608\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4960 - acc: 0.9600\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4850 - acc: 0.9632\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4746 - acc: 0.9607\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4659 - acc: 0.9698\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4597 - acc: 0.9698\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4483 - acc: 0.9708\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4388 - acc: 0.9720\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4324 - acc: 0.9790\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4260 - acc: 0.9782\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4143 - acc: 0.9790\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4071 - acc: 0.9808\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3977 - acc: 0.9802\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3934 - acc: 0.9843\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3819 - acc: 0.9860\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3831 - acc: 0.9833\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3692 - acc: 0.9868\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3646 - acc: 0.9905\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3608 - acc: 0.9908\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3484 - acc: 0.9908\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3375 - acc: 0.9922\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3338 - acc: 0.9915\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3283 - acc: 0.9943\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3230 - acc: 0.9930\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3140 - acc: 0.9937\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3088 - acc: 0.9910\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3023 - acc: 0.9937\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2939 - acc: 0.9940\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2916 - acc: 0.9960\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2861 - acc: 0.9953\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2788 - acc: 0.9947\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2701 - acc: 0.9962\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2654 - acc: 0.9977\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2613 - acc: 0.9985\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2496 - acc: 0.9992\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2468 - acc: 0.9985\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2425 - acc: 0.9992\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2339 - acc: 0.9992\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDAA8A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6976 - acc: 0.6513\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6928 - acc: 0.5152\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6855 - acc: 0.5105\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6780 - acc: 0.5178\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6705 - acc: 0.5227\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6623 - acc: 0.5258\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6533 - acc: 0.6075\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6449 - acc: 0.6952\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6365 - acc: 0.7447\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6293 - acc: 0.7647\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6192 - acc: 0.7792\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6107 - acc: 0.8152\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6030 - acc: 0.8290\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5947 - acc: 0.8438\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5863 - acc: 0.8687\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5755 - acc: 0.8675\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5701 - acc: 0.8943\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5603 - acc: 0.8928\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5511 - acc: 0.9008\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5437 - acc: 0.9053\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5352 - acc: 0.9140\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5252 - acc: 0.9152\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5215 - acc: 0.9217\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5104 - acc: 0.9152\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5039 - acc: 0.9262\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4971 - acc: 0.9237\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4869 - acc: 0.9272\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4795 - acc: 0.9392\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4706 - acc: 0.9390\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4654 - acc: 0.9422\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4517 - acc: 0.9437\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4506 - acc: 0.9482\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4426 - acc: 0.9467\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4345 - acc: 0.9495\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4286 - acc: 0.9500\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4239 - acc: 0.9553\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4166 - acc: 0.9590\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4103 - acc: 0.9607\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4019 - acc: 0.9637\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3968 - acc: 0.9662\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3931 - acc: 0.9665\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3830 - acc: 0.9693\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3764 - acc: 0.9735\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3679 - acc: 0.9753\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3644 - acc: 0.9775\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3598 - acc: 0.9772\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3506 - acc: 0.9815\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3491 - acc: 0.9830\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3455 - acc: 0.9845\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3376 - acc: 0.9832\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3325 - acc: 0.9848\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3294 - acc: 0.9840\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3226 - acc: 0.9883\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3148 - acc: 0.9862\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3082 - acc: 0.9885\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3075 - acc: 0.9917\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2990 - acc: 0.9930\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2945 - acc: 0.9923\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2899 - acc: 0.9938\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2835 - acc: 0.9945\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2818 - acc: 0.9938\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F3665E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7947 - acc: 0.6263\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6866 - acc: 0.5533\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6454 - acc: 0.7687\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6135 - acc: 0.8500\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5841 - acc: 0.8882\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5542 - acc: 0.9065\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5294 - acc: 0.9303\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5052 - acc: 0.9357\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4819 - acc: 0.9428\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4603 - acc: 0.9507\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4393 - acc: 0.9547\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4189 - acc: 0.9550\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3990 - acc: 0.9623\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3810 - acc: 0.9642\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3654 - acc: 0.9662\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3474 - acc: 0.9685\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3303 - acc: 0.9767\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3149 - acc: 0.9775\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3011 - acc: 0.9775\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2885 - acc: 0.9813\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2758 - acc: 0.9828\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2613 - acc: 0.9858\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2498 - acc: 0.9882\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2402 - acc: 0.9890\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2302 - acc: 0.9900\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2196 - acc: 0.9878\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2109 - acc: 0.9887\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1997 - acc: 0.9908\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1914 - acc: 0.9917\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1828 - acc: 0.9953\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1749 - acc: 0.9953\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1669 - acc: 0.9955\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1575 - acc: 0.9968\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1525 - acc: 0.9970\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1461 - acc: 0.9977\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1383 - acc: 0.9977\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1338 - acc: 0.9983\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1271 - acc: 0.9992\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1199 - acc: 0.9992\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1164 - acc: 0.9985\n",
      "Epoch 40/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1108 - acc: 0.9985\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1058 - acc: 1.0000\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1006 - acc: 0.9992\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0973 - acc: 1.0000\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0931 - acc: 1.0000\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0892 - acc: 1.0000\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0852 - acc: 1.0000\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0818 - acc: 1.0000\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0786 - acc: 1.0000\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0755 - acc: 1.0000\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0731 - acc: 1.0000\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0691 - acc: 1.0000\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0664 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0637 - acc: 1.0000\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0612 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0592 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0567 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0546 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0523 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0491 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F2448160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6584 - acc: 0.7075\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6979 - acc: 0.4673\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6571 - acc: 0.7398\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6268 - acc: 0.8618\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5996 - acc: 0.8925\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5740 - acc: 0.9248\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5503 - acc: 0.9315\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5278 - acc: 0.9400\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5077 - acc: 0.9507\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4888 - acc: 0.9513\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4698 - acc: 0.9520\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4531 - acc: 0.9562\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4359 - acc: 0.9578\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4192 - acc: 0.9667\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4073 - acc: 0.9653\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3931 - acc: 0.9672\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3783 - acc: 0.9747\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3639 - acc: 0.9740\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3510 - acc: 0.9753\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3366 - acc: 0.9800\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3254 - acc: 0.9815\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3140 - acc: 0.9788\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3024 - acc: 0.9825\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2880 - acc: 0.9883\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2781 - acc: 0.9883\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2690 - acc: 0.9915\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2591 - acc: 0.9923\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2489 - acc: 0.9910\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2384 - acc: 0.9915\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2298 - acc: 0.9923\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2200 - acc: 0.9938\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2110 - acc: 0.9932\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2048 - acc: 0.9932\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1960 - acc: 0.9917\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1875 - acc: 0.9938\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1791 - acc: 0.9932\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1728 - acc: 0.9938\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1669 - acc: 0.9932\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1593 - acc: 0.9930\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1545 - acc: 0.9932\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1487 - acc: 0.9938\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1418 - acc: 0.9945\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1352 - acc: 0.9947\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1313 - acc: 0.9953\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1254 - acc: 0.9960\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1214 - acc: 0.9938\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1177 - acc: 0.9947\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1123 - acc: 0.9953\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1075 - acc: 0.9953\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1036 - acc: 0.9962\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0988 - acc: 0.9975\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0980 - acc: 0.9955\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0939 - acc: 0.9962\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0894 - acc: 0.9968\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0865 - acc: 0.9962\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0821 - acc: 0.9968\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0819 - acc: 0.9947\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0787 - acc: 0.9962\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0758 - acc: 0.9962\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0722 - acc: 0.9953\n",
      "Epoch 60/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0711 - acc: 0.9947\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D8F3ADC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6278 - acc: 0.6988\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6940 - acc: 0.5042\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6811 - acc: 0.7533\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6713 - acc: 0.8258\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6625 - acc: 0.8788\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6533 - acc: 0.9107\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6458 - acc: 0.9298\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6373 - acc: 0.9400\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6282 - acc: 0.9385\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6203 - acc: 0.9497\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6110 - acc: 0.9520\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6029 - acc: 0.9647\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5967 - acc: 0.9643\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5886 - acc: 0.9618\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5799 - acc: 0.9682\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5742 - acc: 0.9720\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5659 - acc: 0.9713\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5600 - acc: 0.9710\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5511 - acc: 0.9702\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5437 - acc: 0.9723\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5373 - acc: 0.9685\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5284 - acc: 0.9735\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5223 - acc: 0.9707\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5155 - acc: 0.9713\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5076 - acc: 0.9743\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5019 - acc: 0.9752\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4968 - acc: 0.9747\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4860 - acc: 0.9757\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4801 - acc: 0.9748\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4734 - acc: 0.9767\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4673 - acc: 0.9782\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4609 - acc: 0.9720\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4566 - acc: 0.9748\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4463 - acc: 0.9762\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4416 - acc: 0.9790\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4354 - acc: 0.9742\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4288 - acc: 0.9782\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4229 - acc: 0.9763\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4139 - acc: 0.9782\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4109 - acc: 0.9780\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4059 - acc: 0.9792\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4001 - acc: 0.9807\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3903 - acc: 0.9813\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3867 - acc: 0.9808\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3820 - acc: 0.9840\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3746 - acc: 0.9808\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3673 - acc: 0.9843\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3650 - acc: 0.9810\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3574 - acc: 0.9867\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3528 - acc: 0.9858\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3462 - acc: 0.9860\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3427 - acc: 0.9873\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3360 - acc: 0.9873\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3309 - acc: 0.9880\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3253 - acc: 0.9875\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3206 - acc: 0.9860\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3168 - acc: 0.9833\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3119 - acc: 0.9848\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3061 - acc: 0.9855\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3014 - acc: 0.9870\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2975 - acc: 0.9883\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2927 - acc: 0.9897\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2853 - acc: 0.9898\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2803 - acc: 0.9900\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2758 - acc: 0.9913\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2705 - acc: 0.9913\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2677 - acc: 0.9907\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2643 - acc: 0.9908\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2587 - acc: 0.9908\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2560 - acc: 0.9910\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2513 - acc: 0.9917\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E897CAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5678 - acc: 0.7337\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6934 - acc: 0.4672\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6842 - acc: 0.6980\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6771 - acc: 0.7713\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6697 - acc: 0.8275\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6630 - acc: 0.8672\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6560 - acc: 0.9008\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6483 - acc: 0.9253\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6417 - acc: 0.9333\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6343 - acc: 0.9428\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6268 - acc: 0.9525\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6204 - acc: 0.9493\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6129 - acc: 0.9575\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6060 - acc: 0.9600\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5985 - acc: 0.9607\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5918 - acc: 0.9622\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5851 - acc: 0.9623\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5777 - acc: 0.9647\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5712 - acc: 0.9638\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5633 - acc: 0.9667\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5564 - acc: 0.9633\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5510 - acc: 0.9633\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5426 - acc: 0.9712\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5364 - acc: 0.9700\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5286 - acc: 0.9707\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5215 - acc: 0.9708\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5143 - acc: 0.9735\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5085 - acc: 0.9745\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5024 - acc: 0.9738\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4941 - acc: 0.9718\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4886 - acc: 0.9725\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4806 - acc: 0.9732\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4740 - acc: 0.9760\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4653 - acc: 0.9773\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4628 - acc: 0.9742\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4534 - acc: 0.9783\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4477 - acc: 0.9778\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4405 - acc: 0.9770\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4334 - acc: 0.9790\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4280 - acc: 0.9793\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4215 - acc: 0.9785\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4134 - acc: 0.9780\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4073 - acc: 0.9787\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4020 - acc: 0.9793\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3955 - acc: 0.9800\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3897 - acc: 0.9823\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3831 - acc: 0.9802\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3761 - acc: 0.9825\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3694 - acc: 0.9817\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3640 - acc: 0.9830\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3571 - acc: 0.9858\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3550 - acc: 0.9832\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3486 - acc: 0.9832\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3400 - acc: 0.9858\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3340 - acc: 0.9845\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3280 - acc: 0.9838\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3252 - acc: 0.9825\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3194 - acc: 0.9853\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3123 - acc: 0.9840\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3094 - acc: 0.9867\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3047 - acc: 0.9840\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2963 - acc: 0.9855\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2928 - acc: 0.9875\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2886 - acc: 0.9855\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2834 - acc: 0.9868\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2780 - acc: 0.9875\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2730 - acc: 0.9868\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2686 - acc: 0.9855\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2647 - acc: 0.9868\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2593 - acc: 0.9862\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2504 - acc: 0.9875\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0FB9BDD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5661 - acc: 0.7075\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6915 - acc: 0.5558\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6666 - acc: 0.7783\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6510 - acc: 0.8412\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6356 - acc: 0.8818\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6235 - acc: 0.9037\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6113 - acc: 0.9075\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6002 - acc: 0.9228\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5905 - acc: 0.9305\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5792 - acc: 0.9290\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5702 - acc: 0.9385\n",
      "Epoch 11/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5595 - acc: 0.9443\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5493 - acc: 0.9448\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5410 - acc: 0.9477\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5331 - acc: 0.9498\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5234 - acc: 0.9478\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5156 - acc: 0.9537\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5077 - acc: 0.9552\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4992 - acc: 0.9553\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4886 - acc: 0.9558\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4830 - acc: 0.9622\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4743 - acc: 0.9613\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4671 - acc: 0.9655\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4607 - acc: 0.9632\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4517 - acc: 0.9625\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4450 - acc: 0.9623\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4382 - acc: 0.9597\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4295 - acc: 0.9632\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4208 - acc: 0.9697\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4157 - acc: 0.9663\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4075 - acc: 0.9668\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4045 - acc: 0.9700\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3952 - acc: 0.9698\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3899 - acc: 0.9660\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3809 - acc: 0.9728\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3750 - acc: 0.9702\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3695 - acc: 0.9728\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3631 - acc: 0.9710\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3581 - acc: 0.9745\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3522 - acc: 0.9738\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3468 - acc: 0.9745\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3381 - acc: 0.9740\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3334 - acc: 0.9767\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3276 - acc: 0.9747\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3236 - acc: 0.9773\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3143 - acc: 0.9782\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3107 - acc: 0.9775\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3070 - acc: 0.9783\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3027 - acc: 0.9785\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2965 - acc: 0.9813\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2925 - acc: 0.9813\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2869 - acc: 0.9815\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2824 - acc: 0.9852\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2737 - acc: 0.9873\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2732 - acc: 0.9845\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2667 - acc: 0.9855\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2630 - acc: 0.9848\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2556 - acc: 0.9853\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2517 - acc: 0.9875\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2478 - acc: 0.9848\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2469 - acc: 0.9848\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2403 - acc: 0.9870\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2390 - acc: 0.9863\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2353 - acc: 0.9870\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2289 - acc: 0.9885\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2252 - acc: 0.9900\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2210 - acc: 0.9907\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2145 - acc: 0.990 - 0s 7ms/step - loss: 0.2162 - acc: 0.9900\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2126 - acc: 0.9893\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2114 - acc: 0.9907\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2073 - acc: 0.9908\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EBF93A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5534 - acc: 0.7200\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6907 - acc: 0.5448\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6551 - acc: 0.7968\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6322 - acc: 0.8618\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6122 - acc: 0.8833\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5946 - acc: 0.8992\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5783 - acc: 0.9162\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5649 - acc: 0.9185\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5507 - acc: 0.9318\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5384 - acc: 0.9372\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5251 - acc: 0.9383\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5133 - acc: 0.9380\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5011 - acc: 0.9428\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4909 - acc: 0.9388\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4808 - acc: 0.9415\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4694 - acc: 0.9438\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4606 - acc: 0.9423\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4489 - acc: 0.9522\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4419 - acc: 0.9518\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4313 - acc: 0.9518\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4216 - acc: 0.9515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4125 - acc: 0.9537\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4022 - acc: 0.9545\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3947 - acc: 0.9582\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3871 - acc: 0.9557\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3799 - acc: 0.9587\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3682 - acc: 0.9613\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3631 - acc: 0.9628\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3533 - acc: 0.9607\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3454 - acc: 0.9673\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3406 - acc: 0.9683\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3330 - acc: 0.9687\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3280 - acc: 0.9685\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3211 - acc: 0.9673\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3114 - acc: 0.9707\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3076 - acc: 0.9700\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3017 - acc: 0.9693\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2935 - acc: 0.9737\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2896 - acc: 0.9710\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2807 - acc: 0.9745\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2767 - acc: 0.9748\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2681 - acc: 0.9782\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2631 - acc: 0.9768\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2592 - acc: 0.9805\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2529 - acc: 0.9785\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2478 - acc: 0.9815\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2446 - acc: 0.9823\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2402 - acc: 0.9803\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2347 - acc: 0.9823\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2291 - acc: 0.9825\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2267 - acc: 0.9832\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2183 - acc: 0.9845\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2153 - acc: 0.9848\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2119 - acc: 0.9862\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2039 - acc: 0.9868\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2032 - acc: 0.9877\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1958 - acc: 0.9903\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1958 - acc: 0.9877\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1931 - acc: 0.9870\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1867 - acc: 0.9855\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1832 - acc: 0.9877\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1795 - acc: 0.9878\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1754 - acc: 0.9907\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1708 - acc: 0.9907\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1693 - acc: 0.9902\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1658 - acc: 0.9893\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1619 - acc: 0.9922\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1576 - acc: 0.9928\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1543 - acc: 0.9893\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1507 - acc: 0.9887\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1480 - acc: 0.9900\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC469670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5563 - acc: 0.7050\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6930 - acc: 0.5095\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6768 - acc: 0.7007\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6645 - acc: 0.7895\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6530 - acc: 0.8275\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6423 - acc: 0.8812\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6315 - acc: 0.9030\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6204 - acc: 0.9230\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6108 - acc: 0.9348\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6011 - acc: 0.9373\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5907 - acc: 0.9445\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5809 - acc: 0.9513\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5703 - acc: 0.9582\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5598 - acc: 0.9558\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5532 - acc: 0.9572\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5424 - acc: 0.9617\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5332 - acc: 0.9628\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5250 - acc: 0.9622\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5161 - acc: 0.9618\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5095 - acc: 0.9667\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4997 - acc: 0.9662\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4921 - acc: 0.9707\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4840 - acc: 0.9713\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4755 - acc: 0.9747\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4684 - acc: 0.9747\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4613 - acc: 0.9790\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4515 - acc: 0.9783\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4476 - acc: 0.9807\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4372 - acc: 0.9793\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4294 - acc: 0.9798\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4231 - acc: 0.9817\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4168 - acc: 0.9853\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4096 - acc: 0.9853\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4038 - acc: 0.9832\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3975 - acc: 0.9853\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3897 - acc: 0.9873\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3849 - acc: 0.9848\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3783 - acc: 0.9860\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3712 - acc: 0.9842\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3627 - acc: 0.9883\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3583 - acc: 0.9875\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3520 - acc: 0.9870\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3457 - acc: 0.9883\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3416 - acc: 0.9900\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3351 - acc: 0.9922\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3301 - acc: 0.9908\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3237 - acc: 0.9915\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3179 - acc: 0.9928\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3137 - acc: 0.9917\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3053 - acc: 0.9922\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3034 - acc: 0.9930\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2974 - acc: 0.9917\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2944 - acc: 0.9917\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2875 - acc: 0.9930\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2794 - acc: 0.9930\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2797 - acc: 0.9923\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2706 - acc: 0.9923\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2687 - acc: 0.9932\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2652 - acc: 0.9938\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2562 - acc: 0.9938\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2527 - acc: 0.9945\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2497 - acc: 0.9945\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2445 - acc: 0.9945\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2397 - acc: 0.9945\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2360 - acc: 0.9932\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2317 - acc: 0.9938\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2303 - acc: 0.9938\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2197 - acc: 0.9960\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2202 - acc: 0.9968\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2141 - acc: 0.9983\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2127 - acc: 0.998 - 0s 7ms/step - loss: 0.2116 - acc: 0.9977\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED977790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5645 - acc: 0.7150\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6913 - acc: 0.5237\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6781 - acc: 0.7435\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6679 - acc: 0.8040\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6581 - acc: 0.8443\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6477 - acc: 0.8640\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6390 - acc: 0.8858\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6297 - acc: 0.9028\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6203 - acc: 0.9115\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6116 - acc: 0.9140\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6020 - acc: 0.9205\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5934 - acc: 0.9353\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5851 - acc: 0.9405\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5747 - acc: 0.9500\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5660 - acc: 0.9517\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5589 - acc: 0.9523\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5501 - acc: 0.9490\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5407 - acc: 0.9560\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5337 - acc: 0.9525\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5255 - acc: 0.9562\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5177 - acc: 0.9592\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5074 - acc: 0.9613\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5011 - acc: 0.9602\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4936 - acc: 0.9612\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4856 - acc: 0.9610\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4779 - acc: 0.9632\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4695 - acc: 0.9652\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4645 - acc: 0.9655\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4545 - acc: 0.9648\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4486 - acc: 0.9663\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4418 - acc: 0.9678\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4337 - acc: 0.9677\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4241 - acc: 0.9725\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4199 - acc: 0.9678\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4122 - acc: 0.9728\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4060 - acc: 0.9682\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3971 - acc: 0.9720\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3922 - acc: 0.9710\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3841 - acc: 0.9760\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3776 - acc: 0.9775\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3707 - acc: 0.9773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3662 - acc: 0.9748\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3556 - acc: 0.9762\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3512 - acc: 0.9762\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3442 - acc: 0.9762\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3388 - acc: 0.9755\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3318 - acc: 0.9762\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3267 - acc: 0.9777\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3188 - acc: 0.9820\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3133 - acc: 0.9800\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3097 - acc: 0.9828\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3012 - acc: 0.9828\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2987 - acc: 0.9802\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2928 - acc: 0.9835\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2859 - acc: 0.9817\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2810 - acc: 0.9862\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2761 - acc: 0.9855\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2707 - acc: 0.9868\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2643 - acc: 0.9862\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2600 - acc: 0.9868\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2569 - acc: 0.9862\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2504 - acc: 0.9863\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2457 - acc: 0.9877\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2400 - acc: 0.9877\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2352 - acc: 0.9892\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2320 - acc: 0.9877\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2301 - acc: 0.9885\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2237 - acc: 0.9885\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2181 - acc: 0.9878\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2132 - acc: 0.9892\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2094 - acc: 0.9878\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F231C670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5606 - acc: 0.7088\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6903 - acc: 0.5557\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6653 - acc: 0.7680\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6475 - acc: 0.8517\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6333 - acc: 0.8957\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6209 - acc: 0.8993\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6081 - acc: 0.9132\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5978 - acc: 0.9183\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5860 - acc: 0.9213\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5766 - acc: 0.9218\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5658 - acc: 0.9268\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5546 - acc: 0.9263\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5450 - acc: 0.9355\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5365 - acc: 0.9435\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5280 - acc: 0.9407\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5174 - acc: 0.9448\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5098 - acc: 0.9420\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5007 - acc: 0.9477\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4921 - acc: 0.9520\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4831 - acc: 0.9493\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4749 - acc: 0.9527\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4673 - acc: 0.9577\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4607 - acc: 0.9593\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4529 - acc: 0.9595\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4447 - acc: 0.9595\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4362 - acc: 0.9608\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4285 - acc: 0.9645\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4190 - acc: 0.9637\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4132 - acc: 0.9660\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4077 - acc: 0.9662\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3992 - acc: 0.9648\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3936 - acc: 0.9628\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3834 - acc: 0.9718\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3784 - acc: 0.9692\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3724 - acc: 0.9680\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3668 - acc: 0.9708\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3601 - acc: 0.9742\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3532 - acc: 0.9713\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3476 - acc: 0.9715\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3403 - acc: 0.9730\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3363 - acc: 0.9768\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3293 - acc: 0.9733\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3229 - acc: 0.9792\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3165 - acc: 0.9805\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3141 - acc: 0.9785\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3084 - acc: 0.9792\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3046 - acc: 0.9780\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2961 - acc: 0.9785\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2909 - acc: 0.9807\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2848 - acc: 0.9828\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2812 - acc: 0.9810\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2768 - acc: 0.9817\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2698 - acc: 0.9837\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2651 - acc: 0.9807\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2594 - acc: 0.9845\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2562 - acc: 0.9838\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2548 - acc: 0.9810\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2490 - acc: 0.9840\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2436 - acc: 0.9873\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2376 - acc: 0.9848\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2350 - acc: 0.9848\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2305 - acc: 0.9870\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2263 - acc: 0.9870\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2208 - acc: 0.9870\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2183 - acc: 0.9878\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2139 - acc: 0.9892\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2115 - acc: 0.9878\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2070 - acc: 0.9885\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2050 - acc: 0.9900\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2009 - acc: 0.9908\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1952 - acc: 0.9917\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D307E820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5482 - acc: 0.7125\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6950 - acc: 0.4788\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6761 - acc: 0.7465\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6633 - acc: 0.8400\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6522 - acc: 0.8673\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6414 - acc: 0.9018\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6320 - acc: 0.9122\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6229 - acc: 0.9175\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6134 - acc: 0.9328\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6050 - acc: 0.9277\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5970 - acc: 0.9287\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5874 - acc: 0.9372\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5800 - acc: 0.9410\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5715 - acc: 0.9427\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5630 - acc: 0.9507\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5550 - acc: 0.9475\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5468 - acc: 0.9513\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5405 - acc: 0.9493\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5317 - acc: 0.9498\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5253 - acc: 0.9443\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5158 - acc: 0.9562\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5119 - acc: 0.9495\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5004 - acc: 0.9557\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4945 - acc: 0.9538\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4885 - acc: 0.9562\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4817 - acc: 0.9520\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4725 - acc: 0.9560\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4672 - acc: 0.9540\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4591 - acc: 0.9547\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4530 - acc: 0.9547\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4463 - acc: 0.9528\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4372 - acc: 0.9602\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4313 - acc: 0.9605\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4256 - acc: 0.9612\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4187 - acc: 0.9612\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4108 - acc: 0.9635\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4074 - acc: 0.9647\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3992 - acc: 0.9647\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3963 - acc: 0.9632\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3886 - acc: 0.9638\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3843 - acc: 0.9667\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3744 - acc: 0.9682\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3694 - acc: 0.9653\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3665 - acc: 0.9633\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3577 - acc: 0.9650\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3551 - acc: 0.9640\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3461 - acc: 0.9677\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3435 - acc: 0.9700\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3387 - acc: 0.9700\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3310 - acc: 0.9715\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3271 - acc: 0.9722\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3232 - acc: 0.9723\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3175 - acc: 0.9738\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3126 - acc: 0.9762\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3074 - acc: 0.9755\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3027 - acc: 0.9772\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2967 - acc: 0.9805\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2941 - acc: 0.9785\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2896 - acc: 0.9792\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2835 - acc: 0.9802\n",
      "Epoch 60/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2777 - acc: 0.9822\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2740 - acc: 0.9845\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2699 - acc: 0.9825\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2678 - acc: 0.9825\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2613 - acc: 0.9825\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2574 - acc: 0.9838\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2512 - acc: 0.9832\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2524 - acc: 0.9812\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2432 - acc: 0.9845\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2407 - acc: 0.9825\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2356 - acc: 0.9852\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED9779D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5616 - acc: 0.6925\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6931 - acc: 0.4830\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6821 - acc: 0.5440\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6731 - acc: 0.5975\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6646 - acc: 0.6928\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6553 - acc: 0.7060\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6456 - acc: 0.7942\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6381 - acc: 0.8135\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6307 - acc: 0.8355\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6214 - acc: 0.8495\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6114 - acc: 0.8787\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6036 - acc: 0.8765\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5953 - acc: 0.8918\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5856 - acc: 0.9047\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5767 - acc: 0.9092\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5720 - acc: 0.9195\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5636 - acc: 0.9183\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5526 - acc: 0.9208\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5462 - acc: 0.9275\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5367 - acc: 0.9323\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5300 - acc: 0.9400\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5241 - acc: 0.9390\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5166 - acc: 0.9433\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5070 - acc: 0.9430\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5017 - acc: 0.9430\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4931 - acc: 0.9468\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4830 - acc: 0.9498\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4748 - acc: 0.9535\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4681 - acc: 0.9568\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4667 - acc: 0.9620\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4607 - acc: 0.9618\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4531 - acc: 0.9623\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4450 - acc: 0.9668\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4358 - acc: 0.9745\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4303 - acc: 0.9767\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4252 - acc: 0.9750\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4204 - acc: 0.9753\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4116 - acc: 0.9752\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4063 - acc: 0.9753\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4036 - acc: 0.9760\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3937 - acc: 0.9747\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3902 - acc: 0.9827\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3847 - acc: 0.9828\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3805 - acc: 0.9837\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3728 - acc: 0.9817\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3675 - acc: 0.9840\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3632 - acc: 0.9875\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3568 - acc: 0.9877\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3505 - acc: 0.9892\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3457 - acc: 0.9892\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3387 - acc: 0.9892\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3358 - acc: 0.9907\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3298 - acc: 0.9900\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3235 - acc: 0.9907\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3167 - acc: 0.9900\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3165 - acc: 0.9913\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3077 - acc: 0.9910\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3046 - acc: 0.9928\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3011 - acc: 0.9910\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2911 - acc: 0.9917\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2900 - acc: 0.9932\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2819 - acc: 0.9952\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2807 - acc: 0.9953\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2767 - acc: 0.9938\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2672 - acc: 0.9960\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2677 - acc: 0.9955\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2615 - acc: 0.9953\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2567 - acc: 0.9947\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2488 - acc: 0.9962\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2485 - acc: 0.9955\n",
      "Epoch 70/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2427 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F22D5F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6383 - acc: 0.6700\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 0.6926 - acc: 0.5145\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6794 - acc: 0.5150\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6679 - acc: 0.5117\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6540 - acc: 0.5187\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6426 - acc: 0.5658\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6295 - acc: 0.6448\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6159 - acc: 0.6785\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6069 - acc: 0.7310\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5928 - acc: 0.7267\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5802 - acc: 0.7728\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5727 - acc: 0.7918\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5609 - acc: 0.8043\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5514 - acc: 0.8218\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5466 - acc: 0.8242\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5334 - acc: 0.8235\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5255 - acc: 0.8403\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5169 - acc: 0.8518\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5091 - acc: 0.8677\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5011 - acc: 0.8720\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4942 - acc: 0.8768\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4898 - acc: 0.8828\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4788 - acc: 0.8870\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4730 - acc: 0.9005\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4663 - acc: 0.9012\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4608 - acc: 0.9065\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4538 - acc: 0.9108\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4497 - acc: 0.9110\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4457 - acc: 0.9122\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4368 - acc: 0.9183\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4290 - acc: 0.9218\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4308 - acc: 0.9317\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4218 - acc: 0.9288\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4171 - acc: 0.9333\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4138 - acc: 0.9348\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4066 - acc: 0.9383\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4092 - acc: 0.9358\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4047 - acc: 0.9420\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3963 - acc: 0.9395\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3916 - acc: 0.9422\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3920 - acc: 0.9423\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3872 - acc: 0.9420\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3807 - acc: 0.9448\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3817 - acc: 0.9528\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3793 - acc: 0.9525\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3708 - acc: 0.9607\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3734 - acc: 0.9658\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3646 - acc: 0.9653\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3656 - acc: 0.9685\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3621 - acc: 0.9680\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3596 - acc: 0.9688\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3537 - acc: 0.9700\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3487 - acc: 0.9735\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3443 - acc: 0.9768\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3499 - acc: 0.9753\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3404 - acc: 0.9742\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3348 - acc: 0.9790\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3363 - acc: 0.9770\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3348 - acc: 0.9790\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3313 - acc: 0.9792\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3239 - acc: 0.9785\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3232 - acc: 0.9772\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3191 - acc: 0.9813\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3206 - acc: 0.9807\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3175 - acc: 0.9800\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3138 - acc: 0.9820\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3153 - acc: 0.9858\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3099 - acc: 0.9883\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3062 - acc: 0.9870\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3037 - acc: 0.9860\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3084 - acc: 0.9893\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D6716700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8061 - acc: 0.5962\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6970 - acc: 0.4680\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6702 - acc: 0.7717\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6494 - acc: 0.8668\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6316 - acc: 0.8945\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6161 - acc: 0.9155\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6007 - acc: 0.9167\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5855 - acc: 0.9305\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5710 - acc: 0.9430\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5572 - acc: 0.9502\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5439 - acc: 0.9537\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5316 - acc: 0.9555\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5188 - acc: 0.9590\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5051 - acc: 0.9630\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4934 - acc: 0.9638\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4808 - acc: 0.9690\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4693 - acc: 0.9677\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4576 - acc: 0.9678\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4463 - acc: 0.9672\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4363 - acc: 0.9678\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4251 - acc: 0.9695\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4141 - acc: 0.9723\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4045 - acc: 0.9732\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3934 - acc: 0.9750\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3822 - acc: 0.9767\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3721 - acc: 0.9785\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3636 - acc: 0.9785\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3565 - acc: 0.9772\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3461 - acc: 0.9785\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3348 - acc: 0.9843\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3272 - acc: 0.9810\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3189 - acc: 0.9815\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3111 - acc: 0.9810\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3015 - acc: 0.9862\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2928 - acc: 0.9848\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2849 - acc: 0.9898\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2780 - acc: 0.9900\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2715 - acc: 0.9900\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2634 - acc: 0.9902\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2562 - acc: 0.9908\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2485 - acc: 0.9945\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2420 - acc: 0.9923\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2352 - acc: 0.9952\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2292 - acc: 0.9953\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2205 - acc: 0.9947\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2161 - acc: 0.9947\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2092 - acc: 0.9960\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2043 - acc: 0.9955\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1983 - acc: 0.9955\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1933 - acc: 0.9955\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1861 - acc: 0.9962\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1805 - acc: 0.9970\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1777 - acc: 0.9962\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1707 - acc: 0.9983\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1657 - acc: 0.9977\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1592 - acc: 0.9970\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1566 - acc: 0.9977\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1529 - acc: 0.9977\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1483 - acc: 0.9970\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1428 - acc: 0.9970\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1401 - acc: 0.9985\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1363 - acc: 0.9977\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1308 - acc: 0.9992\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1275 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1234 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1195 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1165 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1140 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1093 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1058 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1033 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F25CB670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5806 - acc: 0.7113\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6921 - acc: 0.5185\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6708 - acc: 0.6888\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6542 - acc: 0.8030\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6377 - acc: 0.8563\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6220 - acc: 0.8752\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6078 - acc: 0.9128\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5917 - acc: 0.9230\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5775 - acc: 0.9302\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5635 - acc: 0.9362\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5495 - acc: 0.9423\n",
      "Epoch 11/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5354 - acc: 0.9420\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5232 - acc: 0.9437\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5082 - acc: 0.9500\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4957 - acc: 0.9535\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4819 - acc: 0.9525\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4694 - acc: 0.9553\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4647 - acc: 0.948 - 0s 8ms/step - loss: 0.4598 - acc: 0.9535\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4468 - acc: 0.9532\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4323 - acc: 0.9588\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4228 - acc: 0.9593\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4109 - acc: 0.9620\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4005 - acc: 0.9628\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3930 - acc: 0.9620\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3830 - acc: 0.9610\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3693 - acc: 0.9678\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3622 - acc: 0.9642\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3517 - acc: 0.9670\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3414 - acc: 0.9742\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3323 - acc: 0.9732\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3238 - acc: 0.9755\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3149 - acc: 0.9775\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3062 - acc: 0.9813\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2965 - acc: 0.9813\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2890 - acc: 0.9873\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2838 - acc: 0.9842\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2752 - acc: 0.9870\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2682 - acc: 0.9857\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2608 - acc: 0.9885\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2531 - acc: 0.9878\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2461 - acc: 0.9907\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2377 - acc: 0.9915\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2322 - acc: 0.9907\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2240 - acc: 0.9915\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2203 - acc: 0.9908\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2141 - acc: 0.9915\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2089 - acc: 0.9902\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2032 - acc: 0.9908\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1966 - acc: 0.9908\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1907 - acc: 0.9922\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1875 - acc: 0.9895\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1803 - acc: 0.9902\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1756 - acc: 0.9917\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1717 - acc: 0.9930\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1670 - acc: 0.9908\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1604 - acc: 0.9937\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1568 - acc: 0.9922\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1523 - acc: 0.9930\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1493 - acc: 0.9908\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1427 - acc: 0.9900\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1389 - acc: 0.9943\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1379 - acc: 0.9923\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1329 - acc: 0.9932\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1299 - acc: 0.9917\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1266 - acc: 0.9932\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1215 - acc: 0.9938\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1165 - acc: 0.9943\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1133 - acc: 0.9938\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1097 - acc: 0.9938\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1077 - acc: 0.9947\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1046 - acc: 0.9945\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EBF60B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5771 - acc: 0.6938\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6932 - acc: 0.4892\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6901 - acc: 0.6865\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6858 - acc: 0.7625\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6804 - acc: 0.8557\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6731 - acc: 0.9105\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6645 - acc: 0.9412\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6554 - acc: 0.9597\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6461 - acc: 0.9723\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6364 - acc: 0.9820\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6263 - acc: 0.9823\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6154 - acc: 0.9860\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6054 - acc: 0.9870\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5948 - acc: 0.9868\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5831 - acc: 0.9890\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5725 - acc: 0.9892\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5606 - acc: 0.9905\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5487 - acc: 0.9905\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5374 - acc: 0.9917\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5246 - acc: 0.9910\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5121 - acc: 0.9922\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4997 - acc: 0.9908\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4866 - acc: 0.9930\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4743 - acc: 0.9923\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4619 - acc: 0.9923\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4471 - acc: 0.9900\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4345 - acc: 0.9938\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4212 - acc: 0.9952\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4085 - acc: 0.9968\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3950 - acc: 0.9962\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3821 - acc: 0.9977\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3698 - acc: 0.9977\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3563 - acc: 0.9977\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3419 - acc: 0.9977\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3304 - acc: 0.9977\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3187 - acc: 0.9977\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3044 - acc: 0.9970\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2913 - acc: 0.9977\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2803 - acc: 0.9970\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2665 - acc: 0.9983\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2550 - acc: 0.9983\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2441 - acc: 0.9970\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2330 - acc: 0.9977\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2225 - acc: 0.9977\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2120 - acc: 0.9977\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2014 - acc: 0.9977\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1920 - acc: 0.9970\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1815 - acc: 0.9977\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1720 - acc: 0.9992\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1646 - acc: 1.0000\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1544 - acc: 0.9985\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1468 - acc: 1.0000\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1394 - acc: 1.0000\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1316 - acc: 1.0000\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1220 - acc: 1.0000\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1160 - acc: 1.0000\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1107 - acc: 1.0000\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1044 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0974 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0918 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0867 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0821 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0766 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0731 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0671 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0642 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0598 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0559 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0532 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0494 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0470 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0FB9BD280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6103 - acc: 0.7188\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6933 - acc: 0.4792\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6890 - acc: 0.6625\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6851 - acc: 0.8130\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6804 - acc: 0.8638\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6755 - acc: 0.8782\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6698 - acc: 0.9035\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6643 - acc: 0.9198\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6583 - acc: 0.9388\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6521 - acc: 0.9462\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6453 - acc: 0.9415\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6378 - acc: 0.9548\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6303 - acc: 0.9598\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6221 - acc: 0.9568\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6146 - acc: 0.9593\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6061 - acc: 0.9640\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5965 - acc: 0.9695\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5885 - acc: 0.9712\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5798 - acc: 0.9743\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5695 - acc: 0.9747\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5598 - acc: 0.9725\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5507 - acc: 0.9755\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5399 - acc: 0.9788\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5309 - acc: 0.9802\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5200 - acc: 0.9780\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5106 - acc: 0.9772\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4990 - acc: 0.9815\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4889 - acc: 0.9828\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4766 - acc: 0.9822\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4705 - acc: 0.9817\n",
      "Epoch 30/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4559 - acc: 0.9858\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4481 - acc: 0.9855\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4376 - acc: 0.9873\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4263 - acc: 0.9853\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4169 - acc: 0.9842\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4057 - acc: 0.9862\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3959 - acc: 0.9862\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3851 - acc: 0.9875\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3758 - acc: 0.9883\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3668 - acc: 0.9862\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3551 - acc: 0.9883\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3465 - acc: 0.9877\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3347 - acc: 0.9898\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3258 - acc: 0.9878\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3186 - acc: 0.9898\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3103 - acc: 0.9863\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2993 - acc: 0.9890\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2909 - acc: 0.9885\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2826 - acc: 0.9892\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2730 - acc: 0.9885\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2643 - acc: 0.9898\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2554 - acc: 0.9907\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2491 - acc: 0.9885\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2403 - acc: 0.9907\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2318 - acc: 0.9915\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2266 - acc: 0.9923\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2177 - acc: 0.9938\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2102 - acc: 0.9938\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2036 - acc: 0.9938\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1956 - acc: 0.9967\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1908 - acc: 0.9953\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1828 - acc: 0.9945\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1796 - acc: 0.9932\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1702 - acc: 0.9932\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1673 - acc: 0.9940\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1577 - acc: 0.9937\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1533 - acc: 0.9960\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1463 - acc: 0.9945\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1424 - acc: 0.9945\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1372 - acc: 0.9938\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1310 - acc: 0.9947\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED7F98B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5958 - acc: 0.7188\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6939 - acc: 0.5027\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6808 - acc: 0.7253\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6673 - acc: 0.8267\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6532 - acc: 0.8850\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6375 - acc: 0.8872\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6219 - acc: 0.9118\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6069 - acc: 0.9210\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5894 - acc: 0.9303\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5747 - acc: 0.9288\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5594 - acc: 0.9380\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5426 - acc: 0.9447\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5274 - acc: 0.9465\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5112 - acc: 0.9525\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4974 - acc: 0.9522\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4822 - acc: 0.9577\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4693 - acc: 0.9607\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4541 - acc: 0.9582\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4404 - acc: 0.9662\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4251 - acc: 0.9683\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4120 - acc: 0.9657\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3997 - acc: 0.9705\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3881 - acc: 0.9723\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3737 - acc: 0.9743\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3646 - acc: 0.9802\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3521 - acc: 0.9802\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3387 - acc: 0.9835\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3260 - acc: 0.9842\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3189 - acc: 0.9788\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3073 - acc: 0.9795\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2961 - acc: 0.9822\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2849 - acc: 0.9853\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2757 - acc: 0.9898\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2671 - acc: 0.9885\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2581 - acc: 0.9887\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2489 - acc: 0.9922\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2394 - acc: 0.9907\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2305 - acc: 0.9930\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2224 - acc: 0.9968\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2169 - acc: 0.9962\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2080 - acc: 0.9968\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1987 - acc: 0.9983\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1935 - acc: 0.9970\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1867 - acc: 0.9970\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1806 - acc: 0.9970\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1737 - acc: 0.9970\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1673 - acc: 0.9983\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1590 - acc: 0.9977\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1555 - acc: 0.9970\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1489 - acc: 0.9977\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1442 - acc: 0.9977\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1376 - acc: 0.9985\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1338 - acc: 0.9985\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1274 - acc: 0.9985\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1234 - acc: 0.9985\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1183 - acc: 0.9992\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1148 - acc: 0.9992\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1108 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1074 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1026 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0986 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0947 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0912 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0885 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0852 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0809 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0784 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0763 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0740 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0708 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0683 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC3D98B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6262 - acc: 0.7088\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6933 - acc: 0.5275\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6605 - acc: 0.7700\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6357 - acc: 0.8523\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6109 - acc: 0.8943\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5882 - acc: 0.9167\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5691 - acc: 0.9277\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5481 - acc: 0.9388\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5277 - acc: 0.9487\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5098 - acc: 0.9522\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4934 - acc: 0.9522\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4781 - acc: 0.9635\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4618 - acc: 0.9638\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4472 - acc: 0.9663\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4328 - acc: 0.9670\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4190 - acc: 0.9673\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4060 - acc: 0.9687\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3917 - acc: 0.9722\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3792 - acc: 0.9730\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3667 - acc: 0.9730\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3562 - acc: 0.9763\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3450 - acc: 0.9777\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3335 - acc: 0.9835\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3229 - acc: 0.9852\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3136 - acc: 0.9872\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3047 - acc: 0.9863\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2933 - acc: 0.9915\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2846 - acc: 0.9907\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2762 - acc: 0.9900\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2690 - acc: 0.9900\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2575 - acc: 0.9922\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2498 - acc: 0.9923\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2436 - acc: 0.9930\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2377 - acc: 0.9932\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2303 - acc: 0.9925\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2217 - acc: 0.992 - 0s 10ms/step - loss: 0.2223 - acc: 0.9923\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2166 - acc: 0.9938\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2097 - acc: 0.9938\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2035 - acc: 0.9932\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1968 - acc: 0.9953\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1907 - acc: 0.9960\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1871 - acc: 0.9953\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1815 - acc: 0.9953\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1775 - acc: 0.9947\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1713 - acc: 0.9947\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1662 - acc: 0.9960\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1631 - acc: 0.9953\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1588 - acc: 0.9955\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1550 - acc: 0.9955\n",
      "Epoch 49/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1497 - acc: 0.9968\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1464 - acc: 0.9962\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1430 - acc: 0.9962\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1406 - acc: 0.9947\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1366 - acc: 0.9962\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1321 - acc: 0.9962\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1299 - acc: 0.9962\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1255 - acc: 0.9968\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1235 - acc: 0.9962\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1201 - acc: 0.9962\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1167 - acc: 0.9962\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1134 - acc: 0.9968\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1130 - acc: 0.9947\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1103 - acc: 0.9947\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1053 - acc: 0.9968\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1056 - acc: 0.9955\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1013 - acc: 0.9968\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1004 - acc: 0.9947\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0987 - acc: 0.9955\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0944 - acc: 0.9953\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0922 - acc: 0.9968\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0913 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F3675040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6286 - acc: 0.7125\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6932 - acc: 0.5138\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6814 - acc: 0.7752\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6722 - acc: 0.8657\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6632 - acc: 0.8982\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6545 - acc: 0.9288\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6450 - acc: 0.9363\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6358 - acc: 0.9492\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6279 - acc: 0.9455\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6179 - acc: 0.9483\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6097 - acc: 0.9460\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6001 - acc: 0.9522\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5924 - acc: 0.9568\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5839 - acc: 0.9518\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5750 - acc: 0.9620\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5660 - acc: 0.9600\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5573 - acc: 0.9578\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5494 - acc: 0.9563\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5408 - acc: 0.9607\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5319 - acc: 0.9578\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5233 - acc: 0.9622\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5146 - acc: 0.9653\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5073 - acc: 0.9675\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4991 - acc: 0.9672\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4907 - acc: 0.9683\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4830 - acc: 0.9700\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4751 - acc: 0.9710\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4662 - acc: 0.9717\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4590 - acc: 0.9768\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4492 - acc: 0.9760\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4420 - acc: 0.9782\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4397 - acc: 0.976 - 0s 9ms/step - loss: 0.4361 - acc: 0.9770\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4262 - acc: 0.9777\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4178 - acc: 0.9797\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4110 - acc: 0.9785\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4040 - acc: 0.9813\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3985 - acc: 0.9815\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3887 - acc: 0.9845\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3822 - acc: 0.9845\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3753 - acc: 0.9833\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3668 - acc: 0.9888\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.3613 - acc: 0.9840\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3540 - acc: 0.9862\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3482 - acc: 0.9842\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3419 - acc: 0.9848\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3350 - acc: 0.9862\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3279 - acc: 0.9855\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3201 - acc: 0.9875\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3146 - acc: 0.9855\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3083 - acc: 0.9870\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3031 - acc: 0.9857\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2966 - acc: 0.9883\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2895 - acc: 0.9870\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2837 - acc: 0.9877\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2791 - acc: 0.9863\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2735 - acc: 0.9857\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2679 - acc: 0.9870\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2635 - acc: 0.9900\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2565 - acc: 0.9885\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2506 - acc: 0.9907\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2452 - acc: 0.9900\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED834670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5575 - acc: 0.7287\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6899 - acc: 0.5250\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6715 - acc: 0.6382\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6584 - acc: 0.7065\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6463 - acc: 0.7560\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6327 - acc: 0.7885\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6213 - acc: 0.8285\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6078 - acc: 0.8537\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5987 - acc: 0.8802\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5866 - acc: 0.8872\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5762 - acc: 0.9047\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5634 - acc: 0.9175\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5551 - acc: 0.9207\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5453 - acc: 0.9217\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5347 - acc: 0.9295\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5266 - acc: 0.9267\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5158 - acc: 0.9323\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5051 - acc: 0.9362\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4964 - acc: 0.9357\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4868 - acc: 0.9427\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4779 - acc: 0.9398\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4696 - acc: 0.9418\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4572 - acc: 0.9433\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4506 - acc: 0.9422\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4424 - acc: 0.9503\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4328 - acc: 0.9452\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4272 - acc: 0.9492\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4172 - acc: 0.9542\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4076 - acc: 0.9550\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4009 - acc: 0.9543\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3922 - acc: 0.9537\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3856 - acc: 0.9512\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3796 - acc: 0.9542\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3695 - acc: 0.9577\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3630 - acc: 0.9580\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3563 - acc: 0.9593\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3476 - acc: 0.9622\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3404 - acc: 0.9632\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3314 - acc: 0.9652\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3288 - acc: 0.9692\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3211 - acc: 0.9720\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3144 - acc: 0.9738\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3067 - acc: 0.9755\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3004 - acc: 0.9755\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2937 - acc: 0.9790\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2900 - acc: 0.9748\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2816 - acc: 0.9785\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2765 - acc: 0.9787\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2670 - acc: 0.9805\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2619 - acc: 0.9823\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2569 - acc: 0.9830\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2540 - acc: 0.9830\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2454 - acc: 0.9830\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2385 - acc: 0.9823\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2371 - acc: 0.9825\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2275 - acc: 0.9845\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2282 - acc: 0.9857\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2208 - acc: 0.9863\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2172 - acc: 0.9877\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2111 - acc: 0.9892\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2077 - acc: 0.9872\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E8B4B8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5712 - acc: 0.7000\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6944 - acc: 0.4977\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6677 - acc: 0.7990\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6492 - acc: 0.8667\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6339 - acc: 0.8905\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6184 - acc: 0.9128\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6053 - acc: 0.9160\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5917 - acc: 0.9197\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5802 - acc: 0.9247\n",
      "Epoch 9/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5676 - acc: 0.9323\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5566 - acc: 0.9337\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5462 - acc: 0.9348\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5339 - acc: 0.9435\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5241 - acc: 0.9497\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5132 - acc: 0.9485\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5033 - acc: 0.9495\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4937 - acc: 0.9528\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4839 - acc: 0.9543\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4720 - acc: 0.9598\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4628 - acc: 0.9605\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4537 - acc: 0.9652\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4428 - acc: 0.9653\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4367 - acc: 0.9662\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4271 - acc: 0.9703\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4132 - acc: 0.976 - 0s 9ms/step - loss: 0.4165 - acc: 0.9703\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4104 - acc: 0.9657\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4004 - acc: 0.9692\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3932 - acc: 0.9685\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3834 - acc: 0.9672\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3768 - acc: 0.9687\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3685 - acc: 0.9693\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3617 - acc: 0.9707\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3532 - acc: 0.9707\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3469 - acc: 0.9722\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3390 - acc: 0.9738\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3311 - acc: 0.9745\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3277 - acc: 0.9710\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3162 - acc: 0.9767\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3127 - acc: 0.9725\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3044 - acc: 0.9765\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2997 - acc: 0.9738\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2919 - acc: 0.9753\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2842 - acc: 0.9790\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2816 - acc: 0.9800\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2714 - acc: 0.9800\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2667 - acc: 0.9807\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2610 - acc: 0.9808\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2533 - acc: 0.9843\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2522 - acc: 0.9838\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2453 - acc: 0.9847\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2421 - acc: 0.9855\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2326 - acc: 0.9868\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2286 - acc: 0.9875\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2270 - acc: 0.9863\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2190 - acc: 0.9877\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2146 - acc: 0.9863\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2104 - acc: 0.9892\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2045 - acc: 0.9870\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2016 - acc: 0.9900\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1965 - acc: 0.9893\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1904 - acc: 0.9928\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D307E5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5468 - acc: 0.7200\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6943 - acc: 0.5072\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6586 - acc: 0.7853\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6349 - acc: 0.8730\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6141 - acc: 0.8865\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5952 - acc: 0.8990\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5791 - acc: 0.9108\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5626 - acc: 0.9208\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5490 - acc: 0.9283\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5347 - acc: 0.9385\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5212 - acc: 0.9430\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5056 - acc: 0.948 - 0s 9ms/step - loss: 0.5080 - acc: 0.9435\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4982 - acc: 0.9507\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4878 - acc: 0.9517\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4720 - acc: 0.9535\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4631 - acc: 0.9532\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4491 - acc: 0.9545\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4421 - acc: 0.9518\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4294 - acc: 0.9558\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4195 - acc: 0.9565\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4097 - acc: 0.9547\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3992 - acc: 0.9562\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3893 - acc: 0.9563\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3797 - acc: 0.9555\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3728 - acc: 0.9575\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3654 - acc: 0.9593\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3548 - acc: 0.9628\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3467 - acc: 0.9622\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3398 - acc: 0.9672\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3336 - acc: 0.9700\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3212 - acc: 0.9718\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3170 - acc: 0.9700\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3099 - acc: 0.9673\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3011 - acc: 0.9715\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2937 - acc: 0.9708\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2885 - acc: 0.9723\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2828 - acc: 0.9730\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2739 - acc: 0.9770\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2665 - acc: 0.9777\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2633 - acc: 0.9762\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2546 - acc: 0.9783\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2464 - acc: 0.9777\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2432 - acc: 0.9813\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2368 - acc: 0.9800\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2324 - acc: 0.9817\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2283 - acc: 0.9810\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2215 - acc: 0.9867\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2167 - acc: 0.9847\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2120 - acc: 0.9848\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2049 - acc: 0.9867\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2014 - acc: 0.9855\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1964 - acc: 0.9882\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1928 - acc: 0.9863\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1872 - acc: 0.9885\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1822 - acc: 0.9885\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1805 - acc: 0.9893\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1728 - acc: 0.9913\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1696 - acc: 0.9920\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1676 - acc: 0.9893\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1603 - acc: 0.9898\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1581 - acc: 0.9915\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E8B4B0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5567 - acc: 0.7013\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6938 - acc: 0.4918\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6803 - acc: 0.7695\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6703 - acc: 0.8467\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6600 - acc: 0.8850\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6500 - acc: 0.9102\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6406 - acc: 0.9295\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6308 - acc: 0.9442\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6208 - acc: 0.9438\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6122 - acc: 0.9472\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6021 - acc: 0.9535\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5934 - acc: 0.9572\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5826 - acc: 0.9622\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5730 - acc: 0.9650\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5654 - acc: 0.9698\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5573 - acc: 0.9650\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5458 - acc: 0.9713\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5385 - acc: 0.9715\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5294 - acc: 0.9722\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5182 - acc: 0.9772\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5105 - acc: 0.9767\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5036 - acc: 0.9747\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4955 - acc: 0.9748\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4851 - acc: 0.9762\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4766 - acc: 0.976 - 0s 10ms/step - loss: 0.4773 - acc: 0.9762\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4693 - acc: 0.9768\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4614 - acc: 0.9755\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4541 - acc: 0.9747\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4461 - acc: 0.9747\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4371 - acc: 0.9748\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4306 - acc: 0.9785\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4201 - acc: 0.9768\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4135 - acc: 0.9782\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4058 - acc: 0.9757\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3981 - acc: 0.9777\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3906 - acc: 0.9812\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3862 - acc: 0.9813\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3783 - acc: 0.9793\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3696 - acc: 0.9807\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3648 - acc: 0.9823\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3557 - acc: 0.9823\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3494 - acc: 0.9838\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3432 - acc: 0.9825\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3372 - acc: 0.9832\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3288 - acc: 0.9855\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3234 - acc: 0.9855\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3181 - acc: 0.9875\n",
      "Epoch 47/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3119 - acc: 0.9870\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3089 - acc: 0.9872\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2982 - acc: 0.9905\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2910 - acc: 0.9890\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2883 - acc: 0.9887\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2816 - acc: 0.9893\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2753 - acc: 0.9907\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2692 - acc: 0.9900\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2643 - acc: 0.9913\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2579 - acc: 0.9907\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2517 - acc: 0.9920\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2478 - acc: 0.9893\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2440 - acc: 0.9893\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2374 - acc: 0.9907\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F22D54C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5623 - acc: 0.7250\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6958 - acc: 0.4803\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6819 - acc: 0.6163\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6721 - acc: 0.7143\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6635 - acc: 0.7912\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6540 - acc: 0.8397\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6454 - acc: 0.8758\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6353 - acc: 0.8808\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6255 - acc: 0.9113\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6167 - acc: 0.9262\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6066 - acc: 0.9312\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5980 - acc: 0.9430\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5884 - acc: 0.9503\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5810 - acc: 0.9505\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5709 - acc: 0.9537\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5631 - acc: 0.9548\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5535 - acc: 0.9530\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5455 - acc: 0.9548\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5378 - acc: 0.9525\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5291 - acc: 0.9535\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5173 - acc: 0.9562\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5149 - acc: 0.9623\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5037 - acc: 0.9647\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4962 - acc: 0.9665\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4891 - acc: 0.9652\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4811 - acc: 0.9675\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4731 - acc: 0.9672\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4665 - acc: 0.9702\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4563 - acc: 0.9718\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4523 - acc: 0.9737\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4461 - acc: 0.9718\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4378 - acc: 0.9752\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4323 - acc: 0.9733\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4230 - acc: 0.9752\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4177 - acc: 0.9732\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4138 - acc: 0.9742\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4029 - acc: 0.9747\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3994 - acc: 0.9742\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3910 - acc: 0.9790\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3872 - acc: 0.9763\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3764 - acc: 0.9797\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3703 - acc: 0.9785\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3681 - acc: 0.9800\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3599 - acc: 0.9785\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3541 - acc: 0.9808\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3500 - acc: 0.9795\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3412 - acc: 0.9828\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3391 - acc: 0.9815\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3351 - acc: 0.982 - 0s 8ms/step - loss: 0.3334 - acc: 0.9815\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3257 - acc: 0.9815\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3218 - acc: 0.9795\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3194 - acc: 0.9802\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3091 - acc: 0.9823\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3090 - acc: 0.9808\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2988 - acc: 0.9843\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2950 - acc: 0.9830\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2919 - acc: 0.9823\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2872 - acc: 0.9823\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2842 - acc: 0.9817\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2766 - acc: 0.9843\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2736 - acc: 0.9847\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E897C940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5940 - acc: 0.6988\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6917 - acc: 0.5177\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6603 - acc: 0.7708\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6382 - acc: 0.8455\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6206 - acc: 0.8783\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6037 - acc: 0.8952\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5889 - acc: 0.9045\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5753 - acc: 0.9113\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5626 - acc: 0.9232\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5494 - acc: 0.9335\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5368 - acc: 0.9358\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5258 - acc: 0.9417\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5158 - acc: 0.9447\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5010 - acc: 0.9463\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4897 - acc: 0.9505\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4819 - acc: 0.9507\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4712 - acc: 0.9495\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4617 - acc: 0.9543\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4508 - acc: 0.9580\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4407 - acc: 0.9595\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4305 - acc: 0.9602\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4232 - acc: 0.9642\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4143 - acc: 0.9653\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4058 - acc: 0.9703\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3954 - acc: 0.9670\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3885 - acc: 0.9708\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3799 - acc: 0.9730\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3711 - acc: 0.9702\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3626 - acc: 0.9743\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3559 - acc: 0.9753\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3468 - acc: 0.9760\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3417 - acc: 0.9768\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3349 - acc: 0.9747\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3284 - acc: 0.9735\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3199 - acc: 0.9735\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3117 - acc: 0.9773\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3067 - acc: 0.9742\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2988 - acc: 0.9747\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2901 - acc: 0.9767\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2845 - acc: 0.9793\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2780 - acc: 0.9792\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2737 - acc: 0.9823\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2655 - acc: 0.9837\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2618 - acc: 0.9818\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2552 - acc: 0.9847\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2496 - acc: 0.9855\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2462 - acc: 0.9855\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2394 - acc: 0.9875\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2327 - acc: 0.9875\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2297 - acc: 0.9870\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2229 - acc: 0.9893\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2179 - acc: 0.9900\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2151 - acc: 0.9887\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2073 - acc: 0.9943\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2071 - acc: 0.9887\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2011 - acc: 0.9937\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1948 - acc: 0.9930\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1881 - acc: 0.9930\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1861 - acc: 0.9910\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1789 - acc: 0.9923\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1778 - acc: 0.9930\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDCE43A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5490 - acc: 0.7138\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6891 - acc: 0.5510\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6634 - acc: 0.8007\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6449 - acc: 0.8682\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6274 - acc: 0.8868\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6143 - acc: 0.9033\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6011 - acc: 0.9093\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5894 - acc: 0.9133\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5758 - acc: 0.9255\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5640 - acc: 0.9318\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5523 - acc: 0.9360\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5433 - acc: 0.9380\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5296 - acc: 0.9405\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5197 - acc: 0.9473\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5099 - acc: 0.9440\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4993 - acc: 0.9485\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4904 - acc: 0.9463\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4789 - acc: 0.9470\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4704 - acc: 0.9492\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4601 - acc: 0.9537\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4507 - acc: 0.9525\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4437 - acc: 0.9563\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4325 - acc: 0.9555\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4248 - acc: 0.9583\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4143 - acc: 0.9627\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4080 - acc: 0.9580\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3975 - acc: 0.9620\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3928 - acc: 0.9587\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3816 - acc: 0.9620\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3749 - acc: 0.9587\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3667 - acc: 0.9623\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.3559 - acc: 0.9652\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3538 - acc: 0.9633\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3470 - acc: 0.9613\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3367 - acc: 0.9673\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3290 - acc: 0.9640\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3221 - acc: 0.9660\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3161 - acc: 0.9683\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3086 - acc: 0.9690\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3017 - acc: 0.9750\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2980 - acc: 0.9790\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2896 - acc: 0.9797\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2842 - acc: 0.9798\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2811 - acc: 0.9757\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2668 - acc: 0.984 - 0s 10ms/step - loss: 0.2707 - acc: 0.9797\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2645 - acc: 0.9815\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2630 - acc: 0.9845\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2588 - acc: 0.9853\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2501 - acc: 0.9832\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2442 - acc: 0.9858\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2401 - acc: 0.9840\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2328 - acc: 0.9840\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2312 - acc: 0.9847\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2232 - acc: 0.9855\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2169 - acc: 0.9882\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2146 - acc: 0.9875\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2115 - acc: 0.9855\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2055 - acc: 0.9868\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2010 - acc: 0.9855\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1965 - acc: 0.9862\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1939 - acc: 0.9877\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC588550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5552 - acc: 0.7013\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 0.6933 - acc: 0.4753\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6861 - acc: 0.7253\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6797 - acc: 0.8023\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6721 - acc: 0.8425\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6640 - acc: 0.8712\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6548 - acc: 0.8968\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6456 - acc: 0.9305\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6350 - acc: 0.9383\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6250 - acc: 0.9413\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6124 - acc: 0.9427\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6017 - acc: 0.9603\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5898 - acc: 0.9615\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5780 - acc: 0.9648\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5653 - acc: 0.9713\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5519 - acc: 0.9758\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5401 - acc: 0.9733\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5274 - acc: 0.9718\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5129 - acc: 0.9780\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4987 - acc: 0.9840\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4868 - acc: 0.9800\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4721 - acc: 0.9843\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4606 - acc: 0.9888\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4469 - acc: 0.9860\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4324 - acc: 0.9868\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4201 - acc: 0.9877\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4070 - acc: 0.9878\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3953 - acc: 0.9885\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3798 - acc: 0.9892\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3673 - acc: 0.9898\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3571 - acc: 0.9885\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3422 - acc: 0.9900\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3311 - acc: 0.9908\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3182 - acc: 0.9915\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3069 - acc: 0.9908\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2935 - acc: 0.9915\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2826 - acc: 0.9915\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2708 - acc: 0.9937\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2603 - acc: 0.9932\n",
      "Epoch 39/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2511 - acc: 0.9947\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2408 - acc: 0.9938\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2313 - acc: 0.9960\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2203 - acc: 0.9947\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2111 - acc: 0.9953\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2015 - acc: 0.9953\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1950 - acc: 0.9947\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1838 - acc: 0.9947\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1745 - acc: 0.9962\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1685 - acc: 0.9955\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1594 - acc: 0.9962\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1528 - acc: 0.9968\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1472 - acc: 0.9955\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1421 - acc: 0.9962\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1321 - acc: 0.9977\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1256 - acc: 0.9977\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1204 - acc: 0.9970\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1136 - acc: 0.9977\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1089 - acc: 0.9983\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1017 - acc: 0.9983\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0967 - acc: 0.9977\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0927 - acc: 0.9983\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E8ABAC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5745 - acc: 0.7125\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6933 - acc: 0.5075\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6868 - acc: 0.6715\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6816 - acc: 0.7112\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6755 - acc: 0.7720\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6690 - acc: 0.8480\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6627 - acc: 0.9033\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6562 - acc: 0.8883\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6483 - acc: 0.9190\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6407 - acc: 0.9330\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6336 - acc: 0.9408\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6240 - acc: 0.9385\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6171 - acc: 0.9538\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6072 - acc: 0.9543\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5992 - acc: 0.9585\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5892 - acc: 0.9565\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5801 - acc: 0.9622\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5709 - acc: 0.9668\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5588 - acc: 0.9702\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5490 - acc: 0.9717\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5373 - acc: 0.9732\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5267 - acc: 0.9753\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5165 - acc: 0.9767\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5026 - acc: 0.9785\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4908 - acc: 0.9807\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4788 - acc: 0.9785\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4683 - acc: 0.9800\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4553 - acc: 0.9800\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4433 - acc: 0.9808\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4307 - acc: 0.9837\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4207 - acc: 0.9858\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4075 - acc: 0.9838\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3948 - acc: 0.9860\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3841 - acc: 0.9853\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3712 - acc: 0.9860\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3606 - acc: 0.9883\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3502 - acc: 0.9877\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3369 - acc: 0.9877\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3247 - acc: 0.9897\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3155 - acc: 0.9878\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3007 - acc: 0.9905\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2926 - acc: 0.9890\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2821 - acc: 0.9900\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2724 - acc: 0.9887\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2610 - acc: 0.9908\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2505 - acc: 0.9913\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2415 - acc: 0.9893\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2298 - acc: 0.9907\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2228 - acc: 0.9902\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2142 - acc: 0.9908\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2044 - acc: 0.9908\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1948 - acc: 0.9908\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1875 - acc: 0.9923\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1773 - acc: 0.9923\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1690 - acc: 0.9928\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1633 - acc: 0.9952\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1531 - acc: 0.9937\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1477 - acc: 0.9945\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1407 - acc: 0.9945\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1368 - acc: 0.9932\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.1291 - acc: 0.9917\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0DA7809D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5652 - acc: 0.6975\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6920 - acc: 0.5335\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6634 - acc: 0.8155\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6389 - acc: 0.8730\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.6165 - acc: 0.9027\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5950 - acc: 0.9182\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5754 - acc: 0.9277\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5546 - acc: 0.9378\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5335 - acc: 0.9455\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5152 - acc: 0.9427\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4977 - acc: 0.9472\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4791 - acc: 0.9523\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4609 - acc: 0.9548\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4453 - acc: 0.9600\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4276 - acc: 0.9627\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4128 - acc: 0.9652\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3956 - acc: 0.9683\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3815 - acc: 0.9728\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3661 - acc: 0.9737\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3543 - acc: 0.9738\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3414 - acc: 0.9770\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3288 - acc: 0.9785\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3129 - acc: 0.9792\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3013 - acc: 0.9807\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2915 - acc: 0.9845\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2793 - acc: 0.9837\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2690 - acc: 0.9853\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2590 - acc: 0.9833\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2451 - acc: 0.9875\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2364 - acc: 0.9853\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2260 - acc: 0.9870\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2136 - acc: 0.9898\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2076 - acc: 0.9898\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1997 - acc: 0.9917\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1911 - acc: 0.9938\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1826 - acc: 0.9930\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1748 - acc: 0.9943\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1675 - acc: 0.9968\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1607 - acc: 0.9977\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1538 - acc: 0.9970\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1480 - acc: 0.9977\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1405 - acc: 0.9977\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1349 - acc: 0.9970\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1291 - acc: 0.9977\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1243 - acc: 0.9977\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1200 - acc: 0.9970\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1131 - acc: 0.9970\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1074 - acc: 0.9983\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1025 - acc: 0.9970\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0987 - acc: 0.9970\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0941 - acc: 0.9977\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0889 - acc: 0.9983\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0859 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0820 - acc: 1.0000\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0779 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0760 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0716 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0685 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0648 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0611 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0594 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F22D5820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6084 - acc: 0.7088\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6909 - acc: 0.5133\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6572 - acc: 0.7237\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.6305 - acc: 0.8337\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6063 - acc: 0.8798\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5823 - acc: 0.8927\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5620 - acc: 0.9088\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5407 - acc: 0.9210\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5188 - acc: 0.9343\n",
      "Epoch 9/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4989 - acc: 0.9470\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4804 - acc: 0.9458\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4657 - acc: 0.9485\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4490 - acc: 0.9460\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4333 - acc: 0.9490\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4129 - acc: 0.9567\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3991 - acc: 0.9600\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3840 - acc: 0.9598\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3674 - acc: 0.9688\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3515 - acc: 0.9660\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3412 - acc: 0.9677\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3268 - acc: 0.9708\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3124 - acc: 0.9753\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3041 - acc: 0.9772\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2897 - acc: 0.9800\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2796 - acc: 0.9773\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2668 - acc: 0.9802\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2561 - acc: 0.9823\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2462 - acc: 0.9830\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2375 - acc: 0.9797\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2260 - acc: 0.9853\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2178 - acc: 0.9840\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2087 - acc: 0.9883\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2007 - acc: 0.9878\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1892 - acc: 0.9935\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1843 - acc: 0.9895\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1769 - acc: 0.9895\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1703 - acc: 0.9922\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1585 - acc: 0.9928\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1551 - acc: 0.9915\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1480 - acc: 0.9937\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1443 - acc: 0.9915\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1358 - acc: 0.9930\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1331 - acc: 0.9910\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1255 - acc: 0.9923\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1196 - acc: 0.9922\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1140 - acc: 0.9930\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1106 - acc: 0.9923\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1058 - acc: 0.9900\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1030 - acc: 0.9923\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0960 - acc: 0.9923\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0933 - acc: 0.9893\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0875 - acc: 0.9923\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0857 - acc: 0.9930\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0811 - acc: 0.9945\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0777 - acc: 0.9953\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0742 - acc: 0.9960\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0721 - acc: 0.9960\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0693 - acc: 0.9938\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0667 - acc: 0.9945\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0636 - acc: 0.9953\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0615 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0FB9BDF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6063 - acc: 0.7075\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6928 - acc: 0.4965\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6860 - acc: 0.6100\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6777 - acc: 0.6943\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6683 - acc: 0.7783\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6581 - acc: 0.8178\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6466 - acc: 0.8592\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6363 - acc: 0.8878\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6228 - acc: 0.8928\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6074 - acc: 0.9068\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5956 - acc: 0.9383\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5784 - acc: 0.9330\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5628 - acc: 0.9633\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5483 - acc: 0.9635\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5318 - acc: 0.9703\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5132 - acc: 0.9752\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4993 - acc: 0.9770\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4825 - acc: 0.9808\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4647 - acc: 0.9832\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4455 - acc: 0.9848\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4300 - acc: 0.9848\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4115 - acc: 0.9890\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3939 - acc: 0.9885\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3777 - acc: 0.9893\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3598 - acc: 0.9943\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3423 - acc: 0.9923\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3237 - acc: 0.9915\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3083 - acc: 0.9917\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2929 - acc: 0.9938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2768 - acc: 0.9925\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2615 - acc: 0.9940\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2462 - acc: 0.9960\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2316 - acc: 0.9947\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2178 - acc: 0.9953\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2036 - acc: 0.9962\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1890 - acc: 0.9968\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1784 - acc: 0.9955\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1665 - acc: 0.9968\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1551 - acc: 0.9983\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1462 - acc: 1.0000\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1372 - acc: 1.0000\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1259 - acc: 1.0000\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1182 - acc: 1.0000\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1079 - acc: 1.0000\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1001 - acc: 1.0000\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0929 - acc: 1.0000\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0866 - acc: 1.0000\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0803 - acc: 1.0000\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0741 - acc: 1.0000\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0678 - acc: 1.0000\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0635 - acc: 1.0000\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0591 - acc: 1.0000\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0528 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0501 - acc: 1.0000\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0459 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0423 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0390 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0351 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0330 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0304 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0283 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EBFD7160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6856 - acc: 0.6963\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6932 - acc: 0.5225\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6841 - acc: 0.5247\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6757 - acc: 0.5280\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6650 - acc: 0.5432\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6537 - acc: 0.6218\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6408 - acc: 0.6833\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6270 - acc: 0.7448\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6119 - acc: 0.7965\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5988 - acc: 0.8245\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5809 - acc: 0.8473\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5639 - acc: 0.8658\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5477 - acc: 0.8842\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5313 - acc: 0.8948\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5150 - acc: 0.9113\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4974 - acc: 0.9162\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4835 - acc: 0.9310\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4687 - acc: 0.9413\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4521 - acc: 0.9470\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4344 - acc: 0.9543\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4177 - acc: 0.9602\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4077 - acc: 0.9618\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3899 - acc: 0.9630\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3775 - acc: 0.9670\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3625 - acc: 0.9737\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3481 - acc: 0.9813\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3353 - acc: 0.9838\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3203 - acc: 0.9827\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3049 - acc: 0.9890\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2935 - acc: 0.9870\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2794 - acc: 0.9900\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2677 - acc: 0.9907\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2544 - acc: 0.9922\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2414 - acc: 0.9915\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2326 - acc: 0.9902\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2204 - acc: 0.9923\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2075 - acc: 0.9915\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1930 - acc: 0.9930\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1829 - acc: 0.9908\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1700 - acc: 0.9930\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1629 - acc: 0.9917\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1529 - acc: 0.9910\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1420 - acc: 0.9930\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1318 - acc: 0.9930\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1225 - acc: 0.9945\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1169 - acc: 0.9932\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1070 - acc: 0.9917\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1004 - acc: 0.9940\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0925 - acc: 0.9947\n",
      "Epoch 49/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0862 - acc: 0.9940\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0819 - acc: 0.9947\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0737 - acc: 0.9938\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0673 - acc: 0.9953\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0634 - acc: 0.9932\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0599 - acc: 0.9940\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0550 - acc: 0.9947\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0504 - acc: 0.9953\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0465 - acc: 0.9960\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0441 - acc: 0.9947\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0412 - acc: 0.9953\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0377 - acc: 0.9953\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0FBBD0AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7116 - acc: 0.7013\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6926 - acc: 0.4937\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6667 - acc: 0.7997\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6402 - acc: 0.8858\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6120 - acc: 0.9082\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5840 - acc: 0.9255\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5547 - acc: 0.9353\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5290 - acc: 0.9397\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5018 - acc: 0.9465\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4757 - acc: 0.9503\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4507 - acc: 0.9620\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4252 - acc: 0.9617\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4015 - acc: 0.9685\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3804 - acc: 0.9728\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3571 - acc: 0.9813\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3376 - acc: 0.9823\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3195 - acc: 0.9815\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3018 - acc: 0.9817\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2826 - acc: 0.9823\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2670 - acc: 0.9868\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2517 - acc: 0.9875\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2356 - acc: 0.9885\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2227 - acc: 0.9908\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2082 - acc: 0.9922\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1996 - acc: 0.9925\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1851 - acc: 0.9938\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1749 - acc: 0.9947\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1638 - acc: 0.9953\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1536 - acc: 0.9955\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1439 - acc: 0.9962\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1373 - acc: 0.9970\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1283 - acc: 0.9970\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1205 - acc: 0.9970\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1123 - acc: 0.9977\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1040 - acc: 0.9983\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1006 - acc: 0.9970\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0935 - acc: 0.9970\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0883 - acc: 1.0000\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0824 - acc: 1.0000\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0782 - acc: 1.0000\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0743 - acc: 1.0000\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0688 - acc: 1.0000\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0644 - acc: 1.0000\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0604 - acc: 1.0000\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0572 - acc: 1.0000\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0533 - acc: 1.0000\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0507 - acc: 1.0000\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0475 - acc: 1.0000\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0456 - acc: 1.0000\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0426 - acc: 1.0000\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0405 - acc: 1.0000\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0379 - acc: 1.0000\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0360 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0341 - acc: 1.0000\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0326 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0263 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0238 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC20ADC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7571 - acc: 0.7075\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6949 - acc: 0.4832\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6575 - acc: 0.7770\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6234 - acc: 0.8753\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5904 - acc: 0.9127\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5573 - acc: 0.9212\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5234 - acc: 0.9318\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4926 - acc: 0.9423\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4616 - acc: 0.9490\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4361 - acc: 0.9535\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4071 - acc: 0.9582\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3853 - acc: 0.9613\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3617 - acc: 0.9638\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3392 - acc: 0.9678\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3162 - acc: 0.9725\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2973 - acc: 0.9828\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2818 - acc: 0.9852\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2645 - acc: 0.9868\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2490 - acc: 0.9863\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2327 - acc: 0.9855\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2185 - acc: 0.9890\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2046 - acc: 0.9922\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1921 - acc: 0.9928\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1807 - acc: 0.9937\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1718 - acc: 0.9915\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1613 - acc: 0.9902\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1514 - acc: 0.9908\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1433 - acc: 0.9938\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1338 - acc: 0.9923\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1271 - acc: 0.9923\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1193 - acc: 0.9932\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1129 - acc: 0.9923\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1064 - acc: 0.9938\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1018 - acc: 0.9925\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0941 - acc: 0.9945\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0897 - acc: 0.9953\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0839 - acc: 0.9962\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0814 - acc: 0.9947\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0751 - acc: 0.9968\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0740 - acc: 0.9947\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0686 - acc: 0.9962\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0662 - acc: 0.9962\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0612 - acc: 0.9960\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0595 - acc: 0.9962\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0569 - acc: 0.9947\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0522 - acc: 0.9968\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0509 - acc: 0.9968\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0488 - acc: 0.9953\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0467 - acc: 0.9962\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0454 - acc: 0.9955\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0425 - acc: 0.9962\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0418 - acc: 0.9947\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0401 - acc: 0.9947\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0362 - acc: 0.9968\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0354 - acc: 0.9953\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0351 - acc: 0.9947\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0330 - acc: 0.9962\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0311 - acc: 0.9968\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0307 - acc: 0.9947\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0286 - acc: 0.9968\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0282 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F22D58B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.7555 - acc: 0.7000\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6919 - acc: 0.5340\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6741 - acc: 0.8058\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6598 - acc: 0.8898\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6453 - acc: 0.9290\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6323 - acc: 0.9402\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6199 - acc: 0.9488\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6067 - acc: 0.9493\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5939 - acc: 0.9498\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5819 - acc: 0.9532\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5693 - acc: 0.9570\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5574 - acc: 0.9595\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5461 - acc: 0.9568\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5329 - acc: 0.9618\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5234 - acc: 0.9623\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5121 - acc: 0.9585\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5008 - acc: 0.9652\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4894 - acc: 0.9640\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4807 - acc: 0.9682\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4708 - acc: 0.9720\n",
      "Epoch 20/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4613 - acc: 0.9703\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4515 - acc: 0.9692\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4423 - acc: 0.9717\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4324 - acc: 0.9708\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4234 - acc: 0.9702\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4130 - acc: 0.9772\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4058 - acc: 0.9745\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3947 - acc: 0.9752\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3875 - acc: 0.9775\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3782 - acc: 0.9753\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3685 - acc: 0.9768\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3621 - acc: 0.9762\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3553 - acc: 0.9748\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3478 - acc: 0.9763\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3381 - acc: 0.9792\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3324 - acc: 0.9800\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3225 - acc: 0.9813\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3157 - acc: 0.9845\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3072 - acc: 0.9813\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3007 - acc: 0.9847\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2955 - acc: 0.9853\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2900 - acc: 0.9840\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2806 - acc: 0.9860\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2753 - acc: 0.986 - 0s 8ms/step - loss: 0.2753 - acc: 0.9845\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2698 - acc: 0.9863\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2636 - acc: 0.9892\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2581 - acc: 0.9893\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2534 - acc: 0.9887\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2466 - acc: 0.9887\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2393 - acc: 0.9887\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2318 - acc: 0.9920\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2275 - acc: 0.9902\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2238 - acc: 0.9908\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2174 - acc: 0.9915\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2099 - acc: 0.9922\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2057 - acc: 0.9922\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1993 - acc: 0.9922\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1967 - acc: 0.9915\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1921 - acc: 0.9938\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1875 - acc: 0.9952\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1862 - acc: 0.9925\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1815 - acc: 0.9925\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1734 - acc: 0.9945\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1715 - acc: 0.9925\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1645 - acc: 0.9938\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1636 - acc: 0.9932\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1579 - acc: 0.9953\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1537 - acc: 0.9938\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1502 - acc: 0.9947\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1460 - acc: 0.9947\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1421 - acc: 0.9947\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC3D9670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5535 - acc: 0.7188\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6928 - acc: 0.5325\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6727 - acc: 0.8275\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6567 - acc: 0.8928\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6418 - acc: 0.9232\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6269 - acc: 0.9385\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6139 - acc: 0.9388\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5985 - acc: 0.9498\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5838 - acc: 0.9488\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5708 - acc: 0.9523\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5570 - acc: 0.9552\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5433 - acc: 0.9557\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5310 - acc: 0.9518\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5181 - acc: 0.9635\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5076 - acc: 0.9615\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4920 - acc: 0.9677\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4805 - acc: 0.9627\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4706 - acc: 0.9668\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4597 - acc: 0.9685\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4470 - acc: 0.9693\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4377 - acc: 0.9698\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4267 - acc: 0.9710\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4153 - acc: 0.9723\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4038 - acc: 0.9702\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3953 - acc: 0.9738\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3856 - acc: 0.9747\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3768 - acc: 0.9773\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3679 - acc: 0.9768\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3577 - acc: 0.9793\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3493 - acc: 0.9805\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3390 - acc: 0.9828\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3321 - acc: 0.9808\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3224 - acc: 0.9873\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3163 - acc: 0.9845\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3064 - acc: 0.9833\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2992 - acc: 0.9840\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2910 - acc: 0.9847\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2839 - acc: 0.9873\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2775 - acc: 0.9840\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2673 - acc: 0.9873\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2623 - acc: 0.9862\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2542 - acc: 0.9882\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2486 - acc: 0.9883\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2423 - acc: 0.9883\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2383 - acc: 0.9870\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2309 - acc: 0.9890\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2254 - acc: 0.9883\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2182 - acc: 0.9883\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2141 - acc: 0.9885\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2080 - acc: 0.9885\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2027 - acc: 0.9892\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1965 - acc: 0.9878\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1900 - acc: 0.9885\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1877 - acc: 0.9872\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1810 - acc: 0.9892\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1774 - acc: 0.9893\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1749 - acc: 0.9893\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1704 - acc: 0.9893\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1639 - acc: 0.9880\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1590 - acc: 0.9907\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1572 - acc: 0.9887\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1530 - acc: 0.9887\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1459 - acc: 0.9893\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1434 - acc: 0.9908\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1392 - acc: 0.9915\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1368 - acc: 0.9895\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1342 - acc: 0.9902\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1266 - acc: 0.9915\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1275 - acc: 0.9915\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1224 - acc: 0.9908\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1197 - acc: 0.9922\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D307EB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5557 - acc: 0.6963\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6925 - acc: 0.5363\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6676 - acc: 0.7705\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6492 - acc: 0.8647\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6351 - acc: 0.8882\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6200 - acc: 0.9027\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6075 - acc: 0.9105\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5947 - acc: 0.9223\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5827 - acc: 0.9215\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5727 - acc: 0.9282\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5596 - acc: 0.9360\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5494 - acc: 0.9437\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5400 - acc: 0.9453\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5291 - acc: 0.9447\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5187 - acc: 0.9518\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5105 - acc: 0.9463\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4989 - acc: 0.9520\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4890 - acc: 0.9547\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4794 - acc: 0.9553\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4707 - acc: 0.9562\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4627 - acc: 0.9593\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4531 - acc: 0.9602\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4455 - acc: 0.9593\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4372 - acc: 0.9587\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4269 - acc: 0.9593\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4185 - acc: 0.9615\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4125 - acc: 0.962 - 0s 8ms/step - loss: 0.4108 - acc: 0.9632\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4005 - acc: 0.9643\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3909 - acc: 0.9650\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3868 - acc: 0.9677\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3784 - acc: 0.9705\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3712 - acc: 0.9672\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3652 - acc: 0.9700\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3572 - acc: 0.9697\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3493 - acc: 0.9717\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3410 - acc: 0.9745\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3352 - acc: 0.9737\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3297 - acc: 0.9745\n",
      "Epoch 38/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3204 - acc: 0.9787\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3148 - acc: 0.9827\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3075 - acc: 0.9793\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3020 - acc: 0.9822\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2961 - acc: 0.9800\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2903 - acc: 0.9822\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2836 - acc: 0.9815\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2785 - acc: 0.9810\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2729 - acc: 0.9797\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2647 - acc: 0.9837\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2593 - acc: 0.9817\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2561 - acc: 0.9830\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2490 - acc: 0.9837\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2444 - acc: 0.9845\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2395 - acc: 0.9838\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2334 - acc: 0.9862\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2277 - acc: 0.9860\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2232 - acc: 0.9853\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2202 - acc: 0.9855\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2141 - acc: 0.9890\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2099 - acc: 0.9898\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2048 - acc: 0.9877\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2034 - acc: 0.9878\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1962 - acc: 0.9885\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1934 - acc: 0.9885\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1868 - acc: 0.9922\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1877 - acc: 0.9923\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1786 - acc: 0.9938\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1751 - acc: 0.9938\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1719 - acc: 0.9945\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1686 - acc: 0.9938\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1682 - acc: 0.9940\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1619 - acc: 0.9947\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC370280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5471 - acc: 0.7188\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6955 - acc: 0.4728\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6608 - acc: 0.8040\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6365 - acc: 0.8893\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6181 - acc: 0.9070\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5995 - acc: 0.9180\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5833 - acc: 0.9312\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5690 - acc: 0.9342\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5560 - acc: 0.9373\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5420 - acc: 0.9453\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5298 - acc: 0.9443\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5168 - acc: 0.9470\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.5060 - acc: 0.9440\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4928 - acc: 0.9535\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4807 - acc: 0.9543\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4703 - acc: 0.9497\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4633 - acc: 0.9528\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4497 - acc: 0.9562\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4403 - acc: 0.9572\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4298 - acc: 0.9620\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4195 - acc: 0.9572\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4106 - acc: 0.9592\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4011 - acc: 0.9572\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3912 - acc: 0.9607\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3843 - acc: 0.9603\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3745 - acc: 0.9637\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3648 - acc: 0.9638\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3566 - acc: 0.9667\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3499 - acc: 0.9640\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3417 - acc: 0.9660\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3337 - acc: 0.9682\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3251 - acc: 0.9682\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3205 - acc: 0.9692\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3131 - acc: 0.9703\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3039 - acc: 0.9730\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2951 - acc: 0.9730\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2909 - acc: 0.9762\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2870 - acc: 0.9802\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2779 - acc: 0.9813\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2727 - acc: 0.9795\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2640 - acc: 0.9828\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2583 - acc: 0.9852\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2544 - acc: 0.9840\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2479 - acc: 0.9847\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2427 - acc: 0.9853\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2376 - acc: 0.9853\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2280 - acc: 0.9882\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2280 - acc: 0.9863\n",
      "Epoch 48/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2225 - acc: 0.9870\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2154 - acc: 0.9883\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2108 - acc: 0.9870\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2046 - acc: 0.9883\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1984 - acc: 0.9903\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1980 - acc: 0.9900\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1939 - acc: 0.9878\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1872 - acc: 0.9900\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1842 - acc: 0.9908\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1793 - acc: 0.9928\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1757 - acc: 0.9922\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1720 - acc: 0.9922\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1689 - acc: 0.9908\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1624 - acc: 0.9922\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1607 - acc: 0.9908\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1566 - acc: 0.9902\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1544 - acc: 0.9908\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1505 - acc: 0.9930\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1458 - acc: 0.9928\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1390 - acc: 0.9952\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1407 - acc: 0.9958\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1370 - acc: 0.9938\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1338 - acc: 0.9937\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EE21C670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5644 - acc: 0.7050\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6914 - acc: 0.5568\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6752 - acc: 0.7977\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6622 - acc: 0.8702\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6500 - acc: 0.8982\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6376 - acc: 0.9163\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6263 - acc: 0.9240\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6152 - acc: 0.9320\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6041 - acc: 0.9398\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5930 - acc: 0.9488\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5819 - acc: 0.9488\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5705 - acc: 0.9515\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5607 - acc: 0.9555\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5496 - acc: 0.9562\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5388 - acc: 0.9628\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5291 - acc: 0.9585\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5195 - acc: 0.9543\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.5101 - acc: 0.9602\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4995 - acc: 0.9587\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4892 - acc: 0.9650\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4798 - acc: 0.9648\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4710 - acc: 0.9672\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4618 - acc: 0.9702\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4509 - acc: 0.9675\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4416 - acc: 0.9737\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4326 - acc: 0.9742\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4250 - acc: 0.9747\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4189 - acc: 0.9748\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4093 - acc: 0.9753\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4019 - acc: 0.9712\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3910 - acc: 0.9758\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3823 - acc: 0.9740\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3755 - acc: 0.9762\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3671 - acc: 0.9783\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3610 - acc: 0.9783\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3541 - acc: 0.9798\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3448 - acc: 0.9825\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3368 - acc: 0.9798\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3300 - acc: 0.9813\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3230 - acc: 0.9793\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3164 - acc: 0.9818\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3074 - acc: 0.9815\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3027 - acc: 0.9825\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2953 - acc: 0.9840\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2900 - acc: 0.9853\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2824 - acc: 0.9862\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2785 - acc: 0.9890\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2700 - acc: 0.9892\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2654 - acc: 0.9892\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2586 - acc: 0.9878\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2515 - acc: 0.9898\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2478 - acc: 0.9900\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2409 - acc: 0.9898\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2343 - acc: 0.9907\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2339 - acc: 0.9880\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2227 - acc: 0.9913\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2209 - acc: 0.9895\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2142 - acc: 0.9900\n",
      "Epoch 58/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2092 - acc: 0.9907\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2060 - acc: 0.9928\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1989 - acc: 0.9923\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1958 - acc: 0.9923\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1921 - acc: 0.9923\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1858 - acc: 0.9930\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1826 - acc: 0.9923\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1759 - acc: 0.9945\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1734 - acc: 0.9938\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1714 - acc: 0.9932\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1647 - acc: 0.9932\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1614 - acc: 0.9938\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1575 - acc: 0.9945\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDF2A0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5511 - acc: 0.7188\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6922 - acc: 0.5180\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6735 - acc: 0.7990\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6598 - acc: 0.8687\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6477 - acc: 0.9105\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6342 - acc: 0.9270\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6212 - acc: 0.9390\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6083 - acc: 0.9457\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5963 - acc: 0.9438\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5842 - acc: 0.9477\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5704 - acc: 0.9527\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5585 - acc: 0.9585\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5481 - acc: 0.9573\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5333 - acc: 0.9625\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5237 - acc: 0.9645\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5123 - acc: 0.9627\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5007 - acc: 0.9638\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4900 - acc: 0.9647\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4803 - acc: 0.9627\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4692 - acc: 0.9620\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4580 - acc: 0.9668\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4468 - acc: 0.9675\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4389 - acc: 0.9670\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4281 - acc: 0.9692\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4201 - acc: 0.9658\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4089 - acc: 0.9672\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3998 - acc: 0.9672\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3893 - acc: 0.9692\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3807 - acc: 0.9720\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3728 - acc: 0.9667\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3645 - acc: 0.9708\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3570 - acc: 0.9728\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3480 - acc: 0.9733\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3390 - acc: 0.9747\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3298 - acc: 0.9740\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3234 - acc: 0.9747\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3156 - acc: 0.9767\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3083 - acc: 0.9773\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2988 - acc: 0.9768\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2926 - acc: 0.9803\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2857 - acc: 0.9792\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2789 - acc: 0.9777\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2742 - acc: 0.9777\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2648 - acc: 0.9785\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2572 - acc: 0.9820\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2523 - acc: 0.9795\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2472 - acc: 0.9837\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2398 - acc: 0.9828\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2318 - acc: 0.9837\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2294 - acc: 0.9817\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2231 - acc: 0.9810\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2199 - acc: 0.9803\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2123 - acc: 0.9832\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2054 - acc: 0.9877\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2014 - acc: 0.9877\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1965 - acc: 0.9870\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1894 - acc: 0.9883\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1863 - acc: 0.9870\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1806 - acc: 0.9877\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1774 - acc: 0.9883\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1715 - acc: 0.9898\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1671 - acc: 0.9892\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1650 - acc: 0.9878\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1614 - acc: 0.9878\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1562 - acc: 0.9893\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1517 - acc: 0.9900\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1482 - acc: 0.9907\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1457 - acc: 0.9900\n",
      "Epoch 68/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1432 - acc: 0.9893\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1389 - acc: 0.9900\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1342 - acc: 0.9913\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EBF04B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5550 - acc: 0.7025\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6931 - acc: 0.5247\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6674 - acc: 0.7662\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6495 - acc: 0.8670\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6343 - acc: 0.9047\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6204 - acc: 0.9110\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6084 - acc: 0.9275\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5958 - acc: 0.9390\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5850 - acc: 0.9365\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5736 - acc: 0.9417\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5621 - acc: 0.9480\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5521 - acc: 0.9480\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5417 - acc: 0.9502\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5323 - acc: 0.9538\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5238 - acc: 0.9535\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5134 - acc: 0.9605\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5034 - acc: 0.9607\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4942 - acc: 0.9610\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4837 - acc: 0.9622\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4764 - acc: 0.9618\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4667 - acc: 0.9673\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4570 - acc: 0.9640\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4509 - acc: 0.9653\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4425 - acc: 0.9663\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4328 - acc: 0.9660\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4239 - acc: 0.9675\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4167 - acc: 0.9715\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4100 - acc: 0.9723\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4026 - acc: 0.9723\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3936 - acc: 0.9717\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3865 - acc: 0.9733\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3774 - acc: 0.9740\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3735 - acc: 0.9755\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3648 - acc: 0.9783\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3576 - acc: 0.9817\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3518 - acc: 0.9798\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3422 - acc: 0.9757\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3371 - acc: 0.9793\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3316 - acc: 0.9802\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3252 - acc: 0.9840\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3190 - acc: 0.9793\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3132 - acc: 0.9815\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3045 - acc: 0.9828\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2985 - acc: 0.9823\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2936 - acc: 0.9843\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2881 - acc: 0.9852\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2829 - acc: 0.9823\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2772 - acc: 0.9853\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2692 - acc: 0.9853\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2686 - acc: 0.992 - 0s 12ms/step - loss: 0.2667 - acc: 0.9882\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2573 - acc: 0.9862\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2556 - acc: 0.9842\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2488 - acc: 0.9853\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2448 - acc: 0.9868\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2419 - acc: 0.9848\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2387 - acc: 0.9842\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2309 - acc: 0.9877\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2235 - acc: 0.9878\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2198 - acc: 0.9872\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2140 - acc: 0.9885\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2097 - acc: 0.9892\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2066 - acc: 0.9900\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2044 - acc: 0.9907\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1978 - acc: 0.9923\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1943 - acc: 0.9923\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1907 - acc: 0.9937\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1848 - acc: 0.9953\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1821 - acc: 0.9955\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1789 - acc: 0.9962\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1732 - acc: 0.9967\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1712 - acc: 0.9955\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDF2A4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5519 - acc: 0.7163\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6937 - acc: 0.5047\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6590 - acc: 0.8065\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6348 - acc: 0.8787\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6146 - acc: 0.9013\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5971 - acc: 0.9213\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5812 - acc: 0.9283\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5651 - acc: 0.9352\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5521 - acc: 0.9400\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5373 - acc: 0.9422\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5245 - acc: 0.9475\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5125 - acc: 0.9517\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5010 - acc: 0.9523\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4876 - acc: 0.9527\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4778 - acc: 0.9560\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4650 - acc: 0.9563\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4543 - acc: 0.9590\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4417 - acc: 0.9602\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4360 - acc: 0.9628\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4260 - acc: 0.9578\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4140 - acc: 0.9598\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4071 - acc: 0.9572\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3982 - acc: 0.9607\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3877 - acc: 0.9593\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3785 - acc: 0.9632\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3719 - acc: 0.9642\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3593 - acc: 0.9662\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3543 - acc: 0.9678\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3457 - acc: 0.9708\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3371 - acc: 0.9713\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3286 - acc: 0.9695\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3206 - acc: 0.9728\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3061 - acc: 0.974 - 0s 9ms/step - loss: 0.3114 - acc: 0.9730\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3056 - acc: 0.9773\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3018 - acc: 0.9740\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2921 - acc: 0.9753\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2872 - acc: 0.9748\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2789 - acc: 0.9762\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2736 - acc: 0.9798\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2693 - acc: 0.9793\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2577 - acc: 0.9827\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2552 - acc: 0.9800\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2484 - acc: 0.9800\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2427 - acc: 0.9800\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2361 - acc: 0.9807\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2319 - acc: 0.9817\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2271 - acc: 0.9868\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2236 - acc: 0.9857\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2179 - acc: 0.9870\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2136 - acc: 0.9898\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2064 - acc: 0.9878\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1997 - acc: 0.9885\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1980 - acc: 0.9878\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1937 - acc: 0.9892\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1890 - acc: 0.9872\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1856 - acc: 0.9878\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1807 - acc: 0.9905\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1727 - acc: 0.9913\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1702 - acc: 0.9915\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1692 - acc: 0.9902\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1660 - acc: 0.9902\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1601 - acc: 0.9908\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1564 - acc: 0.9915\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1536 - acc: 0.9908\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1498 - acc: 0.9915\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1442 - acc: 0.9923\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1434 - acc: 0.9917\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1406 - acc: 0.9908\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1355 - acc: 0.9945\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1323 - acc: 0.9932\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1296 - acc: 0.9932\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D8F3AF70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5610 - acc: 0.6975\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.6936 - acc: 0.4972\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6869 - acc: 0.6185\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6814 - acc: 0.6550\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6754 - acc: 0.7102\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6693 - acc: 0.7725\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6618 - acc: 0.7813\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6543 - acc: 0.8212\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6446 - acc: 0.8507\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6357 - acc: 0.8912\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6258 - acc: 0.9067\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6156 - acc: 0.9132\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6041 - acc: 0.9342\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5932 - acc: 0.9407\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5837 - acc: 0.9473\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5709 - acc: 0.9537\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5609 - acc: 0.9587\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5505 - acc: 0.9595\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5369 - acc: 0.9652\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5257 - acc: 0.9680\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5138 - acc: 0.9720\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5018 - acc: 0.9723\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4925 - acc: 0.9738\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4811 - acc: 0.9717\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4679 - acc: 0.9763\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4573 - acc: 0.9747\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4472 - acc: 0.9793\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4369 - acc: 0.9808\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4254 - acc: 0.9822\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4153 - acc: 0.9825\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4042 - acc: 0.9853\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3930 - acc: 0.9852\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3842 - acc: 0.9867\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3741 - acc: 0.9863\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3645 - acc: 0.9870\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3545 - acc: 0.9908\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3449 - acc: 0.9920\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3340 - acc: 0.9923\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3251 - acc: 0.9938\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3146 - acc: 0.9952\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3073 - acc: 0.9955\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2973 - acc: 0.9968\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2899 - acc: 0.9962\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2820 - acc: 0.996 - 0s 9ms/step - loss: 0.2804 - acc: 0.9962\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2714 - acc: 0.9962\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2593 - acc: 0.9977\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2534 - acc: 0.9977\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2441 - acc: 0.9977\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2384 - acc: 0.9970\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2287 - acc: 0.9970\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2209 - acc: 0.9970\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2136 - acc: 0.9970\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2046 - acc: 0.9977\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1956 - acc: 0.998 - 0s 10ms/step - loss: 0.1976 - acc: 0.9977\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1916 - acc: 0.9970\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1851 - acc: 0.9977\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1784 - acc: 0.9977\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1703 - acc: 0.9977\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1641 - acc: 0.9977\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1613 - acc: 0.9970\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1535 - acc: 0.9970\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1460 - acc: 0.9977\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1401 - acc: 0.9985\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1370 - acc: 0.9985\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1303 - acc: 0.9983\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1250 - acc: 0.9992\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1216 - acc: 0.9985\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1139 - acc: 0.9992\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1099 - acc: 0.9985\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1061 - acc: 0.9985\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1012 - acc: 0.9985\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC3D9E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6721 - acc: 0.6888\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6937 - acc: 0.4925\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6808 - acc: 0.5407\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6685 - acc: 0.5580\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6561 - acc: 0.6145\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6426 - acc: 0.6497\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6295 - acc: 0.7005\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6180 - acc: 0.7512\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6058 - acc: 0.7803\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5934 - acc: 0.8053\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5803 - acc: 0.8382\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5676 - acc: 0.8700\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5563 - acc: 0.8835\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5473 - acc: 0.9042\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5345 - acc: 0.9087\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5233 - acc: 0.9207\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5090 - acc: 0.9290\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4978 - acc: 0.9383\n",
      "Epoch 18/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4880 - acc: 0.9425\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4756 - acc: 0.9500\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4649 - acc: 0.9502\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4522 - acc: 0.9552\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4382 - acc: 0.9532\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4296 - acc: 0.9577\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4167 - acc: 0.9587\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4063 - acc: 0.9643\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3975 - acc: 0.9648\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3826 - acc: 0.9655\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3707 - acc: 0.9700\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3594 - acc: 0.9738\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3510 - acc: 0.9768\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3393 - acc: 0.9770\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3277 - acc: 0.9802\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3190 - acc: 0.9803\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3060 - acc: 0.9830\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2956 - acc: 0.9855\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2879 - acc: 0.9883\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2782 - acc: 0.9863\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2683 - acc: 0.9870\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2577 - acc: 0.9872\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2467 - acc: 0.9870\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2379 - acc: 0.9898\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2316 - acc: 0.9877\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2224 - acc: 0.9915\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2125 - acc: 0.9908\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2053 - acc: 0.9900\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1947 - acc: 0.9915\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1869 - acc: 0.9922\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1824 - acc: 0.9908\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1728 - acc: 0.9915\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1672 - acc: 0.9928\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1582 - acc: 0.9937\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1521 - acc: 0.9937\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1464 - acc: 0.9930\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1408 - acc: 0.9923\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1350 - acc: 0.9938\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1290 - acc: 0.9945\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1233 - acc: 0.9945\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1165 - acc: 0.9952\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1120 - acc: 0.9952\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1092 - acc: 0.9923\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1021 - acc: 0.9938\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0982 - acc: 0.9938\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0945 - acc: 0.9925\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0905 - acc: 0.9932\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0853 - acc: 0.9938\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0841 - acc: 0.9932\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0788 - acc: 0.9923\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0757 - acc: 0.9938\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0738 - acc: 0.9947\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0690 - acc: 0.9953\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F22D55E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6380 - acc: 0.7013\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 0.6938 - acc: 0.4770\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6699 - acc: 0.8020\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6506 - acc: 0.8698\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6304 - acc: 0.8973\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6119 - acc: 0.9237\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5923 - acc: 0.9390\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5747 - acc: 0.9400\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5561 - acc: 0.9460\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5386 - acc: 0.9493\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5212 - acc: 0.9488\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5025 - acc: 0.9545\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4860 - acc: 0.9555\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4684 - acc: 0.9590\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4510 - acc: 0.9702\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4371 - acc: 0.9717\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4218 - acc: 0.9745\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4078 - acc: 0.9705\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3918 - acc: 0.9725\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3780 - acc: 0.9753\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3639 - acc: 0.9718\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3523 - acc: 0.9740\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3382 - acc: 0.9748\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3250 - acc: 0.9790\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3103 - acc: 0.9807\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3013 - acc: 0.9783\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2903 - acc: 0.9780\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2783 - acc: 0.9800\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2680 - acc: 0.9815\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2616 - acc: 0.984 - 0s 11ms/step - loss: 0.2589 - acc: 0.9838\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2469 - acc: 0.9852\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2364 - acc: 0.9895\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2297 - acc: 0.9883\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2205 - acc: 0.9877\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2097 - acc: 0.9907\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2039 - acc: 0.9893\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1935 - acc: 0.9923\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1856 - acc: 0.9945\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1805 - acc: 0.9932\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1705 - acc: 0.9952\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1664 - acc: 0.9955\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1580 - acc: 0.9962\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1502 - acc: 0.9955\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1462 - acc: 0.9970\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1376 - acc: 0.9983\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1342 - acc: 0.9970\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1297 - acc: 0.9977\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1219 - acc: 0.9977\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1177 - acc: 0.9977\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1113 - acc: 0.998 - 0s 10ms/step - loss: 0.1121 - acc: 0.9985\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1062 - acc: 0.9992\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1031 - acc: 0.9985\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0995 - acc: 0.9985\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0942 - acc: 0.9992\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0910 - acc: 0.9985\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0861 - acc: 0.9985\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0819 - acc: 0.9992\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0788 - acc: 0.9985\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0764 - acc: 0.9992\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0725 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0706 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0669 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0636 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0613 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0587 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0563 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0534 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0512 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0497 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0473 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0451 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC423CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6338 - acc: 0.7050\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6962 - acc: 0.4647\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6574 - acc: 0.7888\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6292 - acc: 0.8678\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6028 - acc: 0.9072\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5774 - acc: 0.9210\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5565 - acc: 0.9250\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5316 - acc: 0.9408\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5116 - acc: 0.9468\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4915 - acc: 0.9478\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4708 - acc: 0.9502\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4521 - acc: 0.9517\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4338 - acc: 0.9495\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4188 - acc: 0.9513\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3996 - acc: 0.9560\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3843 - acc: 0.9593\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3693 - acc: 0.9597\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3520 - acc: 0.9638\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3378 - acc: 0.9633\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3228 - acc: 0.9700\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3135 - acc: 0.9763\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3017 - acc: 0.9740\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2851 - acc: 0.9783\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2764 - acc: 0.9780\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2637 - acc: 0.9773\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2529 - acc: 0.9823\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2413 - acc: 0.9850\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2305 - acc: 0.9868\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2215 - acc: 0.9868\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2118 - acc: 0.9870\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2025 - acc: 0.9872\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1941 - acc: 0.9907\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1855 - acc: 0.9893\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1783 - acc: 0.9893\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1702 - acc: 0.9913\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1598 - acc: 0.9928\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1557 - acc: 0.9937\n",
      "Epoch 37/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1495 - acc: 0.9930\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1405 - acc: 0.9917\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1348 - acc: 0.9945\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1297 - acc: 0.9943\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1247 - acc: 0.9945\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1216 - acc: 0.9932\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1136 - acc: 0.9923\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1119 - acc: 0.990 - 0s 8ms/step - loss: 0.1106 - acc: 0.9917\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1056 - acc: 0.9908\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1001 - acc: 0.9923\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0963 - acc: 0.9923\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0915 - acc: 0.9945\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0889 - acc: 0.9923\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0843 - acc: 0.9945\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0818 - acc: 0.9938\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0789 - acc: 0.9947\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0743 - acc: 0.9945\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0709 - acc: 0.9937\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0690 - acc: 0.9938\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0651 - acc: 0.9953\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0625 - acc: 0.9953\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0612 - acc: 0.9962\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0600 - acc: 0.9955\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0560 - acc: 0.9968\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0537 - acc: 0.9960\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0521 - acc: 0.9968\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0489 - acc: 0.9960\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0489 - acc: 0.9955\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0452 - acc: 0.9968\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0437 - acc: 0.9962\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0439 - acc: 0.9955\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0400 - acc: 0.9960\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0393 - acc: 0.9947\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0381 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F775A550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6726 - acc: 0.6975\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6936 - acc: 0.4975\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6870 - acc: 0.7030\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6800 - acc: 0.8288\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6713 - acc: 0.8825\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6609 - acc: 0.9135\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6496 - acc: 0.9490\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6364 - acc: 0.9615\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6220 - acc: 0.9772\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6079 - acc: 0.9802\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5917 - acc: 0.9882\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5747 - acc: 0.9875\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5574 - acc: 0.9885\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5378 - acc: 0.9883\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5212 - acc: 0.9902\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5016 - acc: 0.9923\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4801 - acc: 0.9930\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4607 - acc: 0.9938\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4403 - acc: 0.9953\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4212 - acc: 0.9938\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4004 - acc: 0.9960\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3805 - acc: 0.9962\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3637 - acc: 0.9940\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3432 - acc: 0.9953\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3258 - acc: 0.9947\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3063 - acc: 0.9953\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2886 - acc: 0.9953\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2736 - acc: 0.9960\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2547 - acc: 0.9970\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2401 - acc: 0.9977\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2260 - acc: 0.9970\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2108 - acc: 0.9983\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1967 - acc: 0.9970\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1849 - acc: 0.9977\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1721 - acc: 0.9970\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1599 - acc: 0.9977\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1490 - acc: 0.9970\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1386 - acc: 0.9977\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1292 - acc: 0.9992\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1189 - acc: 0.9985\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1111 - acc: 0.9985\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1031 - acc: 0.9992\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0938 - acc: 1.0000\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0883 - acc: 1.0000\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0819 - acc: 1.0000\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0760 - acc: 1.0000\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0683 - acc: 1.0000\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0635 - acc: 1.0000\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0575 - acc: 1.0000\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0543 - acc: 1.0000\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0503 - acc: 1.0000\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0452 - acc: 1.0000\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0412 - acc: 1.000 - 0s 11ms/step - loss: 0.0418 - acc: 1.0000\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0383 - acc: 1.0000\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0364 - acc: 1.0000\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0326 - acc: 1.0000\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0300 - acc: 1.0000\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0257 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0156 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0091 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED7F9F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7984 - acc: 0.7163\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6933 - acc: 0.4860\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6858 - acc: 0.7475\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6769 - acc: 0.7752\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6666 - acc: 0.8545\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6543 - acc: 0.8903\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6436 - acc: 0.9173\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6308 - acc: 0.9195\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6175 - acc: 0.9347\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6020 - acc: 0.9410\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5888 - acc: 0.9572\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5733 - acc: 0.9568\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5588 - acc: 0.9585\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5433 - acc: 0.9633\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5289 - acc: 0.9698\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5125 - acc: 0.9737\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4977 - acc: 0.9825\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4797 - acc: 0.9775\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4683 - acc: 0.9762\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4525 - acc: 0.9778\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4347 - acc: 0.9785\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4222 - acc: 0.9827\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4059 - acc: 0.9772\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3911 - acc: 0.9823\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3760 - acc: 0.9802\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3622 - acc: 0.9862\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3459 - acc: 0.9892\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3308 - acc: 0.9892\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3173 - acc: 0.9908\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3024 - acc: 0.9908\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2867 - acc: 0.9937\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2743 - acc: 0.9925\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2621 - acc: 0.9943\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2473 - acc: 0.9953\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2348 - acc: 0.9947\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2200 - acc: 0.9940\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2070 - acc: 0.9960\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1939 - acc: 0.9953\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1847 - acc: 0.9947\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1694 - acc: 0.9947\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1604 - acc: 0.9953\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1479 - acc: 0.9945\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1412 - acc: 0.9947\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1312 - acc: 0.9945\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1220 - acc: 0.9960\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1146 - acc: 0.9947\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1070 - acc: 0.9953\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1019 - acc: 0.9953\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0950 - acc: 0.9953\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0876 - acc: 0.9953\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0829 - acc: 0.9947\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0782 - acc: 0.9947\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0722 - acc: 0.9945\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0662 - acc: 0.9960\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0624 - acc: 0.9960\n",
      "Epoch 55/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0601 - acc: 0.9947\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0545 - acc: 0.9960\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0517 - acc: 0.9962\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0483 - acc: 0.9968\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0442 - acc: 0.9968\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0446 - acc: 0.9955\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0403 - acc: 0.9962\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0392 - acc: 0.9955\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0345 - acc: 0.9968\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0323 - acc: 0.9968\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0318 - acc: 0.9955\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0279 - acc: 0.9968\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0288 - acc: 0.9955\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0261 - acc: 0.9953\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0236 - acc: 0.9960\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0235 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F22D50D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7466 - acc: 0.7088\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6950 - acc: 0.4780\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6531 - acc: 0.8352\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6179 - acc: 0.8960\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5839 - acc: 0.9245\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5523 - acc: 0.9287\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5189 - acc: 0.9450\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4905 - acc: 0.9472\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4605 - acc: 0.9500\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4304 - acc: 0.9555\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4057 - acc: 0.9637\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3812 - acc: 0.9687\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3563 - acc: 0.9712\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3339 - acc: 0.9740\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3127 - acc: 0.9753\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2938 - acc: 0.9787\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2751 - acc: 0.9817\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2539 - acc: 0.9845\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2394 - acc: 0.9847\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2219 - acc: 0.9875\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2093 - acc: 0.9863\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1944 - acc: 0.9892\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1810 - acc: 0.9937\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1689 - acc: 0.9947\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1567 - acc: 0.9960\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1458 - acc: 0.9968\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1365 - acc: 0.9968\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1283 - acc: 0.9970\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1186 - acc: 0.9955\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1098 - acc: 0.9968\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1025 - acc: 0.9983\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0951 - acc: 0.9992\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0874 - acc: 0.9992\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0838 - acc: 1.0000\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0766 - acc: 0.9992\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0720 - acc: 1.0000\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0676 - acc: 1.0000\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0634 - acc: 1.0000\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0581 - acc: 1.0000\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0559 - acc: 1.0000\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0515 - acc: 1.0000\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0480 - acc: 1.0000\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0445 - acc: 1.0000\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0415 - acc: 1.0000\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0392 - acc: 1.0000\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0369 - acc: 1.0000\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0346 - acc: 1.0000\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0324 - acc: 1.0000\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0265 - acc: 1.0000\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0246 - acc: 1.0000\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0235 - acc: 1.0000\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0170 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0108 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0083 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E897CD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8962 - acc: 0.7025\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6924 - acc: 0.5327\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6559 - acc: 0.7750\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6232 - acc: 0.8640\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5910 - acc: 0.9082\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5616 - acc: 0.9210\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5320 - acc: 0.9357\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5036 - acc: 0.9430\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4778 - acc: 0.9517\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4505 - acc: 0.9550\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4267 - acc: 0.9612\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4037 - acc: 0.9600\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3821 - acc: 0.9645\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3620 - acc: 0.9720\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3409 - acc: 0.9722\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3236 - acc: 0.9745\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3055 - acc: 0.9785\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2879 - acc: 0.9837\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2741 - acc: 0.9818\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2599 - acc: 0.9847\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2448 - acc: 0.9853\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2310 - acc: 0.9900\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2169 - acc: 0.9890\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2058 - acc: 0.9892\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1939 - acc: 0.9908\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1860 - acc: 0.990 - 0s 8ms/step - loss: 0.1842 - acc: 0.9900\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1743 - acc: 0.9908\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1633 - acc: 0.9922\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1551 - acc: 0.9922\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1473 - acc: 0.9923\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1371 - acc: 0.9943\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1290 - acc: 0.9923\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1238 - acc: 0.9917\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1169 - acc: 0.9930\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1116 - acc: 0.9932\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1063 - acc: 0.9923\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1001 - acc: 0.9930\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0950 - acc: 0.9932\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0895 - acc: 0.9953\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0839 - acc: 0.9945\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0809 - acc: 0.9947\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0758 - acc: 0.9945\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0751 - acc: 0.9947\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0709 - acc: 0.9955\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0655 - acc: 0.9960\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0619 - acc: 0.9968\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0621 - acc: 0.9955\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0574 - acc: 0.9953\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0544 - acc: 0.9968\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0522 - acc: 0.9968\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0514 - acc: 0.9955\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0467 - acc: 0.9975\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0468 - acc: 0.9947\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0433 - acc: 0.9968\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0435 - acc: 0.9962\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0419 - acc: 0.9962\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0375 - acc: 0.9975\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0383 - acc: 0.9955\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0352 - acc: 0.9968\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0354 - acc: 0.9955\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0341 - acc: 0.9955\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0309 - acc: 0.9968\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0282 - acc: 0.9975\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0277 - acc: 0.9968\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0284 - acc: 0.9968\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0265 - acc: 0.9968\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0265 - acc: 0.9947\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0257 - acc: 0.9947\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0239 - acc: 0.9962\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0227 - acc: 0.9968\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0219 - acc: 0.9977\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC16D1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8129 - acc: 0.7050\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6929 - acc: 0.5213\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6734 - acc: 0.8000\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6586 - acc: 0.8667\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6439 - acc: 0.8957\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6299 - acc: 0.9165\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6173 - acc: 0.9308\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6042 - acc: 0.9278\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5892 - acc: 0.9400\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5772 - acc: 0.9467\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5648 - acc: 0.9492\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5528 - acc: 0.9527\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5406 - acc: 0.9543\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5296 - acc: 0.9552\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5210 - acc: 0.9520\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5086 - acc: 0.9518\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4987 - acc: 0.9545\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4860 - acc: 0.9608\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4750 - acc: 0.9618\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4668 - acc: 0.9645\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4567 - acc: 0.9628\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4464 - acc: 0.9692\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4389 - acc: 0.9698\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4288 - acc: 0.9725\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4192 - acc: 0.9732\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4089 - acc: 0.9730\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3992 - acc: 0.9772\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3927 - acc: 0.9775\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3836 - acc: 0.9793\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3742 - acc: 0.9807\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3670 - acc: 0.9808\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3567 - acc: 0.9820\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3510 - acc: 0.9807\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3425 - acc: 0.9810\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3340 - acc: 0.9837\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3255 - acc: 0.9837\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3183 - acc: 0.9853\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3133 - acc: 0.9847\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3064 - acc: 0.9875\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2988 - acc: 0.9860\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2899 - acc: 0.9868\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2845 - acc: 0.9862\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2758 - acc: 0.9892\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2704 - acc: 0.9883\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2648 - acc: 0.9875\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2560 - acc: 0.9898\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2516 - acc: 0.9918\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2425 - acc: 0.9920\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2408 - acc: 0.9930\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2348 - acc: 0.9915\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2297 - acc: 0.9892\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2251 - acc: 0.9917\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2168 - acc: 0.9922\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2112 - acc: 0.9937\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2090 - acc: 0.9945\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2040 - acc: 0.9917\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1965 - acc: 0.9932\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1935 - acc: 0.9938\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1857 - acc: 0.9945\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1829 - acc: 0.9938\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1772 - acc: 0.9945\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F77484C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5624 - acc: 0.7125\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6936 - acc: 0.5063\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6750 - acc: 0.8217\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6610 - acc: 0.8925\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6467 - acc: 0.9183\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6326 - acc: 0.9258\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6189 - acc: 0.9367\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6049 - acc: 0.9530\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5925 - acc: 0.9448\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5795 - acc: 0.9478\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5672 - acc: 0.9468\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5562 - acc: 0.9488\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5424 - acc: 0.9500\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5310 - acc: 0.9502\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5189 - acc: 0.9555\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5072 - acc: 0.9517\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4967 - acc: 0.9598\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4861 - acc: 0.9605\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4744 - acc: 0.9587\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4620 - acc: 0.9663\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4530 - acc: 0.9623\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4457 - acc: 0.960 - 0s 8ms/step - loss: 0.4439 - acc: 0.9633\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4330 - acc: 0.9655\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4237 - acc: 0.9662\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4113 - acc: 0.9688\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4047 - acc: 0.9657\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3944 - acc: 0.9700\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3857 - acc: 0.9693\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3767 - acc: 0.9707\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3664 - acc: 0.9743\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3582 - acc: 0.9732\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3499 - acc: 0.9740\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3411 - acc: 0.9775\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3325 - acc: 0.9783\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3237 - acc: 0.9812\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3157 - acc: 0.9835\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3094 - acc: 0.9843\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3004 - acc: 0.9823\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2965 - acc: 0.9818\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2869 - acc: 0.9847\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2782 - acc: 0.9873\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2720 - acc: 0.9853\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2650 - acc: 0.9860\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2588 - acc: 0.9862\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2517 - acc: 0.9883\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2457 - acc: 0.9862\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2402 - acc: 0.9890\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2333 - acc: 0.9883\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2297 - acc: 0.9885\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2205 - acc: 0.9907\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2149 - acc: 0.9913\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2120 - acc: 0.9900\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2074 - acc: 0.9913\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1999 - acc: 0.9907\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1943 - acc: 0.9913\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1916 - acc: 0.9900\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1860 - acc: 0.9913\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1804 - acc: 0.9907\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1774 - acc: 0.9900\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1715 - acc: 0.9893\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1678 - acc: 0.9893\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0FBA191F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5564 - acc: 0.6988\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6891 - acc: 0.5455\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6529 - acc: 0.8088\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6281 - acc: 0.8742\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6101 - acc: 0.9040\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5906 - acc: 0.9097\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5751 - acc: 0.9212\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5595 - acc: 0.9265\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5435 - acc: 0.9422\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5308 - acc: 0.9415\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5175 - acc: 0.9430\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5043 - acc: 0.9462\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4926 - acc: 0.9473\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4813 - acc: 0.9487\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4703 - acc: 0.9548\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4561 - acc: 0.9537\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4486 - acc: 0.9542\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4372 - acc: 0.9548\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4255 - acc: 0.9557\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4146 - acc: 0.9582\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4037 - acc: 0.9613\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3936 - acc: 0.9613\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3850 - acc: 0.9655\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3778 - acc: 0.9690\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3664 - acc: 0.9710\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3611 - acc: 0.9685\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3498 - acc: 0.9713\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3435 - acc: 0.9673\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3311 - acc: 0.9700\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3257 - acc: 0.9733\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.3177 - acc: 0.9760\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3116 - acc: 0.9797\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3043 - acc: 0.9770\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2965 - acc: 0.9793\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2891 - acc: 0.9800\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2833 - acc: 0.9778\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2758 - acc: 0.9815\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2691 - acc: 0.9817\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2617 - acc: 0.9792\n",
      "Epoch 39/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2555 - acc: 0.9808\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2483 - acc: 0.9823\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2427 - acc: 0.9832\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2369 - acc: 0.9852\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2311 - acc: 0.9860\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2255 - acc: 0.9875\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2213 - acc: 0.9862\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2154 - acc: 0.9882\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2090 - acc: 0.9883\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2056 - acc: 0.9877\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1988 - acc: 0.9892\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1958 - acc: 0.9900\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1906 - acc: 0.9893\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1861 - acc: 0.9917\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1818 - acc: 0.9923\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1759 - acc: 0.9917\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1711 - acc: 0.9930\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1694 - acc: 0.9952\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1637 - acc: 0.9930\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1609 - acc: 0.9938\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1543 - acc: 0.9945\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1516 - acc: 0.9947\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0DA780F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5476 - acc: 0.7125\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6937 - acc: 0.4935\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6516 - acc: 0.8210\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6233 - acc: 0.8833\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6003 - acc: 0.9068\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5815 - acc: 0.9175\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5619 - acc: 0.9327\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5455 - acc: 0.9412\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5287 - acc: 0.9370\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5142 - acc: 0.9427\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4989 - acc: 0.9430\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4857 - acc: 0.9468\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4738 - acc: 0.9503\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4605 - acc: 0.9567\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4479 - acc: 0.9567\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4352 - acc: 0.9602\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4241 - acc: 0.9577\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4142 - acc: 0.9620\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4041 - acc: 0.9593\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3954 - acc: 0.9588\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3823 - acc: 0.9620\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3715 - acc: 0.9635\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3620 - acc: 0.9630\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3538 - acc: 0.9673\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3450 - acc: 0.9702\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3361 - acc: 0.9677\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3253 - acc: 0.9728\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3202 - acc: 0.9705\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3120 - acc: 0.9730\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3037 - acc: 0.9732\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2957 - acc: 0.9762\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2898 - acc: 0.9755\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2823 - acc: 0.9735\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2762 - acc: 0.9772\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2673 - acc: 0.9748\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2605 - acc: 0.9793\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2531 - acc: 0.9800\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2475 - acc: 0.9828\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2411 - acc: 0.9830\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2361 - acc: 0.9800\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2283 - acc: 0.9838\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2211 - acc: 0.9852\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2154 - acc: 0.9867\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2136 - acc: 0.9848\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2053 - acc: 0.9862\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2015 - acc: 0.9870\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1961 - acc: 0.9877\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1906 - acc: 0.9893\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1882 - acc: 0.9870\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1826 - acc: 0.9863\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1753 - acc: 0.9890\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1724 - acc: 0.9892\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1674 - acc: 0.9907\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1644 - acc: 0.9898\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1595 - acc: 0.9902\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1541 - acc: 0.9908\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1525 - acc: 0.9907\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1471 - acc: 0.9900\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1441 - acc: 0.9908\n",
      "Epoch 59/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1428 - acc: 0.9908\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1354 - acc: 0.9922\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC3D9670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5594 - acc: 0.7025\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6936 - acc: 0.5105\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6727 - acc: 0.7632\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6564 - acc: 0.8498\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6423 - acc: 0.9093\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6286 - acc: 0.9230\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6137 - acc: 0.9347\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6011 - acc: 0.9470\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5882 - acc: 0.9527\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5741 - acc: 0.9552\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5621 - acc: 0.9620\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5517 - acc: 0.9577\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5396 - acc: 0.9622\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5266 - acc: 0.9645\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5159 - acc: 0.9710\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5044 - acc: 0.9682\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4946 - acc: 0.9682\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4803 - acc: 0.9728\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4730 - acc: 0.9708\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4625 - acc: 0.9715\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4524 - acc: 0.9753\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4417 - acc: 0.9762\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4314 - acc: 0.9768\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4241 - acc: 0.9777\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4151 - acc: 0.9755\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4040 - acc: 0.9768\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3948 - acc: 0.9755\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3866 - acc: 0.9777\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3783 - acc: 0.9762\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3691 - acc: 0.9777\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3617 - acc: 0.9782\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3545 - acc: 0.9757\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3441 - acc: 0.9805\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3390 - acc: 0.9817\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3300 - acc: 0.9822\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3213 - acc: 0.9865\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3167 - acc: 0.9847\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3072 - acc: 0.9853\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2995 - acc: 0.9873\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2936 - acc: 0.9868\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2874 - acc: 0.9868\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2805 - acc: 0.9862\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2725 - acc: 0.9883\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2658 - acc: 0.9892\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2610 - acc: 0.9883\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2572 - acc: 0.9863\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2498 - acc: 0.9892\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2418 - acc: 0.9885\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2386 - acc: 0.9893\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2306 - acc: 0.9900\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2248 - acc: 0.9885\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2208 - acc: 0.9892\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2157 - acc: 0.9913\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2084 - acc: 0.9893\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2059 - acc: 0.9902\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1991 - acc: 0.9923\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1965 - acc: 0.9917\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1916 - acc: 0.9923\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1850 - acc: 0.9952\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1812 - acc: 0.9947\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1773 - acc: 0.9945\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D8F3AAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5519 - acc: 0.7275\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6914 - acc: 0.5390\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6741 - acc: 0.8170\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6605 - acc: 0.8870\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6476 - acc: 0.9167\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6345 - acc: 0.9297\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6216 - acc: 0.9332\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6100 - acc: 0.9460\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5981 - acc: 0.9488\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5868 - acc: 0.9582\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5753 - acc: 0.9568\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5652 - acc: 0.9575\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5538 - acc: 0.9645\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5432 - acc: 0.9652\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5331 - acc: 0.9702\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5234 - acc: 0.9675\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5122 - acc: 0.9698\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5034 - acc: 0.9677\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4924 - acc: 0.9672\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4825 - acc: 0.9713\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4741 - acc: 0.9695\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4626 - acc: 0.9715\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4546 - acc: 0.9735\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4468 - acc: 0.9740\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4354 - acc: 0.9773\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4279 - acc: 0.9738\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4175 - acc: 0.9753\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4100 - acc: 0.9775\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4025 - acc: 0.9735\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3915 - acc: 0.9747\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3836 - acc: 0.9780\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3755 - acc: 0.9790\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3682 - acc: 0.9763\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3579 - acc: 0.9783\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3524 - acc: 0.9777\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3434 - acc: 0.9788\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3374 - acc: 0.9805\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3306 - acc: 0.9805\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3213 - acc: 0.9790\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3165 - acc: 0.9800\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3090 - acc: 0.9807\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2993 - acc: 0.9798\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2949 - acc: 0.9780\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2879 - acc: 0.9815\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2815 - acc: 0.9817\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2761 - acc: 0.9802\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2702 - acc: 0.9808\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2638 - acc: 0.9815\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2550 - acc: 0.9823\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2515 - acc: 0.9817\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2445 - acc: 0.9837\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2413 - acc: 0.9797\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2339 - acc: 0.9837\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2288 - acc: 0.9853\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2236 - acc: 0.9870\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2170 - acc: 0.9873\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2140 - acc: 0.9878\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2092 - acc: 0.9870\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2059 - acc: 0.9892\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1974 - acc: 0.9885\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1948 - acc: 0.9892\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC2FDB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5615 - acc: 0.7038\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6949 - acc: 0.4903\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6632 - acc: 0.7890\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6420 - acc: 0.8528\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6227 - acc: 0.9002\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6067 - acc: 0.9203\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5923 - acc: 0.9290\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5783 - acc: 0.9337\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5660 - acc: 0.9407\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5510 - acc: 0.9403\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5397 - acc: 0.9383\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5262 - acc: 0.9470\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5145 - acc: 0.9488\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5030 - acc: 0.9507\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4921 - acc: 0.9537\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4796 - acc: 0.9613\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4689 - acc: 0.9607\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4609 - acc: 0.9593\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4480 - acc: 0.9607\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4387 - acc: 0.9608\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4273 - acc: 0.9637\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4191 - acc: 0.9645\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4084 - acc: 0.9677\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4005 - acc: 0.9662\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3917 - acc: 0.9692\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3812 - acc: 0.9722\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3729 - acc: 0.9748\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3645 - acc: 0.9708\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3587 - acc: 0.9717\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3489 - acc: 0.9753\n",
      "Epoch 30/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3425 - acc: 0.9718\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3356 - acc: 0.9718\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3245 - acc: 0.9747\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3206 - acc: 0.9763\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3107 - acc: 0.9770\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3005 - acc: 0.9818\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2962 - acc: 0.9783\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2915 - acc: 0.9773\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2841 - acc: 0.9820\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2763 - acc: 0.9835\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2696 - acc: 0.9817\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2638 - acc: 0.9830\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2571 - acc: 0.9825\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2486 - acc: 0.9850\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2462 - acc: 0.9845\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2373 - acc: 0.9853\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2364 - acc: 0.9853\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2297 - acc: 0.9873\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2230 - acc: 0.9870\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2174 - acc: 0.9877\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2137 - acc: 0.9877\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2090 - acc: 0.9863\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2029 - acc: 0.9885\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1983 - acc: 0.9885\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1936 - acc: 0.9872\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1886 - acc: 0.9885\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1841 - acc: 0.9902\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1794 - acc: 0.9915\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1746 - acc: 0.9922\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1723 - acc: 0.9908\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1649 - acc: 0.9937\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E8A4C0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5468 - acc: 0.7125\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6882 - acc: 0.5657\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6449 - acc: 0.8272\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6162 - acc: 0.8882\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5928 - acc: 0.9225\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5730 - acc: 0.9253\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5536 - acc: 0.9253\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5384 - acc: 0.9283\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5190 - acc: 0.9380\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5054 - acc: 0.9410\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4896 - acc: 0.9432\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4766 - acc: 0.9470\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4634 - acc: 0.9505\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4518 - acc: 0.9517\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4381 - acc: 0.9528\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4270 - acc: 0.9518\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4139 - acc: 0.9518\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4023 - acc: 0.9540\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3895 - acc: 0.9575\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3842 - acc: 0.9533\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3718 - acc: 0.9590\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3637 - acc: 0.9577\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3504 - acc: 0.9627\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3425 - acc: 0.9613\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3373 - acc: 0.9577\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3266 - acc: 0.9623\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3177 - acc: 0.9645\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3088 - acc: 0.9683\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2930 - acc: 0.974 - 0s 9ms/step - loss: 0.2981 - acc: 0.9697\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2927 - acc: 0.9708\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2868 - acc: 0.9723\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2783 - acc: 0.9760\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2685 - acc: 0.9777\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2636 - acc: 0.9797\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2580 - acc: 0.9777\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2549 - acc: 0.9765\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2409 - acc: 0.9822\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2364 - acc: 0.9837\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2293 - acc: 0.9867\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2235 - acc: 0.9867\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2200 - acc: 0.9848\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2133 - acc: 0.9862\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2096 - acc: 0.9870\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2023 - acc: 0.9898\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1986 - acc: 0.9885\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1937 - acc: 0.9878\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1858 - acc: 0.9892\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1810 - acc: 0.9900\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1796 - acc: 0.9887\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1734 - acc: 0.9887\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1685 - acc: 0.9907\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1663 - acc: 0.9908\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1577 - acc: 0.9922\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1558 - acc: 0.9908\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1545 - acc: 0.9908\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1473 - acc: 0.9937\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1428 - acc: 0.9928\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1398 - acc: 0.9930\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1358 - acc: 0.9945\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1350 - acc: 0.9932\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1292 - acc: 0.9945\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDFE5310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5570 - acc: 0.6988\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6925 - acc: 0.4987\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6824 - acc: 0.6128\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6718 - acc: 0.6152\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6626 - acc: 0.7177\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6514 - acc: 0.7297\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6401 - acc: 0.7588\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6287 - acc: 0.7807\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6166 - acc: 0.8177\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6052 - acc: 0.8417\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5917 - acc: 0.8543\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5817 - acc: 0.8840\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5683 - acc: 0.8897\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5583 - acc: 0.9052\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5440 - acc: 0.9120\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5326 - acc: 0.9137\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5202 - acc: 0.9147\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5078 - acc: 0.9255\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4957 - acc: 0.9248\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4854 - acc: 0.9303\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4736 - acc: 0.9365\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4605 - acc: 0.9482\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4536 - acc: 0.9513\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4443 - acc: 0.9503\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4287 - acc: 0.9562\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4199 - acc: 0.9598\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4099 - acc: 0.9643\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4005 - acc: 0.9663\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3880 - acc: 0.9727\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3817 - acc: 0.9707\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3715 - acc: 0.9730\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3596 - acc: 0.9760\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3514 - acc: 0.9805\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3438 - acc: 0.9788\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3333 - acc: 0.9795\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3236 - acc: 0.9828\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3149 - acc: 0.9828\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3061 - acc: 0.9795\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2979 - acc: 0.9818\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2885 - acc: 0.9852\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2794 - acc: 0.9877\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2745 - acc: 0.9877\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2603 - acc: 0.9905\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2524 - acc: 0.9943\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2462 - acc: 0.9945\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2385 - acc: 0.9932\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2338 - acc: 0.9932\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2214 - acc: 0.9945\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2198 - acc: 0.9947\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2113 - acc: 0.9962\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2033 - acc: 0.9955\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1918 - acc: 0.9962\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1872 - acc: 0.9962\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1808 - acc: 0.9968\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1703 - acc: 0.9975\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1632 - acc: 0.9962\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1571 - acc: 0.9962\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1511 - acc: 0.9962\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1422 - acc: 0.9977\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1353 - acc: 0.9977\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1295 - acc: 0.9970\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0DA780AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6402 - acc: 0.6875\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6927 - acc: 0.5028\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6830 - acc: 0.7313\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6739 - acc: 0.8552\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6641 - acc: 0.9355\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6537 - acc: 0.9392\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6420 - acc: 0.9485\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6301 - acc: 0.9597\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6175 - acc: 0.9640\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6052 - acc: 0.9657\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5926 - acc: 0.9717\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5794 - acc: 0.9707\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5658 - acc: 0.9765\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5526 - acc: 0.9782\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5387 - acc: 0.9798\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5254 - acc: 0.9805\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5124 - acc: 0.9805\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4975 - acc: 0.9800\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4837 - acc: 0.9802\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4712 - acc: 0.9835\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4565 - acc: 0.9823\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4446 - acc: 0.9832\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4301 - acc: 0.9825\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4149 - acc: 0.9857\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4018 - acc: 0.9855\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3895 - acc: 0.9868\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3746 - acc: 0.9868\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3617 - acc: 0.9868\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3490 - acc: 0.9868\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3364 - acc: 0.9862\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3227 - acc: 0.9870\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3117 - acc: 0.9890\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2987 - acc: 0.9898\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2879 - acc: 0.9885\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2753 - acc: 0.9885\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2650 - acc: 0.9885\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2536 - acc: 0.9892\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2448 - acc: 0.9885\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2336 - acc: 0.9885\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2221 - acc: 0.9893\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2130 - acc: 0.9907\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2036 - acc: 0.9900\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1937 - acc: 0.9928\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1848 - acc: 0.9922\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1788 - acc: 0.9915\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1689 - acc: 0.9928\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1612 - acc: 0.9900\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1541 - acc: 0.9915\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1476 - acc: 0.9922\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1386 - acc: 0.9915\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1328 - acc: 0.9915\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1295 - acc: 0.9902\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1220 - acc: 0.9908\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1173 - acc: 0.9917\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1106 - acc: 0.9923\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1069 - acc: 0.9917\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0997 - acc: 0.9945\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0976 - acc: 0.9923\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0920 - acc: 0.9932\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0856 - acc: 0.9952\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0812 - acc: 0.9930\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED7F9E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5663 - acc: 0.7075\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6929 - acc: 0.5197\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6665 - acc: 0.8018\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6478 - acc: 0.8817\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6275 - acc: 0.9075\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6094 - acc: 0.9248\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5903 - acc: 0.9298\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5730 - acc: 0.9335\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5540 - acc: 0.9433\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5370 - acc: 0.9555\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5200 - acc: 0.9577\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5030 - acc: 0.9593\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4870 - acc: 0.9587\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4717 - acc: 0.966 - 0s 9ms/step - loss: 0.4708 - acc: 0.9628\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4542 - acc: 0.9680\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4389 - acc: 0.9667\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4263 - acc: 0.9685\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4094 - acc: 0.9685\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3945 - acc: 0.9718\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3828 - acc: 0.9728\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3700 - acc: 0.9732\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3552 - acc: 0.9742\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3431 - acc: 0.9755\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3317 - acc: 0.9747\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3183 - acc: 0.9757\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3093 - acc: 0.9785\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2972 - acc: 0.9792\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2860 - acc: 0.9807\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2748 - acc: 0.9837\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2660 - acc: 0.9832\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2542 - acc: 0.9860\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2457 - acc: 0.9878\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2381 - acc: 0.9893\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2267 - acc: 0.9907\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2191 - acc: 0.9887\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2084 - acc: 0.9928\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2008 - acc: 0.9945\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1930 - acc: 0.9962\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1855 - acc: 0.9955\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1792 - acc: 0.9962\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1726 - acc: 0.9962\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1659 - acc: 0.9968\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1569 - acc: 0.9975\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1527 - acc: 0.9962\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1462 - acc: 0.9955\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1394 - acc: 0.9968\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1351 - acc: 0.9970\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1286 - acc: 0.9977\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1233 - acc: 0.9977\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1184 - acc: 0.9977\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1138 - acc: 0.9970\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1093 - acc: 0.9983\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1042 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1000 - acc: 0.9985\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0945 - acc: 0.9992\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0915 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0878 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0846 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0791 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0780 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0740 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC3D9430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5953 - acc: 0.7150\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6912 - acc: 0.5447\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6591 - acc: 0.7772\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6337 - acc: 0.8563\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6092 - acc: 0.8953\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5862 - acc: 0.9200\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5638 - acc: 0.9313\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5430 - acc: 0.9395\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5232 - acc: 0.9372\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5039 - acc: 0.9437\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4830 - acc: 0.9475\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4678 - acc: 0.9498\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4497 - acc: 0.9553\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4321 - acc: 0.9528\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4143 - acc: 0.9598\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3976 - acc: 0.9605\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3851 - acc: 0.9638\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3681 - acc: 0.9707\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3559 - acc: 0.9717\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3411 - acc: 0.9733\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3297 - acc: 0.9725\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3146 - acc: 0.9787\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3023 - acc: 0.9790\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2909 - acc: 0.9793\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2784 - acc: 0.9793\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2695 - acc: 0.9808\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2553 - acc: 0.9828\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2470 - acc: 0.9838\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2386 - acc: 0.9853\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2285 - acc: 0.9877\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2183 - acc: 0.9877\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2102 - acc: 0.9885\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2006 - acc: 0.9907\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1936 - acc: 0.9907\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1845 - acc: 0.9907\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1785 - acc: 0.9915\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1730 - acc: 0.9902\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1629 - acc: 0.9913\n",
      "Epoch 38/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1580 - acc: 0.9915\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1504 - acc: 0.9928\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1446 - acc: 0.9930\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1392 - acc: 0.9923\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1343 - acc: 0.9893\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1290 - acc: 0.9917\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1225 - acc: 0.9928\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1189 - acc: 0.9917\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1121 - acc: 0.9937\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1092 - acc: 0.9923\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1022 - acc: 0.9930\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1001 - acc: 0.9908\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0965 - acc: 0.9908\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0913 - acc: 0.9930\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0896 - acc: 0.9930\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0858 - acc: 0.9908\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0807 - acc: 0.9922\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0783 - acc: 0.9953\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0747 - acc: 0.9945\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0712 - acc: 0.9945\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0699 - acc: 0.9953\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0662 - acc: 0.9960\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0659 - acc: 0.9947\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0FB9BD670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6135 - acc: 0.7038\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 0.6937 - acc: 0.5058\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6832 - acc: 0.6247\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6714 - acc: 0.6458\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6580 - acc: 0.7178\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6424 - acc: 0.7828\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6295 - acc: 0.8202\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6125 - acc: 0.7955\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5978 - acc: 0.8555\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5817 - acc: 0.8480\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5647 - acc: 0.8868\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5496 - acc: 0.8948\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5341 - acc: 0.9075\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5210 - acc: 0.9158\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5039 - acc: 0.9237\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4884 - acc: 0.9363\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4759 - acc: 0.9392\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4592 - acc: 0.9397\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.9557\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4336 - acc: 0.9498\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4182 - acc: 0.9663\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4041 - acc: 0.9677\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3954 - acc: 0.9763\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3786 - acc: 0.9755\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3673 - acc: 0.9858\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3566 - acc: 0.9835\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3452 - acc: 0.9865\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3351 - acc: 0.9840\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3177 - acc: 0.9862\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3133 - acc: 0.9907\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2962 - acc: 0.9913\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2911 - acc: 0.990 - 0s 10ms/step - loss: 0.2882 - acc: 0.9908\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2793 - acc: 0.9938\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2662 - acc: 0.9953\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2539 - acc: 0.9962\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2443 - acc: 0.9962\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2305 - acc: 0.9977\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2228 - acc: 0.9977\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2100 - acc: 0.9985\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2031 - acc: 0.9985\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1931 - acc: 0.9985\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1835 - acc: 0.9992\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1709 - acc: 0.9992\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1634 - acc: 0.9985\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1541 - acc: 0.9992\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1457 - acc: 1.0000\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1367 - acc: 1.0000\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1307 - acc: 1.0000\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1218 - acc: 1.0000\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1129 - acc: 1.0000\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1086 - acc: 1.0000\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0995 - acc: 1.0000\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0954 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0880 - acc: 1.0000\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0814 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0757 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0707 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0668 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0608 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0568 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0532 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED8061F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7617 - acc: 0.6862\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 0.6930 - acc: 0.5245\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6889 - acc: 0.5320\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6834 - acc: 0.5232\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6769 - acc: 0.5427\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6701 - acc: 0.6125\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6616 - acc: 0.6293\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6517 - acc: 0.7257\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6420 - acc: 0.7948\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6319 - acc: 0.8217\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6198 - acc: 0.8405\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6086 - acc: 0.8907\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5978 - acc: 0.8887\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5850 - acc: 0.9025\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5723 - acc: 0.9220\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5583 - acc: 0.9303\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5458 - acc: 0.9308\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5339 - acc: 0.9352\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5215 - acc: 0.9395\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5048 - acc: 0.9453\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4917 - acc: 0.9540\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4789 - acc: 0.9593\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4640 - acc: 0.9600\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4513 - acc: 0.9623\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4366 - acc: 0.9685\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4221 - acc: 0.9687\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4026 - acc: 0.9748\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3876 - acc: 0.9758\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3764 - acc: 0.982 - 0s 10ms/step - loss: 0.3753 - acc: 0.9765\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3583 - acc: 0.9798\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3439 - acc: 0.9822\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3283 - acc: 0.9837\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3125 - acc: 0.9840\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2956 - acc: 0.9897\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2843 - acc: 0.9863\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2712 - acc: 0.9878\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2535 - acc: 0.9870\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2388 - acc: 0.9905\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2264 - acc: 0.9900\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2121 - acc: 0.9922\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2005 - acc: 0.9930\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1885 - acc: 0.9917\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1764 - acc: 0.9930\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1648 - acc: 0.9915\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1554 - acc: 0.9923\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1437 - acc: 0.9947\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1359 - acc: 0.9960\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1257 - acc: 0.9945\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1194 - acc: 0.9955\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1113 - acc: 0.9947\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1027 - acc: 0.9962\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0978 - acc: 0.9955\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0904 - acc: 0.9955\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0845 - acc: 0.9962\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0796 - acc: 0.9962\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0731 - acc: 0.9962\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0666 - acc: 0.9960\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0647 - acc: 0.9955\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0566 - acc: 0.9975\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0558 - acc: 0.9947\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0518 - acc: 0.9968\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EBF5ECA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6549 - acc: 0.7025\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6929 - acc: 0.5152\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6650 - acc: 0.7938\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6388 - acc: 0.8707\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6070 - acc: 0.9230\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5752 - acc: 0.9248\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5410 - acc: 0.9405\n",
      "Epoch 7/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5086 - acc: 0.9463\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4765 - acc: 0.9537\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4469 - acc: 0.9600\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4171 - acc: 0.9608\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3901 - acc: 0.9603\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3641 - acc: 0.9648\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3377 - acc: 0.9670\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3181 - acc: 0.9738\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2957 - acc: 0.9712\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2709 - acc: 0.9788\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2550 - acc: 0.9828\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2341 - acc: 0.9828\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2186 - acc: 0.9877\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2048 - acc: 0.9863\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1874 - acc: 0.9913\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1764 - acc: 0.9930\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1658 - acc: 0.9940\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1507 - acc: 0.9953\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1405 - acc: 0.9955\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1321 - acc: 0.9962\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1211 - acc: 0.9970\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1135 - acc: 0.9977\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1021 - acc: 0.9977\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0956 - acc: 0.9977\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0888 - acc: 0.9977\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0819 - acc: 0.9992\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0756 - acc: 0.9992\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0721 - acc: 1.0000\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0664 - acc: 1.0000\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0614 - acc: 1.0000\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0567 - acc: 1.0000\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0519 - acc: 1.0000\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0489 - acc: 1.0000\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0460 - acc: 1.0000\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0426 - acc: 1.0000\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0396 - acc: 1.0000\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0373 - acc: 1.0000\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0347 - acc: 1.0000\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0321 - acc: 1.0000\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0302 - acc: 1.0000\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0277 - acc: 1.0000\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0246 - acc: 1.0000\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0215 - acc: 1.0000\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0199 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0120 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0CBC7A280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8188 - acc: 0.7150\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 0.6940 - acc: 0.5002\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6614 - acc: 0.7772\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6303 - acc: 0.8568\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5974 - acc: 0.8982\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5636 - acc: 0.9232\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5280 - acc: 0.9387\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4952 - acc: 0.9432\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4622 - acc: 0.9465\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4283 - acc: 0.9492\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4002 - acc: 0.9553\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3704 - acc: 0.9623\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3427 - acc: 0.9658\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3208 - acc: 0.9625\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2976 - acc: 0.9723\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2757 - acc: 0.9758\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2529 - acc: 0.9798\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2360 - acc: 0.9845\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2171 - acc: 0.9892\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2016 - acc: 0.9890\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1870 - acc: 0.9913\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1753 - acc: 0.9902\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1639 - acc: 0.9923\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1516 - acc: 0.9930\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1406 - acc: 0.9917\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1315 - acc: 0.9932\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1200 - acc: 0.9938\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1144 - acc: 0.9925\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1036 - acc: 0.9938\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0978 - acc: 0.9925\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0883 - acc: 0.9945\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0844 - acc: 0.9938\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0779 - acc: 0.9945\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0754 - acc: 0.9917\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0699 - acc: 0.9940\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0663 - acc: 0.9938\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0610 - acc: 0.9953\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0563 - acc: 0.9960\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0532 - acc: 0.9968\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0501 - acc: 0.9962\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0460 - acc: 0.9968\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0444 - acc: 0.9962\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0419 - acc: 0.9953\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0411 - acc: 0.9955\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0361 - acc: 0.9975\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0361 - acc: 0.9962\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0332 - acc: 0.9968\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0313 - acc: 0.9968\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0320 - acc: 0.9962\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0294 - acc: 0.9968\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0284 - acc: 0.9947\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0269 - acc: 0.9962\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0268 - acc: 0.9955\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0244 - acc: 0.9968\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0229 - acc: 0.9953\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0216 - acc: 0.9962\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0215 - acc: 0.9962\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0190 - acc: 0.9968\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0179 - acc: 0.9968\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0177 - acc: 0.9962\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0180 - acc: 0.9947\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0FB9BD8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8174 - acc: 0.7088\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6928 - acc: 0.5158\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6740 - acc: 0.8093\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6594 - acc: 0.8850\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6451 - acc: 0.9108\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6297 - acc: 0.9297\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6156 - acc: 0.9405\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6016 - acc: 0.9417\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5874 - acc: 0.9453\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5759 - acc: 0.9447\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5610 - acc: 0.9448\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5486 - acc: 0.9528\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5363 - acc: 0.9493\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5243 - acc: 0.9572\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5111 - acc: 0.9645\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5013 - acc: 0.9603\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4900 - acc: 0.9588\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4773 - acc: 0.9648\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4690 - acc: 0.9633\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4573 - acc: 0.9662\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4468 - acc: 0.9633\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4370 - acc: 0.9662\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4261 - acc: 0.9653\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4152 - acc: 0.9685\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4062 - acc: 0.9705\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3959 - acc: 0.9715\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3881 - acc: 0.9728\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3794 - acc: 0.9742\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3699 - acc: 0.9715\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3625 - acc: 0.9712\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3515 - acc: 0.9737\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3434 - acc: 0.9722\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3370 - acc: 0.9688\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3264 - acc: 0.9743\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3184 - acc: 0.9782\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3148 - acc: 0.972 - 0s 9ms/step - loss: 0.3125 - acc: 0.9748\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3050 - acc: 0.9792\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2971 - acc: 0.9785\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2881 - acc: 0.9807\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2818 - acc: 0.9807\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2741 - acc: 0.9802\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2659 - acc: 0.9837\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2592 - acc: 0.9850\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2550 - acc: 0.9823\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2488 - acc: 0.9823\n",
      "Epoch 45/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2428 - acc: 0.9838\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2338 - acc: 0.9838\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2311 - acc: 0.9853\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2243 - acc: 0.9847\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2184 - acc: 0.9853\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2130 - acc: 0.9847\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2059 - acc: 0.9867\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2017 - acc: 0.9883\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1975 - acc: 0.9877\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1911 - acc: 0.9883\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1870 - acc: 0.9885\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1831 - acc: 0.9898\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1772 - acc: 0.9892\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1720 - acc: 0.9878\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1680 - acc: 0.9892\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1645 - acc: 0.9900\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1579 - acc: 0.9922\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1547 - acc: 0.9925\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1499 - acc: 0.9945\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1498 - acc: 0.9947\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1415 - acc: 0.9953\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1391 - acc: 0.9947\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1352 - acc: 0.9967\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1322 - acc: 0.9975\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1275 - acc: 0.9962\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1227 - acc: 0.9968\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC3D9310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5493 - acc: 0.7237\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6930 - acc: 0.4993\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6760 - acc: 0.8138\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6619 - acc: 0.8897\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6485 - acc: 0.9185\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6352 - acc: 0.9282\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6233 - acc: 0.9310\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6099 - acc: 0.9462\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5972 - acc: 0.9482\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5860 - acc: 0.9527\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5739 - acc: 0.9603\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5630 - acc: 0.9557\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5506 - acc: 0.9587\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5398 - acc: 0.9607\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5290 - acc: 0.9578\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5196 - acc: 0.9575\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5083 - acc: 0.9588\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4971 - acc: 0.9595\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4864 - acc: 0.9595\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4760 - acc: 0.9618\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4646 - acc: 0.9667\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4557 - acc: 0.9660\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4450 - acc: 0.9705\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4354 - acc: 0.9715\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4259 - acc: 0.9708\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4189 - acc: 0.9682\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4092 - acc: 0.9708\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4003 - acc: 0.9697\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3883 - acc: 0.9723\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3812 - acc: 0.9738\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3694 - acc: 0.9773\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3662 - acc: 0.9747\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3555 - acc: 0.9805\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3471 - acc: 0.9777\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3387 - acc: 0.9798\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3331 - acc: 0.9800\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3219 - acc: 0.9787\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3173 - acc: 0.9807\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3079 - acc: 0.9825\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3024 - acc: 0.9817\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2942 - acc: 0.9852\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2873 - acc: 0.9832\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2791 - acc: 0.9823\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2741 - acc: 0.9845\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2675 - acc: 0.9862\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2590 - acc: 0.9892\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2526 - acc: 0.9905\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2481 - acc: 0.9885\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2428 - acc: 0.9878\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2373 - acc: 0.9900\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2318 - acc: 0.9907\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2237 - acc: 0.9920\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2209 - acc: 0.9900\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2140 - acc: 0.9893\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2068 - acc: 0.9907\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2032 - acc: 0.9913\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1983 - acc: 0.9893\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1928 - acc: 0.9893\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1899 - acc: 0.9880\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1822 - acc: 0.9900\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1794 - acc: 0.9907\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1740 - acc: 0.9900\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1724 - acc: 0.9900\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1688 - acc: 0.9887\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1624 - acc: 0.9893\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1567 - acc: 0.9907\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1529 - acc: 0.9907\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1489 - acc: 0.9907\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1454 - acc: 0.9915\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1415 - acc: 0.9902\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1384 - acc: 0.9915\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC2FD940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5562 - acc: 0.7050\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6964 - acc: 0.4742\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6739 - acc: 0.7493\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6578 - acc: 0.8398\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6435 - acc: 0.8720\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6296 - acc: 0.8973\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6171 - acc: 0.9120\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6057 - acc: 0.9253\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5943 - acc: 0.9263\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5830 - acc: 0.9325\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.5744 - acc: 0.926 - 0s 8ms/step - loss: 0.5724 - acc: 0.9320\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5622 - acc: 0.9388\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5496 - acc: 0.9363\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5391 - acc: 0.9515\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5307 - acc: 0.9495\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5192 - acc: 0.9543\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5097 - acc: 0.9545\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5008 - acc: 0.9535\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4908 - acc: 0.9548\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4811 - acc: 0.9587\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4700 - acc: 0.9598\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4624 - acc: 0.9610\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4542 - acc: 0.9617\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4437 - acc: 0.9647\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4352 - acc: 0.9660\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4262 - acc: 0.9640\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4175 - acc: 0.9653\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4105 - acc: 0.9635\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4008 - acc: 0.9685\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3930 - acc: 0.9683\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3841 - acc: 0.9698\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3765 - acc: 0.9707\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3695 - acc: 0.9715\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3598 - acc: 0.9748\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3552 - acc: 0.9718\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3452 - acc: 0.9737\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3378 - acc: 0.9752\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3326 - acc: 0.9740\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3264 - acc: 0.9738\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3184 - acc: 0.9798\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3124 - acc: 0.9742\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3063 - acc: 0.9798\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2993 - acc: 0.9753\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2904 - acc: 0.9785\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2850 - acc: 0.9792\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2795 - acc: 0.9792\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2727 - acc: 0.9807\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2709 - acc: 0.9808\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2641 - acc: 0.9822\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2588 - acc: 0.9830\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2528 - acc: 0.9840\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2462 - acc: 0.9847\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2414 - acc: 0.9853\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2351 - acc: 0.9860\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2334 - acc: 0.9873\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2251 - acc: 0.9860\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2157 - acc: 0.9873\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2144 - acc: 0.9863\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2103 - acc: 0.9870\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2036 - acc: 0.9877\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2006 - acc: 0.9870\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1961 - acc: 0.9877\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1937 - acc: 0.9885\n",
      "Epoch 63/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1894 - acc: 0.9892\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1827 - acc: 0.9898\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1763 - acc: 0.9915\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1739 - acc: 0.9922\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1698 - acc: 0.9937\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1697 - acc: 0.9932\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1631 - acc: 0.9917\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1599 - acc: 0.9930\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC0990D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5455 - acc: 0.7262\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6957 - acc: 0.4758\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6540 - acc: 0.8142\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6277 - acc: 0.8623\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6040 - acc: 0.8972\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5838 - acc: 0.9082\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5659 - acc: 0.9222\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5492 - acc: 0.9272\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5335 - acc: 0.9317\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5184 - acc: 0.9382\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5048 - acc: 0.9408\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4916 - acc: 0.9437\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4783 - acc: 0.9397\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4653 - acc: 0.9410\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4522 - acc: 0.9440\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4397 - acc: 0.9462\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4289 - acc: 0.9483\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4185 - acc: 0.9535\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4088 - acc: 0.9508\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3941 - acc: 0.9543\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3870 - acc: 0.9550\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3737 - acc: 0.9590\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3664 - acc: 0.9618\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3572 - acc: 0.9615\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3472 - acc: 0.9665\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3373 - acc: 0.9645\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3292 - acc: 0.9625\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3206 - acc: 0.9625\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3140 - acc: 0.9642\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3028 - acc: 0.9720\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2961 - acc: 0.9708\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2892 - acc: 0.9725\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2831 - acc: 0.9768\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2738 - acc: 0.9780\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2696 - acc: 0.9787\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2615 - acc: 0.9798\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2529 - acc: 0.9813\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2452 - acc: 0.9800\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2429 - acc: 0.9787\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2355 - acc: 0.9815\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2308 - acc: 0.9810\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2259 - acc: 0.9823\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2174 - acc: 0.9837\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2127 - acc: 0.9853\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2087 - acc: 0.9860\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2050 - acc: 0.9862\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1980 - acc: 0.9860\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1917 - acc: 0.9862\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1872 - acc: 0.9883\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1827 - acc: 0.9863\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1774 - acc: 0.9868\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1772 - acc: 0.9878\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1696 - acc: 0.9900\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1646 - acc: 0.9885\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1609 - acc: 0.9878\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1572 - acc: 0.9872\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1533 - acc: 0.9893\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1467 - acc: 0.9922\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1438 - acc: 0.9922\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1403 - acc: 0.9928\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1363 - acc: 0.9908\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1343 - acc: 0.9930\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1281 - acc: 0.9937\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1265 - acc: 0.9925\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1236 - acc: 0.9932\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1227 - acc: 0.9925\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1187 - acc: 0.9945\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1141 - acc: 0.9923\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1101 - acc: 0.9945\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1086 - acc: 0.9945\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1073 - acc: 0.9923\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F24634C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5618 - acc: 0.7000\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6922 - acc: 0.5028\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6706 - acc: 0.8318\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6543 - acc: 0.9110\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6390 - acc: 0.9445\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6242 - acc: 0.9510\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6091 - acc: 0.9572\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5960 - acc: 0.9577\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5806 - acc: 0.9628\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5679 - acc: 0.9625\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5548 - acc: 0.9647\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5409 - acc: 0.9682\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5293 - acc: 0.9728\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5163 - acc: 0.9712\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5057 - acc: 0.9713\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4937 - acc: 0.9732\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4840 - acc: 0.9702\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4701 - acc: 0.9715\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4595 - acc: 0.9700\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4497 - acc: 0.9710\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4389 - acc: 0.9745\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4283 - acc: 0.9730\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4180 - acc: 0.9753\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4078 - acc: 0.9787\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3993 - acc: 0.9747\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3895 - acc: 0.9767\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3791 - acc: 0.9753\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3708 - acc: 0.9775\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3607 - acc: 0.9785\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3529 - acc: 0.9820\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3454 - acc: 0.9822\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3368 - acc: 0.9838\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3290 - acc: 0.9810\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3208 - acc: 0.9838\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3128 - acc: 0.9838\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3049 - acc: 0.9847\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2967 - acc: 0.9832\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2902 - acc: 0.9847\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2826 - acc: 0.9838\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2745 - acc: 0.9847\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2686 - acc: 0.9827\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2617 - acc: 0.9860\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2558 - acc: 0.9847\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2493 - acc: 0.9847\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2416 - acc: 0.9862\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2336 - acc: 0.9913\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2286 - acc: 0.9883\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2283 - acc: 0.990 - 0s 9ms/step - loss: 0.2255 - acc: 0.9908\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2179 - acc: 0.9913\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2126 - acc: 0.9937\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2068 - acc: 0.9930\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2026 - acc: 0.9917\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1977 - acc: 0.9917\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1912 - acc: 0.9923\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1867 - acc: 0.9930\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1814 - acc: 0.9932\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1766 - acc: 0.9938\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1706 - acc: 0.9958\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1674 - acc: 0.9953\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1619 - acc: 0.9952\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1598 - acc: 0.9960\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1548 - acc: 0.9962\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1502 - acc: 0.9947\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1475 - acc: 0.9962\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1409 - acc: 0.9968\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1401 - acc: 0.9962\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1353 - acc: 0.9955\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1326 - acc: 0.9962\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1272 - acc: 0.9962\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1251 - acc: 0.9955\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1238 - acc: 0.9955\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED6CC3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5493 - acc: 0.7275\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 10ms/step - loss: 0.6928 - acc: 0.5160\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6791 - acc: 0.7562\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6681 - acc: 0.8428\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6567 - acc: 0.8652\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6466 - acc: 0.8913\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6363 - acc: 0.8963\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6237 - acc: 0.9102\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6140 - acc: 0.9180\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6035 - acc: 0.9218\n",
      "Epoch 10/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5912 - acc: 0.9338\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5809 - acc: 0.9315\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5706 - acc: 0.9405\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5588 - acc: 0.9332\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5492 - acc: 0.9448\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5388 - acc: 0.9418\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5271 - acc: 0.9452\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5163 - acc: 0.9453\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5079 - acc: 0.9433\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4961 - acc: 0.9468\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4886 - acc: 0.9515\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4758 - acc: 0.9552\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4676 - acc: 0.9540\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4573 - acc: 0.9527\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4488 - acc: 0.9588\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4389 - acc: 0.9577\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4312 - acc: 0.9593\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4239 - acc: 0.9622\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4149 - acc: 0.9633\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4032 - acc: 0.9665\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3952 - acc: 0.9662\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3870 - acc: 0.9683\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3826 - acc: 0.9678\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3724 - acc: 0.9672\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3631 - acc: 0.9695\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3545 - acc: 0.9737\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3446 - acc: 0.9758\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3397 - acc: 0.9748\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3300 - acc: 0.9787\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3238 - acc: 0.9792\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3172 - acc: 0.9798\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3098 - acc: 0.9772\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3012 - acc: 0.9805\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2936 - acc: 0.9798\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2926 - acc: 0.9802\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2822 - acc: 0.9837\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2748 - acc: 0.9838\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2671 - acc: 0.9850\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2637 - acc: 0.9853\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2588 - acc: 0.9825\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2522 - acc: 0.9868\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2437 - acc: 0.9845\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2410 - acc: 0.9855\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2340 - acc: 0.9855\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2289 - acc: 0.9855\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2214 - acc: 0.9855\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2156 - acc: 0.9875\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2130 - acc: 0.9877\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2048 - acc: 0.9877\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2015 - acc: 0.9857\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1975 - acc: 0.9863\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1914 - acc: 0.9905\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1873 - acc: 0.9900\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1834 - acc: 0.9893\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1789 - acc: 0.9900\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1731 - acc: 0.9887\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1688 - acc: 0.9887\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1662 - acc: 0.9907\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1607 - acc: 0.9900\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1566 - acc: 0.9922\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1556 - acc: 0.9908\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC2FDEE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5605 - acc: 0.7088\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6910 - acc: 0.5555\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6659 - acc: 0.8518\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6477 - acc: 0.8948\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6331 - acc: 0.9185\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6188 - acc: 0.9278\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6061 - acc: 0.9323\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5939 - acc: 0.9397\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5832 - acc: 0.9420\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5717 - acc: 0.9422\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5613 - acc: 0.9460\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5516 - acc: 0.9478\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5412 - acc: 0.9535\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5302 - acc: 0.9533\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5209 - acc: 0.9537\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5090 - acc: 0.9598\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5015 - acc: 0.9577\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4908 - acc: 0.9617\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4832 - acc: 0.9617\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4733 - acc: 0.9632\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4648 - acc: 0.9645\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4577 - acc: 0.9613\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4479 - acc: 0.9647\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4375 - acc: 0.9672\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4307 - acc: 0.9670\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4240 - acc: 0.9665\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4141 - acc: 0.9710\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4047 - acc: 0.9738\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3971 - acc: 0.9765\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3939 - acc: 0.9725\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3846 - acc: 0.9732\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3759 - acc: 0.9740\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3672 - acc: 0.9780\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3646 - acc: 0.9755\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3549 - acc: 0.9768\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3471 - acc: 0.9778\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3405 - acc: 0.9798\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3332 - acc: 0.9785\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3259 - acc: 0.9820\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3242 - acc: 0.9802\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3149 - acc: 0.9817\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3080 - acc: 0.9828\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3002 - acc: 0.9832\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2960 - acc: 0.9865\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2903 - acc: 0.9868\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2826 - acc: 0.9868\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2784 - acc: 0.9868\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2732 - acc: 0.9853\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2698 - acc: 0.9877\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2626 - acc: 0.9877\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2559 - acc: 0.9883\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2500 - acc: 0.9868\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2468 - acc: 0.9898\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2410 - acc: 0.9892\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2362 - acc: 0.9892\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2294 - acc: 0.9885\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2263 - acc: 0.9913\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2240 - acc: 0.9908\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2166 - acc: 0.9893\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2111 - acc: 0.9923\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2100 - acc: 0.9917\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2046 - acc: 0.9923\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2003 - acc: 0.9932\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1961 - acc: 0.9938\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1913 - acc: 0.9953\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1874 - acc: 0.9947\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1816 - acc: 0.9947\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1789 - acc: 0.9940\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1739 - acc: 0.9953\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1707 - acc: 0.9968\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1688 - acc: 0.9955\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D307EB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5556 - acc: 0.7175\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6915 - acc: 0.5350\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6620 - acc: 0.7697\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6407 - acc: 0.8422\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6224 - acc: 0.8810\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6065 - acc: 0.9047\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5919 - acc: 0.9133\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5779 - acc: 0.9182\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5632 - acc: 0.9242\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5519 - acc: 0.9258\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5379 - acc: 0.9305\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5275 - acc: 0.9403\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5134 - acc: 0.9458\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5038 - acc: 0.9458\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4911 - acc: 0.9512\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4815 - acc: 0.9480\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4706 - acc: 0.9468\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4582 - acc: 0.9527\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4481 - acc: 0.9535\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4389 - acc: 0.9482\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4314 - acc: 0.9492\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4206 - acc: 0.9555\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4099 - acc: 0.9568\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4006 - acc: 0.9582\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3908 - acc: 0.9575\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3857 - acc: 0.9555\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3773 - acc: 0.9535\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3685 - acc: 0.9568\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3599 - acc: 0.9543\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3506 - acc: 0.9577\n",
      "Epoch 30/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3419 - acc: 0.9620\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3371 - acc: 0.9580\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3263 - acc: 0.9652\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3206 - acc: 0.9663\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3129 - acc: 0.9662\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3066 - acc: 0.9715\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2966 - acc: 0.978 - 0s 8ms/step - loss: 0.2976 - acc: 0.9760\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2920 - acc: 0.9755\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2866 - acc: 0.9777\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2816 - acc: 0.9792\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2714 - acc: 0.9792\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2655 - acc: 0.9785\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2592 - acc: 0.9813\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2520 - acc: 0.9800\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2480 - acc: 0.9823\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2430 - acc: 0.9817\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2351 - acc: 0.9830\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2311 - acc: 0.9845\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2252 - acc: 0.9832\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2198 - acc: 0.9832\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2139 - acc: 0.9847\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2081 - acc: 0.9882\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2035 - acc: 0.9890\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2020 - acc: 0.9868\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1937 - acc: 0.9898\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1910 - acc: 0.9878\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1871 - acc: 0.9872\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1841 - acc: 0.9872\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1789 - acc: 0.9905\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1735 - acc: 0.9922\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1687 - acc: 0.9915\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1668 - acc: 0.9922\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1633 - acc: 0.9908\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1591 - acc: 0.9930\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1539 - acc: 0.9908\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1517 - acc: 0.9922\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1472 - acc: 0.9937\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1429 - acc: 0.9937\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1415 - acc: 0.9908\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1386 - acc: 0.9917\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1351 - acc: 0.9923\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC3D9790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5578 - acc: 0.7013\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6932 - acc: 0.5035\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6817 - acc: 0.7817\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6713 - acc: 0.8532\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6587 - acc: 0.9082\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6468 - acc: 0.9390\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6337 - acc: 0.9482\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6197 - acc: 0.9550\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6059 - acc: 0.9590\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5904 - acc: 0.9688\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.5759 - acc: 0.9693\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5606 - acc: 0.9732\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5445 - acc: 0.9792\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5293 - acc: 0.9778\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5152 - acc: 0.9808\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4977 - acc: 0.9815\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4831 - acc: 0.9860\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4675 - acc: 0.9882\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4522 - acc: 0.9885\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4384 - acc: 0.9905\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4241 - acc: 0.9930\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4107 - acc: 0.9898\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3931 - acc: 0.9922\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3804 - acc: 0.9908\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3682 - acc: 0.9908\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3526 - acc: 0.9902\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3381 - acc: 0.9915\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3268 - acc: 0.9930\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3126 - acc: 0.9923\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3008 - acc: 0.9937\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2881 - acc: 0.9938\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2770 - acc: 0.9932\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2643 - acc: 0.9953\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2544 - acc: 0.9953\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2421 - acc: 0.9968\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2320 - acc: 0.9968\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2218 - acc: 0.9962\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2117 - acc: 0.9983\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2035 - acc: 0.9977\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1942 - acc: 0.9977\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1844 - acc: 0.9977\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1761 - acc: 0.9970\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1669 - acc: 0.9977\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1582 - acc: 0.9983\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1489 - acc: 0.9977\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1425 - acc: 0.9977\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1350 - acc: 0.9977\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1274 - acc: 0.9983\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1236 - acc: 0.9977\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1161 - acc: 0.9970\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1099 - acc: 0.9970\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1049 - acc: 0.9977\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0986 - acc: 0.9992\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0937 - acc: 0.9992\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0886 - acc: 0.9985\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0856 - acc: 0.9985\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0787 - acc: 0.9992\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0711 - acc: 1.000 - 0s 11ms/step - loss: 0.0737 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0722 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0668 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0639 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0589 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0566 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0537 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0497 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0483 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0446 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0430 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0379 - acc: 1.000 - 0s 9ms/step - loss: 0.0392 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0371 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0360 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDD9E9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6229 - acc: 0.7250\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6923 - acc: 0.5182\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6762 - acc: 0.7850\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6615 - acc: 0.8713\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6458 - acc: 0.8950\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6303 - acc: 0.9190\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6136 - acc: 0.9307\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5960 - acc: 0.9513\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5789 - acc: 0.9527\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5628 - acc: 0.9610\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5465 - acc: 0.9615\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5294 - acc: 0.9655\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5119 - acc: 0.9667\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4960 - acc: 0.9672\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4762 - acc: 0.9732\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4624 - acc: 0.9722\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4447 - acc: 0.9730\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4310 - acc: 0.9738\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4144 - acc: 0.9770\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3988 - acc: 0.9800\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3853 - acc: 0.9808\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3693 - acc: 0.9822\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3553 - acc: 0.9823\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3436 - acc: 0.9818\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3281 - acc: 0.9845\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3152 - acc: 0.9825\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3018 - acc: 0.9840\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2878 - acc: 0.9862\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2762 - acc: 0.9862\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2643 - acc: 0.9920\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2531 - acc: 0.9898\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2444 - acc: 0.9900\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2319 - acc: 0.9907\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2218 - acc: 0.9892\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2118 - acc: 0.9893\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2038 - acc: 0.9913\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.1951 - acc: 0.9893\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1854 - acc: 0.9913\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1776 - acc: 0.9908\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1691 - acc: 0.9915\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1612 - acc: 0.9915\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1535 - acc: 0.9915\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1478 - acc: 0.9902\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1395 - acc: 0.9915\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1356 - acc: 0.9902\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1284 - acc: 0.9908\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1208 - acc: 0.9902\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1158 - acc: 0.9915\n",
      "Epoch 48/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1094 - acc: 0.9915\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1054 - acc: 0.9930\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1011 - acc: 0.9917\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0956 - acc: 0.9932\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0899 - acc: 0.9932\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0854 - acc: 0.9923\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0827 - acc: 0.9938\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0772 - acc: 0.9945\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0733 - acc: 0.9945\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0701 - acc: 0.9947\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0689 - acc: 0.9940\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0638 - acc: 0.9947\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0619 - acc: 0.9947\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0577 - acc: 0.9953\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0544 - acc: 0.9938\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0512 - acc: 0.9953\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0515 - acc: 0.9947\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0493 - acc: 0.9940\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0458 - acc: 0.9953\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0416 - acc: 0.9952\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0405 - acc: 0.9968\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0396 - acc: 0.9962\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0366 - acc: 0.9968\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC159A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6472 - acc: 0.7050\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6893 - acc: 0.5453\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6488 - acc: 0.7983\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6157 - acc: 0.8707\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5863 - acc: 0.8973\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5583 - acc: 0.9223\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5328 - acc: 0.9373\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5095 - acc: 0.9455\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4833 - acc: 0.9513\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4634 - acc: 0.9527\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4424 - acc: 0.9610\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4227 - acc: 0.9637\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4037 - acc: 0.9647\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3855 - acc: 0.9722\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3691 - acc: 0.9737\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3506 - acc: 0.9737\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3366 - acc: 0.9768\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3204 - acc: 0.9760\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3052 - acc: 0.9745\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2905 - acc: 0.9772\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2760 - acc: 0.9800\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2642 - acc: 0.9808\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2525 - acc: 0.9827\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2408 - acc: 0.9860\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2302 - acc: 0.9853\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2203 - acc: 0.9907\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2099 - acc: 0.9913\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1985 - acc: 0.9938\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1903 - acc: 0.9938\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1802 - acc: 0.9938\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1701 - acc: 0.9960\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1619 - acc: 0.9968\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1530 - acc: 0.9977\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1453 - acc: 0.9970\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1420 - acc: 0.9970\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1331 - acc: 0.9977\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1283 - acc: 0.996 - 0s 8ms/step - loss: 0.1274 - acc: 0.9970\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1208 - acc: 0.9977\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1163 - acc: 0.9970\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1079 - acc: 0.9977\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1047 - acc: 0.9977\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0980 - acc: 0.9977\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0934 - acc: 0.9983\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0885 - acc: 0.9985\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0847 - acc: 0.9992\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0803 - acc: 0.9985\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0769 - acc: 0.9985\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0723 - acc: 0.9985\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0687 - acc: 0.9985\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0654 - acc: 0.9992\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0623 - acc: 1.0000\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0588 - acc: 1.0000\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0563 - acc: 1.0000\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0531 - acc: 1.0000\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0510 - acc: 1.0000\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0486 - acc: 1.0000\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0461 - acc: 1.0000\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0435 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0416 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0394 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0368 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0340 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0280 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0247 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0238 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0220 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC38F040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7079 - acc: 0.7113\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6899 - acc: 0.5457\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6585 - acc: 0.8138\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6343 - acc: 0.8578\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6110 - acc: 0.9008\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5901 - acc: 0.9048\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5691 - acc: 0.9137\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5493 - acc: 0.9277\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5292 - acc: 0.9428\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5132 - acc: 0.9437\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4968 - acc: 0.9443\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4790 - acc: 0.9492\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4618 - acc: 0.9492\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4456 - acc: 0.9508\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4286 - acc: 0.9550\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4164 - acc: 0.9520\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4009 - acc: 0.9570\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3867 - acc: 0.9573\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3739 - acc: 0.9617\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3573 - acc: 0.9648\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3450 - acc: 0.9663\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3323 - acc: 0.9700\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3201 - acc: 0.9708\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3068 - acc: 0.9753\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2986 - acc: 0.9748\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2873 - acc: 0.9763\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2741 - acc: 0.9790\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2626 - acc: 0.9798\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2542 - acc: 0.9830\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2431 - acc: 0.9838\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2341 - acc: 0.9847\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2260 - acc: 0.9857\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2157 - acc: 0.9892\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2073 - acc: 0.9885\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2000 - acc: 0.9893\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1915 - acc: 0.9893\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1818 - acc: 0.9928\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1737 - acc: 0.9928\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1669 - acc: 0.9908\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1601 - acc: 0.9915\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1573 - acc: 0.9908\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1479 - acc: 0.9900\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1414 - acc: 0.9945\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1374 - acc: 0.9945\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1330 - acc: 0.9938\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1240 - acc: 0.9937\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1203 - acc: 0.9923\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1165 - acc: 0.9938\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1114 - acc: 0.9932\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1073 - acc: 0.9932\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1031 - acc: 0.9930\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0982 - acc: 0.9938\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0937 - acc: 0.9930\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0911 - acc: 0.9938\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0874 - acc: 0.9932\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0836 - acc: 0.9953\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0783 - acc: 0.9953\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0774 - acc: 0.9947\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0743 - acc: 0.9947\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0706 - acc: 0.9953\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0659 - acc: 0.9960\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0649 - acc: 0.9953\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0626 - acc: 0.9953\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0611 - acc: 0.9962\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0575 - acc: 0.9962\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0561 - acc: 0.9955\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0515 - acc: 0.9975\n",
      "Epoch 67/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0514 - acc: 0.9968\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0501 - acc: 0.9955\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0477 - acc: 0.9962\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0471 - acc: 0.9947\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D8F3ACA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6495 - acc: 0.7088\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6933 - acc: 0.4908\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6887 - acc: 0.7563\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6834 - acc: 0.8432\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6759 - acc: 0.9072\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6668 - acc: 0.9293\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6552 - acc: 0.9478\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6429 - acc: 0.9535\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6292 - acc: 0.9658\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6141 - acc: 0.9710\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5980 - acc: 0.9732\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5806 - acc: 0.9778\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5638 - acc: 0.9823\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5446 - acc: 0.9838\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5251 - acc: 0.9860\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5065 - acc: 0.9840\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4858 - acc: 0.9900\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4644 - acc: 0.9913\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4458 - acc: 0.9937\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4236 - acc: 0.9923\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4032 - acc: 0.9930\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3831 - acc: 0.9930\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3620 - acc: 0.9930\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3421 - acc: 0.9937\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3221 - acc: 0.9953\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3021 - acc: 0.9952\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2848 - acc: 0.9953\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2663 - acc: 0.9953\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2516 - acc: 0.9947\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2338 - acc: 0.9968\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2181 - acc: 0.9970\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2024 - acc: 0.998 - 0s 9ms/step - loss: 0.2032 - acc: 0.9977\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1900 - acc: 0.9970\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1768 - acc: 0.9992\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1643 - acc: 0.9992\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1533 - acc: 0.9985\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1415 - acc: 0.9985\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1309 - acc: 0.9985\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1216 - acc: 0.9992\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1133 - acc: 0.9985\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1034 - acc: 0.9992\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0952 - acc: 0.9992\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0895 - acc: 0.9985\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0809 - acc: 0.9992\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0772 - acc: 0.9992\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0703 - acc: 0.9985\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0658 - acc: 0.9985\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0606 - acc: 0.9985\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0551 - acc: 0.9985\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0508 - acc: 0.9985\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0472 - acc: 0.9985\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0429 - acc: 0.9992\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0398 - acc: 0.9992\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0369 - acc: 0.9985\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0337 - acc: 1.0000\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0305 - acc: 0.9992\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0282 - acc: 1.0000\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0242 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0219 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0126 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0089 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED806D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7945 - acc: 0.7138\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6925 - acc: 0.5130\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6821 - acc: 0.5723\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6710 - acc: 0.6302\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6596 - acc: 0.6852\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6461 - acc: 0.7380\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6297 - acc: 0.7723\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6141 - acc: 0.8138\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5965 - acc: 0.8322\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5801 - acc: 0.8468\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5619 - acc: 0.8687\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5441 - acc: 0.8833\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5279 - acc: 0.9093\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5112 - acc: 0.9230\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4960 - acc: 0.9277\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4783 - acc: 0.9282\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4603 - acc: 0.9397\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4443 - acc: 0.9495\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4309 - acc: 0.9475\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4144 - acc: 0.9563\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3995 - acc: 0.9548\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3873 - acc: 0.9547\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3675 - acc: 0.9638\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3548 - acc: 0.9700\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3429 - acc: 0.9692\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3272 - acc: 0.9717\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3111 - acc: 0.9795\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2978 - acc: 0.9813\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2869 - acc: 0.9837\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2744 - acc: 0.9862\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2627 - acc: 0.9872\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2490 - acc: 0.9907\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2387 - acc: 0.9907\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2280 - acc: 0.9943\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2166 - acc: 0.9930\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2083 - acc: 0.9932\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1936 - acc: 0.9952\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1865 - acc: 0.9945\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1794 - acc: 0.9932\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1686 - acc: 0.9930\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1587 - acc: 0.9938\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1506 - acc: 0.9953\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1409 - acc: 0.9947\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1317 - acc: 0.9938\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1248 - acc: 0.9947\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1174 - acc: 0.9940\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1100 - acc: 0.9960\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1050 - acc: 0.9947\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0965 - acc: 0.9947\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0927 - acc: 0.9940\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0859 - acc: 0.9947\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0820 - acc: 0.9953\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0746 - acc: 0.9968\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0693 - acc: 0.9953\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0666 - acc: 0.9947\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0611 - acc: 0.9968\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0585 - acc: 0.9968\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0543 - acc: 0.9962\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0514 - acc: 0.9962\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0472 - acc: 0.9975\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0456 - acc: 0.9962\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0414 - acc: 0.9962\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0398 - acc: 0.9953\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0373 - acc: 0.9968\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0351 - acc: 0.9953\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0344 - acc: 0.9955\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0309 - acc: 0.9962\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0289 - acc: 0.9962\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0282 - acc: 0.9962\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0262 - acc: 0.9962\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0252 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED7F9DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8094 - acc: 0.7075\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6930 - acc: 0.5262\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6504 - acc: 0.8080\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6136 - acc: 0.8778\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5767 - acc: 0.9270\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5408 - acc: 0.9322\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5079 - acc: 0.9387\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4758 - acc: 0.9503\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4453 - acc: 0.9575\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4171 - acc: 0.9623\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3907 - acc: 0.9655\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3673 - acc: 0.9730\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3439 - acc: 0.9722\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3243 - acc: 0.9732\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3033 - acc: 0.9795\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2835 - acc: 0.9830\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2657 - acc: 0.9823\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2487 - acc: 0.9853\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2330 - acc: 0.9855\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2175 - acc: 0.9907\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2018 - acc: 0.9915\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1897 - acc: 0.9930\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1800 - acc: 0.9938\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1688 - acc: 0.9925\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1566 - acc: 0.9923\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1452 - acc: 0.9968\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1362 - acc: 0.9983\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1292 - acc: 0.9970\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1202 - acc: 0.9970\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1127 - acc: 0.9970\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1054 - acc: 0.9970\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0988 - acc: 0.9970\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0915 - acc: 0.9983\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0860 - acc: 1.0000\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0807 - acc: 1.0000\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0750 - acc: 1.0000\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0713 - acc: 1.0000\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0666 - acc: 1.0000\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0617 - acc: 1.0000\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0581 - acc: 1.0000\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0546 - acc: 1.0000\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0478 - acc: 1.0000\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0446 - acc: 1.0000\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0415 - acc: 1.0000\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0396 - acc: 1.0000\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0364 - acc: 1.0000\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0346 - acc: 1.0000\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0324 - acc: 1.0000\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0306 - acc: 1.0000\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0229 - acc: 1.0000\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0206 - acc: 1.0000\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0100 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC2FD790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8947 - acc: 0.7088\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 0.6908 - acc: 0.5573\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6588 - acc: 0.7747\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6264 - acc: 0.8417\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5947 - acc: 0.9098\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5618 - acc: 0.9255\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5313 - acc: 0.9307\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4964 - acc: 0.9477\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4683 - acc: 0.9560\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4406 - acc: 0.9562\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4145 - acc: 0.9615\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3908 - acc: 0.9690\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3682 - acc: 0.9755\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3467 - acc: 0.9775\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3254 - acc: 0.9768\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3084 - acc: 0.9813\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2926 - acc: 0.9823\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2747 - acc: 0.9823\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2598 - acc: 0.9840\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2421 - acc: 0.9895\n",
      "Epoch 20/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2315 - acc: 0.9893\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2175 - acc: 0.9930\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2060 - acc: 0.9930\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1959 - acc: 0.9923\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1851 - acc: 0.9938\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1778 - acc: 0.9932\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1671 - acc: 0.9932\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1569 - acc: 0.9930\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1495 - acc: 0.9932\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1418 - acc: 0.9932\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1352 - acc: 0.9938\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1277 - acc: 0.9930\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1209 - acc: 0.9930\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1149 - acc: 0.9960\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1096 - acc: 0.9947\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1042 - acc: 0.9945\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0986 - acc: 0.9953\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0974 - acc: 0.9940\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0918 - acc: 0.9953\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0878 - acc: 0.9947\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0832 - acc: 0.9962\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0802 - acc: 0.9962\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0760 - acc: 0.9962\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0727 - acc: 0.9962\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0704 - acc: 0.9968\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0680 - acc: 0.9955\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0647 - acc: 0.9962\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0623 - acc: 0.9947\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0571 - acc: 0.9975\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0568 - acc: 0.9968\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0552 - acc: 0.9955\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0534 - acc: 0.9955\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0503 - acc: 0.9962\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0497 - acc: 0.9955\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0460 - acc: 0.9968\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0425 - acc: 0.9975\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0437 - acc: 0.9962\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0400 - acc: 0.9975\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0398 - acc: 0.9962\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0385 - acc: 0.9962\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0378 - acc: 0.9947\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0350 - acc: 0.9962\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0342 - acc: 0.9962\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0319 - acc: 0.9968\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0316 - acc: 0.9962\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0301 - acc: 0.9962\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0290 - acc: 0.9962\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0265 - acc: 0.9975\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0273 - acc: 0.9970\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0261 - acc: 0.9970\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0249 - acc: 0.9968\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F2394160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8168 - acc: 0.7038\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6944 - acc: 0.4815\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6782 - acc: 0.8220\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6653 - acc: 0.8815\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6527 - acc: 0.9155\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6397 - acc: 0.9338\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6274 - acc: 0.9460\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6141 - acc: 0.9453\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6009 - acc: 0.9542\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5887 - acc: 0.9545\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5759 - acc: 0.9605\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5627 - acc: 0.9545\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5511 - acc: 0.9568\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5395 - acc: 0.9600\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5271 - acc: 0.9645\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5147 - acc: 0.9637\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5024 - acc: 0.9638\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4911 - acc: 0.9673\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4819 - acc: 0.9682\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4712 - acc: 0.9688\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4606 - acc: 0.9693\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4501 - acc: 0.9717\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4403 - acc: 0.9730\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4285 - acc: 0.9737\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4193 - acc: 0.9730\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4109 - acc: 0.9738\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3979 - acc: 0.9738\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3906 - acc: 0.9745\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3833 - acc: 0.9755\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3728 - acc: 0.9775\n",
      "Epoch 30/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 21ms/step - loss: 0.3630 - acc: 0.9790\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3545 - acc: 0.9770\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3449 - acc: 0.9763\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3377 - acc: 0.9763\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3287 - acc: 0.9785\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3225 - acc: 0.9793\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3149 - acc: 0.9822\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3075 - acc: 0.9830\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3000 - acc: 0.9802\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2911 - acc: 0.9823\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2844 - acc: 0.9863\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2771 - acc: 0.9868\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2702 - acc: 0.9877\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2633 - acc: 0.9855\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2567 - acc: 0.9847\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2521 - acc: 0.9855\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2415 - acc: 0.9883\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2367 - acc: 0.9877\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2323 - acc: 0.9870\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2250 - acc: 0.9863\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2209 - acc: 0.9863\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2126 - acc: 0.9870\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2085 - acc: 0.9885\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2024 - acc: 0.9890\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1978 - acc: 0.9893\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1932 - acc: 0.9900\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1894 - acc: 0.9887\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1822 - acc: 0.9908\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1760 - acc: 0.9943\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1706 - acc: 0.9943\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1677 - acc: 0.9923\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EE058550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5487 - acc: 0.7188\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6929 - acc: 0.5128\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6670 - acc: 0.7725\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6470 - acc: 0.8647\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6280 - acc: 0.8907\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6096 - acc: 0.9153\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5916 - acc: 0.9178\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5750 - acc: 0.9330\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5587 - acc: 0.9443\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5434 - acc: 0.9460\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5263 - acc: 0.9412\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5104 - acc: 0.9452\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4938 - acc: 0.9517\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4817 - acc: 0.9537\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4664 - acc: 0.9605\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4548 - acc: 0.9630\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 0.4412 - acc: 0.9648\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4273 - acc: 0.9652\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4171 - acc: 0.9647\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4045 - acc: 0.9662\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3925 - acc: 0.9668\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3816 - acc: 0.9733\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3688 - acc: 0.9715\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3624 - acc: 0.9717\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3512 - acc: 0.9708\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3414 - acc: 0.9718\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3337 - acc: 0.9705\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3229 - acc: 0.9747\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3130 - acc: 0.9782\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3037 - acc: 0.9827\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2941 - acc: 0.9820\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2879 - acc: 0.9788\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2787 - acc: 0.9822\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2711 - acc: 0.9823\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2619 - acc: 0.9837\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2559 - acc: 0.9837\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2493 - acc: 0.9825\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2407 - acc: 0.9845\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2345 - acc: 0.9832\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2277 - acc: 0.9862\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2207 - acc: 0.9862\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2137 - acc: 0.9875\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2086 - acc: 0.9855\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2027 - acc: 0.9855\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1963 - acc: 0.9878\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1918 - acc: 0.9892\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1861 - acc: 0.9900\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1786 - acc: 0.9913\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1763 - acc: 0.9907\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1693 - acc: 0.9893\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1636 - acc: 0.9900\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1559 - acc: 0.990 - 0s 10ms/step - loss: 0.1586 - acc: 0.9900\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1532 - acc: 0.9900\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1519 - acc: 0.9895\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1466 - acc: 0.9915\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1418 - acc: 0.9922\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1377 - acc: 0.9908\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1315 - acc: 0.9915\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1296 - acc: 0.9922\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1254 - acc: 0.9908\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1223 - acc: 0.9923\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED7F9550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5627 - acc: 0.7175\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6895 - acc: 0.5758\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6563 - acc: 0.8167\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6322 - acc: 0.8865\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6128 - acc: 0.9022\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5947 - acc: 0.9230\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5784 - acc: 0.9278\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5638 - acc: 0.9360\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5488 - acc: 0.9392\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5349 - acc: 0.9393\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5210 - acc: 0.9408\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5076 - acc: 0.9495\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4954 - acc: 0.9542\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4812 - acc: 0.9540\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4712 - acc: 0.9567\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4602 - acc: 0.9603\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4493 - acc: 0.9590\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4371 - acc: 0.9623\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4275 - acc: 0.9632\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4189 - acc: 0.9620\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4064 - acc: 0.9653\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3972 - acc: 0.9640\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3863 - acc: 0.9682\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3790 - acc: 0.9657\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3683 - acc: 0.9705\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3616 - acc: 0.9687\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3511 - acc: 0.9715\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3434 - acc: 0.9728\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3323 - acc: 0.9730\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3238 - acc: 0.9743\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3179 - acc: 0.9738\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3092 - acc: 0.9732\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3043 - acc: 0.9740\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2964 - acc: 0.9718\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2863 - acc: 0.9762\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2807 - acc: 0.9777\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2717 - acc: 0.9798\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2658 - acc: 0.9823\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2588 - acc: 0.9827\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2534 - acc: 0.9828\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2466 - acc: 0.9845\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2422 - acc: 0.9818\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2351 - acc: 0.9860\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2286 - acc: 0.9840\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2242 - acc: 0.9853\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2167 - acc: 0.9868\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2130 - acc: 0.9848\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2087 - acc: 0.9870\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1996 - acc: 0.9885\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1979 - acc: 0.9885\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1922 - acc: 0.9907\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1835 - acc: 0.9900\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1815 - acc: 0.9930\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1771 - acc: 0.9953\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1735 - acc: 0.9940\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1656 - acc: 0.9945\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1651 - acc: 0.9947\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1608 - acc: 0.9962\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1566 - acc: 0.9977\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1528 - acc: 0.9970\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1480 - acc: 0.9975\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EE058790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5462 - acc: 0.7225\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6928 - acc: 0.5285\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6548 - acc: 0.8123\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6309 - acc: 0.8757\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6096 - acc: 0.8987\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5903 - acc: 0.9135\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5744 - acc: 0.9208\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5583 - acc: 0.9272\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5445 - acc: 0.9333\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5297 - acc: 0.9415\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5165 - acc: 0.9443\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5040 - acc: 0.9433\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4897 - acc: 0.9448\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4791 - acc: 0.9498\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4665 - acc: 0.9522\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4555 - acc: 0.9502\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4443 - acc: 0.9550\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4327 - acc: 0.9532\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4241 - acc: 0.9590\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4125 - acc: 0.9542\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4002 - acc: 0.9632\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3902 - acc: 0.9598\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3833 - acc: 0.9655\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3761 - acc: 0.9603\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3630 - acc: 0.9643\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3561 - acc: 0.9638\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3467 - acc: 0.9655\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3398 - acc: 0.9695\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3299 - acc: 0.9717\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3222 - acc: 0.9758\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3124 - acc: 0.9740\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.3043 - acc: 0.9767\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2988 - acc: 0.9768\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2932 - acc: 0.9793\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2829 - acc: 0.9792\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2761 - acc: 0.9807\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2715 - acc: 0.9807\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2609 - acc: 0.9837\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2578 - acc: 0.9843\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2526 - acc: 0.9825\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2488 - acc: 0.9818\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2380 - acc: 0.9832\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2337 - acc: 0.9845\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2277 - acc: 0.9838\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2227 - acc: 0.9847\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2176 - acc: 0.9868\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2114 - acc: 0.9863\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2063 - acc: 0.9863\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2007 - acc: 0.9892\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1966 - acc: 0.9892\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1946 - acc: 0.9908\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1863 - acc: 0.9922\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1807 - acc: 0.9908\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1782 - acc: 0.9915\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1724 - acc: 0.9908\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1687 - acc: 0.9915\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1646 - acc: 0.9908\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1578 - acc: 0.9928\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1547 - acc: 0.9928\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1533 - acc: 0.9915\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1497 - acc: 0.9930\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0FB9BD0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5632 - acc: 0.7013\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6932 - acc: 0.5252\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6713 - acc: 0.8235\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6549 - acc: 0.9052\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6396 - acc: 0.9297\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6249 - acc: 0.9343\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6104 - acc: 0.9462\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5968 - acc: 0.9508\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5830 - acc: 0.9562\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5690 - acc: 0.9605\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5561 - acc: 0.9607\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5453 - acc: 0.9630\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5315 - acc: 0.9670\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5178 - acc: 0.9677\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5082 - acc: 0.9685\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4947 - acc: 0.9675\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4861 - acc: 0.9695\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4730 - acc: 0.9722\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4647 - acc: 0.9712\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4528 - acc: 0.9702\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4390 - acc: 0.9765\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4333 - acc: 0.9738\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4222 - acc: 0.9740\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4129 - acc: 0.9755\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4036 - acc: 0.9733\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3932 - acc: 0.9747\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3830 - acc: 0.9747\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3734 - acc: 0.9733\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3665 - acc: 0.9740\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3559 - acc: 0.9762\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3471 - acc: 0.9775\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3413 - acc: 0.9762\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3317 - acc: 0.9762\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3228 - acc: 0.9768\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3116 - acc: 0.9798\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3054 - acc: 0.9800\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2973 - acc: 0.9828\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2915 - acc: 0.9813\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2833 - acc: 0.9830\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2782 - acc: 0.9852\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2719 - acc: 0.9855\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2647 - acc: 0.9868\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2568 - acc: 0.9860\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2520 - acc: 0.9885\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2407 - acc: 0.9903\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2381 - acc: 0.9885\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2305 - acc: 0.9892\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2269 - acc: 0.9877\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2164 - acc: 0.9913\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2140 - acc: 0.9915\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2095 - acc: 0.9910\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2026 - acc: 0.9930\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1984 - acc: 0.9937\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1918 - acc: 0.9923\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1910 - acc: 0.9917\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1844 - acc: 0.9917\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1767 - acc: 0.9953\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1711 - acc: 0.9940\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1670 - acc: 0.9960\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1639 - acc: 0.9967\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1592 - acc: 0.9947\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED8069D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5476 - acc: 0.7200\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5367\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6677 - acc: 0.8430\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6499 - acc: 0.8808\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6330 - acc: 0.9143\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6167 - acc: 0.9245\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6008 - acc: 0.9375\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5845 - acc: 0.9420\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5711 - acc: 0.9503\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5580 - acc: 0.9513\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5437 - acc: 0.9507\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5296 - acc: 0.9487\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5171 - acc: 0.9542\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5053 - acc: 0.9548\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4926 - acc: 0.9532\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4809 - acc: 0.9558\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4684 - acc: 0.9565\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.4568 - acc: 0.9580\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4452 - acc: 0.9592\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4357 - acc: 0.9610\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4230 - acc: 0.9632\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4155 - acc: 0.9620\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4023 - acc: 0.9628\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3925 - acc: 0.9657\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3835 - acc: 0.9685\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3708 - acc: 0.9700\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3623 - acc: 0.9720\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3513 - acc: 0.9727\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3430 - acc: 0.9708\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3357 - acc: 0.9767\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3272 - acc: 0.9780\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3197 - acc: 0.9735\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3094 - acc: 0.9755\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3001 - acc: 0.9783\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2935 - acc: 0.9778\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2874 - acc: 0.9772\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2801 - acc: 0.9787\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2692 - acc: 0.9835\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2647 - acc: 0.9810\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2586 - acc: 0.9818\n",
      "Epoch 40/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2509 - acc: 0.9838\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2436 - acc: 0.9810\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2380 - acc: 0.9840\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2324 - acc: 0.9833\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2216 - acc: 0.9862\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2159 - acc: 0.9868\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2105 - acc: 0.9877\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2051 - acc: 0.9877\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1998 - acc: 0.9890\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1959 - acc: 0.9863\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1894 - acc: 0.9877\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1826 - acc: 0.9883\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1794 - acc: 0.9907\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1743 - acc: 0.990 - 0s 9ms/step - loss: 0.1742 - acc: 0.9900\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1682 - acc: 0.9898\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1660 - acc: 0.9893\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1602 - acc: 0.9915\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1556 - acc: 0.9915\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1505 - acc: 0.9915\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1459 - acc: 0.9928\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1425 - acc: 0.9908\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDB9B790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5592 - acc: 0.7013\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6918 - acc: 0.5303\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6532 - acc: 0.8342\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6270 - acc: 0.9015\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6075 - acc: 0.9170\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5875 - acc: 0.9302\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5700 - acc: 0.9392\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5530 - acc: 0.9390\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5367 - acc: 0.9448\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5234 - acc: 0.9458\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5088 - acc: 0.9547\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4967 - acc: 0.9545\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4832 - acc: 0.9605\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4690 - acc: 0.9630\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4583 - acc: 0.9652\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4484 - acc: 0.9632\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4354 - acc: 0.9620\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4213 - acc: 0.9688\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4134 - acc: 0.9677\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4018 - acc: 0.9722\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3912 - acc: 0.9702\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3803 - acc: 0.9722\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3722 - acc: 0.9712\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3640 - acc: 0.9717\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3503 - acc: 0.9778\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3424 - acc: 0.9780\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3338 - acc: 0.9732\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3261 - acc: 0.9767\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3182 - acc: 0.9762\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3066 - acc: 0.9805\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3011 - acc: 0.9807\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2922 - acc: 0.9783\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2868 - acc: 0.9815\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2783 - acc: 0.9822\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2720 - acc: 0.9810\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2606 - acc: 0.9850\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2592 - acc: 0.9837\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2511 - acc: 0.9817\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2444 - acc: 0.9825\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2379 - acc: 0.9840\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2330 - acc: 0.9833\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2272 - acc: 0.9853\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2190 - acc: 0.9870\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2133 - acc: 0.9883\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2102 - acc: 0.9887\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2036 - acc: 0.9892\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1974 - acc: 0.9898\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1923 - acc: 0.9893\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1875 - acc: 0.9880\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1818 - acc: 0.9893\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1784 - acc: 0.9893\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1733 - acc: 0.9908\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1663 - acc: 0.9908\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1662 - acc: 0.9908\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1622 - acc: 0.9917\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1562 - acc: 0.9930\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1514 - acc: 0.9952\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1474 - acc: 0.9945\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1441 - acc: 0.9953\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1395 - acc: 0.9955\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1374 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDA5B550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5497 - acc: 0.7200\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6917 - acc: 0.5168\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6578 - acc: 0.7900\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6341 - acc: 0.8480\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6157 - acc: 0.8800\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5975 - acc: 0.9047\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5830 - acc: 0.9130\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5657 - acc: 0.9220\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5504 - acc: 0.9347\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5375 - acc: 0.9387\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5243 - acc: 0.9390\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5122 - acc: 0.9370\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4997 - acc: 0.9358\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4849 - acc: 0.9463\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4744 - acc: 0.9475\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4644 - acc: 0.9442\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4507 - acc: 0.9518\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4400 - acc: 0.9478\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4309 - acc: 0.9443\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4203 - acc: 0.9485\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4085 - acc: 0.9535\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3989 - acc: 0.9517\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3908 - acc: 0.9555\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3776 - acc: 0.9602\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3701 - acc: 0.9637\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3639 - acc: 0.9615\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3525 - acc: 0.9648\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3437 - acc: 0.9662\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3368 - acc: 0.9647\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3251 - acc: 0.9682\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3190 - acc: 0.966 - 0s 9ms/step - loss: 0.3193 - acc: 0.9670\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3122 - acc: 0.9720\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3039 - acc: 0.9695\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2945 - acc: 0.9750\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.2881 - acc: 0.9745\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2806 - acc: 0.9752\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2720 - acc: 0.9775\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2702 - acc: 0.9747\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2599 - acc: 0.9775\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2544 - acc: 0.9768\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2488 - acc: 0.9777\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2416 - acc: 0.9778\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2366 - acc: 0.9808\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2289 - acc: 0.9802\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2266 - acc: 0.9837\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2177 - acc: 0.9843\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2135 - acc: 0.9860\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2081 - acc: 0.9853\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2001 - acc: 0.9875\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1948 - acc: 0.9868\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1953 - acc: 0.9870\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1892 - acc: 0.9850\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1821 - acc: 0.9883\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1793 - acc: 0.9863\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1746 - acc: 0.9878\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1708 - acc: 0.9870\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1671 - acc: 0.9900\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1629 - acc: 0.9915\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1578 - acc: 0.9915\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1547 - acc: 0.9900\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1505 - acc: 0.9908\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F2449CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5567 - acc: 0.7088\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 0.6936 - acc: 0.4775\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6849 - acc: 0.7562\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6771 - acc: 0.8305\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6688 - acc: 0.8992\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6596 - acc: 0.9297\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6496 - acc: 0.9467\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6388 - acc: 0.9533\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6267 - acc: 0.9673\n",
      "Epoch 9/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6148 - acc: 0.9698\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6021 - acc: 0.9737\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5908 - acc: 0.9768\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5775 - acc: 0.9785\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5635 - acc: 0.9793\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5498 - acc: 0.9828\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5356 - acc: 0.9795\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5223 - acc: 0.9830\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5075 - acc: 0.9843\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4932 - acc: 0.9823\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4772 - acc: 0.9860\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4644 - acc: 0.9853\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4492 - acc: 0.9853\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4336 - acc: 0.9890\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4209 - acc: 0.9878\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4052 - acc: 0.9898\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3899 - acc: 0.9883\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3747 - acc: 0.9930\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3632 - acc: 0.9923\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3485 - acc: 0.9908\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3351 - acc: 0.9937\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3208 - acc: 0.9923\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3073 - acc: 0.9925\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2940 - acc: 0.9938\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2809 - acc: 0.9953\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2695 - acc: 0.9947\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2555 - acc: 0.9945\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2455 - acc: 0.9953\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2345 - acc: 0.9953\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2238 - acc: 0.9968\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2118 - acc: 0.9968\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2020 - acc: 0.9962\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1929 - acc: 0.9962\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1827 - acc: 0.9962\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1747 - acc: 0.9977\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1657 - acc: 0.9970\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1563 - acc: 0.9970\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1466 - acc: 0.9977\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1402 - acc: 0.9977\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1337 - acc: 0.9977\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1267 - acc: 0.9970\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1203 - acc: 0.9977\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1142 - acc: 0.9977\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1070 - acc: 0.9977\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1015 - acc: 0.9977\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0944 - acc: 0.9992\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0889 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0860 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0794 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0749 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0715 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0672 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0FB9BD1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5801 - acc: 0.7113\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6925 - acc: 0.5325\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6813 - acc: 0.8213\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6701 - acc: 0.8897\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6577 - acc: 0.9125\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6446 - acc: 0.9277\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6320 - acc: 0.9438\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6177 - acc: 0.9465\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6038 - acc: 0.9445\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5892 - acc: 0.9580\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5756 - acc: 0.9602\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5598 - acc: 0.9588\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5456 - acc: 0.9675\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5295 - acc: 0.9613\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5152 - acc: 0.9675\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4998 - acc: 0.9638\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4843 - acc: 0.9693\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4694 - acc: 0.9707\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4542 - acc: 0.9730\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4394 - acc: 0.9695\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4236 - acc: 0.9753\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4062 - acc: 0.9767\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3917 - acc: 0.9763\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3788 - acc: 0.9790\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3641 - acc: 0.9793\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3476 - acc: 0.9822\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3362 - acc: 0.9817\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3225 - acc: 0.9817\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3062 - acc: 0.9830\n",
      "Epoch 29/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2953 - acc: 0.9845\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2830 - acc: 0.9838\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2692 - acc: 0.9838\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2590 - acc: 0.9827\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2455 - acc: 0.9862\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2348 - acc: 0.9863\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2229 - acc: 0.9885\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2162 - acc: 0.986 - 0s 11ms/step - loss: 0.2145 - acc: 0.9878\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2055 - acc: 0.9872\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1940 - acc: 0.9885\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1847 - acc: 0.9878\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1758 - acc: 0.9885\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1678 - acc: 0.9885\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1588 - acc: 0.9885\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1527 - acc: 0.9893\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1455 - acc: 0.9915\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1373 - acc: 0.9923\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1302 - acc: 0.9895\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1223 - acc: 0.9923\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1189 - acc: 0.9938\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1111 - acc: 0.9945\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1061 - acc: 0.9932\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1014 - acc: 0.9938\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0965 - acc: 0.9947\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0916 - acc: 0.9940\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0868 - acc: 0.9947\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0807 - acc: 0.9938\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0777 - acc: 0.9953\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0748 - acc: 0.9940\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0697 - acc: 0.9953\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0671 - acc: 0.9938\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0631 - acc: 0.9938\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDB9BD30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5898 - acc: 0.7025\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6919 - acc: 0.5638\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6664 - acc: 0.8188\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6431 - acc: 0.8760\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6195 - acc: 0.9007\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5971 - acc: 0.9077\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5728 - acc: 0.9353\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5511 - acc: 0.9407\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5289 - acc: 0.9520\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5058 - acc: 0.9552\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4839 - acc: 0.9657\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4652 - acc: 0.9663\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4459 - acc: 0.9673\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4281 - acc: 0.9712\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4065 - acc: 0.9730\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3901 - acc: 0.9745\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3706 - acc: 0.9787\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3565 - acc: 0.9777\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3419 - acc: 0.9805\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3234 - acc: 0.9797\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3072 - acc: 0.9828\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2978 - acc: 0.9830\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2829 - acc: 0.9823\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2681 - acc: 0.9823\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2591 - acc: 0.9840\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2441 - acc: 0.9875\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2330 - acc: 0.9862\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2219 - acc: 0.9877\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2124 - acc: 0.9883\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2033 - acc: 0.9907\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1931 - acc: 0.9908\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1839 - acc: 0.9893\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1725 - acc: 0.9945\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1652 - acc: 0.9945\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1576 - acc: 0.9953\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1486 - acc: 0.9962\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1404 - acc: 0.9983\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1337 - acc: 0.9962\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1294 - acc: 0.9970\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1221 - acc: 0.9970\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1131 - acc: 0.9983\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1088 - acc: 0.9970\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1029 - acc: 0.9977\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0989 - acc: 0.9977\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0953 - acc: 0.9970\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0900 - acc: 0.9970\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0856 - acc: 0.9970\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0793 - acc: 0.9992\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0756 - acc: 0.9985\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0715 - acc: 0.9992\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0675 - acc: 0.9992\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0640 - acc: 0.9992\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0614 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0592 - acc: 1.0000\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0542 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0521 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0494 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0471 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0442 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0419 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0399 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED8069D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6423 - acc: 0.7025\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6926 - acc: 0.5370\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6716 - acc: 0.7570\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6523 - acc: 0.8552\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6322 - acc: 0.8798\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6142 - acc: 0.9063\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5924 - acc: 0.9182\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5753 - acc: 0.9212\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5541 - acc: 0.9288\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5354 - acc: 0.9445\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5164 - acc: 0.9508\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4985 - acc: 0.9495\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4793 - acc: 0.9567\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4618 - acc: 0.9567\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4453 - acc: 0.9583\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4264 - acc: 0.9592\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4128 - acc: 0.9620\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3976 - acc: 0.9643\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3820 - acc: 0.9667\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3646 - acc: 0.9695\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3506 - acc: 0.9737\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3357 - acc: 0.9738\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3241 - acc: 0.9777\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3100 - acc: 0.9785\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2961 - acc: 0.9820\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2845 - acc: 0.9827\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2732 - acc: 0.9830\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2603 - acc: 0.9830\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2499 - acc: 0.9837\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2367 - acc: 0.9862\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2272 - acc: 0.9888\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2198 - acc: 0.9870\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2098 - acc: 0.9905\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2029 - acc: 0.9878\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1922 - acc: 0.9900\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1835 - acc: 0.9908\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1768 - acc: 0.9895\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1695 - acc: 0.9908\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1587 - acc: 0.9900\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1528 - acc: 0.9922\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1446 - acc: 0.9930\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1388 - acc: 0.9937\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1340 - acc: 0.9945\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1285 - acc: 0.9908\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1243 - acc: 0.9917\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1147 - acc: 0.9937\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1112 - acc: 0.9917\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1075 - acc: 0.9930\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1029 - acc: 0.9917\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0987 - acc: 0.9908\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0946 - acc: 0.9908\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0896 - acc: 0.9923\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0831 - acc: 0.9952\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0807 - acc: 0.9945\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0794 - acc: 0.9930\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0762 - acc: 0.9930\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0720 - acc: 0.9938\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0692 - acc: 0.9938\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0654 - acc: 0.9932\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0632 - acc: 0.9932\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0598 - acc: 0.9945\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E897C040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6231 - acc: 0.7013\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 0.6929 - acc: 0.5230\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6865 - acc: 0.7113\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6780 - acc: 0.7840\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6677 - acc: 0.8118\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6546 - acc: 0.8448\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6412 - acc: 0.8857\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6259 - acc: 0.9017\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6100 - acc: 0.9107\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5911 - acc: 0.9232\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5750 - acc: 0.9400\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5546 - acc: 0.9440\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5334 - acc: 0.9580\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5161 - acc: 0.9662\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4945 - acc: 0.9708\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4751 - acc: 0.9772\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4536 - acc: 0.9800\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4338 - acc: 0.9813\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4116 - acc: 0.9833\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3909 - acc: 0.9847\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3711 - acc: 0.9855\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3530 - acc: 0.9897\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3330 - acc: 0.9907\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3140 - acc: 0.9917\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2943 - acc: 0.9937\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2780 - acc: 0.9930\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2635 - acc: 0.9940\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2485 - acc: 0.9947\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2309 - acc: 0.9947\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2169 - acc: 0.9940\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2015 - acc: 0.9953\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1873 - acc: 0.9953\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1745 - acc: 0.9975\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1627 - acc: 0.9962\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1510 - acc: 0.9975\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1397 - acc: 0.9977\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1303 - acc: 0.9970\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1198 - acc: 0.9983\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1111 - acc: 0.9977\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1042 - acc: 0.9970\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0947 - acc: 0.9970\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0870 - acc: 0.9985\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0822 - acc: 0.9985\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0750 - acc: 1.0000\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0679 - acc: 1.0000\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0628 - acc: 1.0000\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0579 - acc: 1.0000\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0534 - acc: 1.0000\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0492 - acc: 1.0000\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0446 - acc: 1.0000\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0410 - acc: 1.0000\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0384 - acc: 1.0000\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0337 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0310 - acc: 1.0000\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0167 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D6716AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7518 - acc: 0.7113\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6928 - acc: 0.5103\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6853 - acc: 0.5918\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6771 - acc: 0.7358\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6666 - acc: 0.8180\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6555 - acc: 0.9088\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6418 - acc: 0.9285\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6266 - acc: 0.9397\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6096 - acc: 0.9467\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5908 - acc: 0.9610\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5704 - acc: 0.9640\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5489 - acc: 0.9678\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5266 - acc: 0.9670\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5032 - acc: 0.9685\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4794 - acc: 0.9768\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4541 - acc: 0.9798\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4312 - acc: 0.9813\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4062 - acc: 0.9822\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3815 - acc: 0.9843\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3580 - acc: 0.9837\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3376 - acc: 0.9855\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3154 - acc: 0.9855\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.2938 - acc: 0.9917\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2720 - acc: 0.9907\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2540 - acc: 0.9922\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2378 - acc: 0.9893\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2176 - acc: 0.9937\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2010 - acc: 0.9943\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1866 - acc: 0.9938\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1739 - acc: 0.9937\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1600 - acc: 0.9960\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1468 - acc: 0.9960\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1356 - acc: 0.9938\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1261 - acc: 0.9947\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1152 - acc: 0.9953\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1064 - acc: 0.9953\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0999 - acc: 0.9932\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0921 - acc: 0.9940\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0845 - acc: 0.9953\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0780 - acc: 0.9940\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0703 - acc: 0.9975\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0649 - acc: 0.9968\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0609 - acc: 0.9968\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0574 - acc: 0.9968\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0532 - acc: 0.9955\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0486 - acc: 0.9968\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0448 - acc: 0.9953\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0440 - acc: 0.9947\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0391 - acc: 0.9962\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0369 - acc: 0.9962\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0331 - acc: 0.9953\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0322 - acc: 0.9962\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0313 - acc: 0.9955\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0286 - acc: 0.9955\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0276 - acc: 0.9955\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0254 - acc: 0.9962\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0234 - acc: 0.9962\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0213 - acc: 0.9962\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0215 - acc: 0.9955\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0190 - acc: 0.9953\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0179 - acc: 0.9953\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDD8A040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7556 - acc: 0.7025\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6917 - acc: 0.5277\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6504 - acc: 0.8203\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6129 - acc: 0.8910\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5744 - acc: 0.9243\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5377 - acc: 0.9402\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5063 - acc: 0.9402\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4688 - acc: 0.9517\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4404 - acc: 0.9572\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4101 - acc: 0.9662\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3830 - acc: 0.9700\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3569 - acc: 0.9740\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3344 - acc: 0.9777\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3118 - acc: 0.9785\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2900 - acc: 0.9845\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2710 - acc: 0.9875\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2536 - acc: 0.9883\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2370 - acc: 0.9898\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2220 - acc: 0.9902\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2076 - acc: 0.9932\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1925 - acc: 0.9932\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1817 - acc: 0.9947\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1679 - acc: 0.9960\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1569 - acc: 0.9977\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1457 - acc: 0.9977\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1382 - acc: 0.9970\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1283 - acc: 0.9970\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1200 - acc: 0.9983\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1125 - acc: 0.9970\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1039 - acc: 0.9992\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0963 - acc: 0.9985\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0904 - acc: 0.9992\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0854 - acc: 0.9992\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0798 - acc: 0.9992\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0745 - acc: 0.9992\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0708 - acc: 1.0000\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0662 - acc: 1.0000\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0616 - acc: 1.0000\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0581 - acc: 1.0000\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0545 - acc: 1.0000\n",
      "Epoch 40/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0513 - acc: 1.0000\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0481 - acc: 1.0000\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0455 - acc: 1.0000\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0423 - acc: 1.0000\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0399 - acc: 1.0000\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0379 - acc: 1.0000\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0337 - acc: 1.0000\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0320 - acc: 1.0000\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0301 - acc: 1.0000\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0285 - acc: 1.0000\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0256 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0240 - acc: 1.0000\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0170 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0DA7809D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8040 - acc: 0.7050\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6897 - acc: 0.5692\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6559 - acc: 0.7863\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6234 - acc: 0.8603\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5891 - acc: 0.9205\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5561 - acc: 0.9417\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5243 - acc: 0.9488\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4911 - acc: 0.9515\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4608 - acc: 0.9500\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4323 - acc: 0.9590\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4034 - acc: 0.9670\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3767 - acc: 0.9677\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3503 - acc: 0.9700\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3260 - acc: 0.9752\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3056 - acc: 0.9777\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2855 - acc: 0.9787\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2645 - acc: 0.9825\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2446 - acc: 0.9890\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2274 - acc: 0.990 - 0s 9ms/step - loss: 0.2283 - acc: 0.9900\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2136 - acc: 0.9907\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1980 - acc: 0.9908\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1821 - acc: 0.9922\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1728 - acc: 0.9923\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1601 - acc: 0.9915\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1483 - acc: 0.9908\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1401 - acc: 0.9902\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1302 - acc: 0.9923\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1222 - acc: 0.9917\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1124 - acc: 0.9923\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1062 - acc: 0.9917\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1002 - acc: 0.9917\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0936 - acc: 0.9925\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0872 - acc: 0.9932\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0802 - acc: 0.9945\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0770 - acc: 0.9932\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0729 - acc: 0.9917\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0684 - acc: 0.9938\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0654 - acc: 0.9932\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0591 - acc: 0.9962\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0564 - acc: 0.9962\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0550 - acc: 0.9955\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0498 - acc: 0.9962\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0486 - acc: 0.9947\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0437 - acc: 0.9975\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0420 - acc: 0.9953\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0416 - acc: 0.9955\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0390 - acc: 0.9962\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0384 - acc: 0.9955\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0339 - acc: 0.9968\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0345 - acc: 0.9955\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0302 - acc: 0.9960\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0305 - acc: 0.9962\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0286 - acc: 0.9962\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0272 - acc: 0.9962\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0245 - acc: 0.9960\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0249 - acc: 0.9953\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0244 - acc: 0.9955\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0235 - acc: 0.9955\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0213 - acc: 0.9968\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0212 - acc: 0.9947\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0195 - acc: 0.9968\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E897C790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8182 - acc: 0.7025\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6933 - acc: 0.5163\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6768 - acc: 0.8040\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6641 - acc: 0.8613\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6514 - acc: 0.8910\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6391 - acc: 0.9202\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6279 - acc: 0.9280\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6156 - acc: 0.9360\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6035 - acc: 0.9370\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5930 - acc: 0.9425\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5815 - acc: 0.9432\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5710 - acc: 0.9440\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5598 - acc: 0.9452\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5479 - acc: 0.9463\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5387 - acc: 0.9525\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5267 - acc: 0.9543\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5174 - acc: 0.9553\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5051 - acc: 0.9533\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4963 - acc: 0.9575\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4870 - acc: 0.9590\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4760 - acc: 0.9598\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4675 - acc: 0.9580\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4573 - acc: 0.9607\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4476 - acc: 0.9597\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4396 - acc: 0.9617\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4295 - acc: 0.9625\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4189 - acc: 0.9652\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4124 - acc: 0.9683\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4024 - acc: 0.9697\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3943 - acc: 0.9672\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3861 - acc: 0.9715\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3763 - acc: 0.9693\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3704 - acc: 0.9723\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3596 - acc: 0.9753\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3567 - acc: 0.9750\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3457 - acc: 0.9782\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3379 - acc: 0.9762\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3314 - acc: 0.9800\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3219 - acc: 0.9815\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3148 - acc: 0.9793\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3057 - acc: 0.9863\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3003 - acc: 0.9830\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2929 - acc: 0.9838\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.2867 - acc: 0.9837\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2821 - acc: 0.9847\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2758 - acc: 0.9853\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2706 - acc: 0.9833\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2645 - acc: 0.9827\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2553 - acc: 0.9853\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2498 - acc: 0.9898\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2454 - acc: 0.9898\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2371 - acc: 0.9892\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2343 - acc: 0.9893\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2256 - acc: 0.9920\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2227 - acc: 0.9887\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2176 - acc: 0.9908\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2118 - acc: 0.9922\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2046 - acc: 0.9915\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.2024 - acc: 0.9902\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1944 - acc: 0.9902\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1927 - acc: 0.9908\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1862 - acc: 0.9922\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1822 - acc: 0.9902\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1779 - acc: 0.9915\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1743 - acc: 0.9938\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1685 - acc: 0.9938\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1657 - acc: 0.9947\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1619 - acc: 0.9940\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1575 - acc: 0.9947\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1515 - acc: 0.9953\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1486 - acc: 0.9947\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED8068B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5566 - acc: 0.7138\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6910 - acc: 0.5323\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6754 - acc: 0.7768\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6630 - acc: 0.8205\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6507 - acc: 0.8473\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6384 - acc: 0.8855\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6262 - acc: 0.8975\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6147 - acc: 0.9037\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6037 - acc: 0.9128\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5901 - acc: 0.9268\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5807 - acc: 0.9257\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5688 - acc: 0.9298\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5573 - acc: 0.9378\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5481 - acc: 0.9348\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5362 - acc: 0.9378\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5253 - acc: 0.9413\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5148 - acc: 0.9465\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5049 - acc: 0.9473\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4960 - acc: 0.9492\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4852 - acc: 0.9492\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4774 - acc: 0.9507\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4644 - acc: 0.9543\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4571 - acc: 0.9517\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4455 - acc: 0.9537\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4386 - acc: 0.9545\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4284 - acc: 0.9583\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4197 - acc: 0.9602\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4094 - acc: 0.9593\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4002 - acc: 0.9658\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3939 - acc: 0.9685\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3847 - acc: 0.9715\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3716 - acc: 0.976 - 0s 10ms/step - loss: 0.3746 - acc: 0.9712\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3678 - acc: 0.9723\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3589 - acc: 0.9748\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3503 - acc: 0.9782\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3434 - acc: 0.9768\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3375 - acc: 0.9770\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3265 - acc: 0.9783\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3201 - acc: 0.9777\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3137 - acc: 0.9763\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3049 - acc: 0.9777\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2978 - acc: 0.9822\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2910 - acc: 0.9837\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2866 - acc: 0.9832\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2773 - acc: 0.9830\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2713 - acc: 0.9832\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2639 - acc: 0.9845\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2592 - acc: 0.9840\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2554 - acc: 0.9827\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2436 - acc: 0.9847\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2386 - acc: 0.9875\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2363 - acc: 0.9892\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2288 - acc: 0.9900\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2238 - acc: 0.9887\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2178 - acc: 0.9913\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2134 - acc: 0.9907\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2077 - acc: 0.9907\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2024 - acc: 0.9900\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1962 - acc: 0.9893\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1940 - acc: 0.9907\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1896 - acc: 0.9907\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1844 - acc: 0.9907\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1782 - acc: 0.9902\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1737 - acc: 0.9908\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1699 - acc: 0.9902\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1640 - acc: 0.9915\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1606 - acc: 0.9915\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1580 - acc: 0.9915\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1538 - acc: 0.9908\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1503 - acc: 0.9908\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1462 - acc: 0.9908\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F22D53A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5629 - acc: 0.7063\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6934 - acc: 0.5085\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6619 - acc: 0.8095\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6395 - acc: 0.8870\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6213 - acc: 0.9062\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6042 - acc: 0.9157\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5888 - acc: 0.9250\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5731 - acc: 0.9380\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5588 - acc: 0.9425\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5476 - acc: 0.9475\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5333 - acc: 0.9497\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5199 - acc: 0.9503\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5088 - acc: 0.9532\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4967 - acc: 0.9483\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4841 - acc: 0.9540\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4738 - acc: 0.9575\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4618 - acc: 0.9608\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4508 - acc: 0.9608\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4423 - acc: 0.9638\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4317 - acc: 0.9673\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4182 - acc: 0.9653\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4122 - acc: 0.9648\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4023 - acc: 0.9698\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3939 - acc: 0.9715\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3827 - acc: 0.9708\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3744 - acc: 0.9707\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3631 - acc: 0.9728\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3564 - acc: 0.9717\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3494 - acc: 0.9740\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3368 - acc: 0.9738\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3299 - acc: 0.9767\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3237 - acc: 0.9772\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3174 - acc: 0.9773\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3066 - acc: 0.9800\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2976 - acc: 0.9800\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2944 - acc: 0.9778\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2878 - acc: 0.9793\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2788 - acc: 0.9807\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2748 - acc: 0.9787\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2639 - acc: 0.9830\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2592 - acc: 0.9822\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2534 - acc: 0.9837\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2467 - acc: 0.9838\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2408 - acc: 0.9867\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2368 - acc: 0.9832\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2276 - acc: 0.9853\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2244 - acc: 0.9855\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2179 - acc: 0.9883\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2151 - acc: 0.9863\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2082 - acc: 0.9877\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2014 - acc: 0.9937\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1973 - acc: 0.9913\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1924 - acc: 0.9923\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1869 - acc: 0.9923\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1821 - acc: 0.9937\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1775 - acc: 0.9910\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1743 - acc: 0.9923\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1676 - acc: 0.9937\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1647 - acc: 0.9923\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1623 - acc: 0.9917\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1564 - acc: 0.9938\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1511 - acc: 0.9960\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1494 - acc: 0.9940\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1431 - acc: 0.9960\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1429 - acc: 0.9947\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1386 - acc: 0.9962\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1323 - acc: 0.9968\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1316 - acc: 0.9955\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1279 - acc: 0.9962\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1231 - acc: 0.9955\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1224 - acc: 0.9955\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDB06160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5518 - acc: 0.7225\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6914 - acc: 0.5240\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6486 - acc: 0.7978\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6187 - acc: 0.8677\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5967 - acc: 0.8992\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5753 - acc: 0.9135\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5571 - acc: 0.9272\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5379 - acc: 0.9308\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5239 - acc: 0.9403\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5067 - acc: 0.9395\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4925 - acc: 0.9450\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4770 - acc: 0.9487\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4650 - acc: 0.9495\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4511 - acc: 0.9488\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4407 - acc: 0.9482\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4266 - acc: 0.9517\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4150 - acc: 0.9547\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4031 - acc: 0.9525\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3918 - acc: 0.9558\n",
      "Epoch 19/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3814 - acc: 0.9553\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3716 - acc: 0.9558\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3576 - acc: 0.9632\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3515 - acc: 0.9613\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3417 - acc: 0.9652\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3345 - acc: 0.9618\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3216 - acc: 0.9665\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3090 - acc: 0.9718\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3034 - acc: 0.9727\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2961 - acc: 0.9723\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2891 - acc: 0.9702\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2802 - acc: 0.9732\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2757 - acc: 0.9763\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2646 - acc: 0.9782\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2585 - acc: 0.9800\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2522 - acc: 0.9837\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2471 - acc: 0.9815\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2385 - acc: 0.9830\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2319 - acc: 0.9845\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2263 - acc: 0.9862\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2207 - acc: 0.9868\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2154 - acc: 0.9855\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2090 - acc: 0.9868\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2036 - acc: 0.9848\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1967 - acc: 0.9862\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1907 - acc: 0.9888\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1859 - acc: 0.9868\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1820 - acc: 0.9885\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1785 - acc: 0.9863\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1715 - acc: 0.9898\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1691 - acc: 0.9893\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1652 - acc: 0.9880\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1599 - acc: 0.9893\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1566 - acc: 0.9900\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1502 - acc: 0.9907\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1470 - acc: 0.9915\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1420 - acc: 0.9922\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1433 - acc: 0.988 - 0s 11ms/step - loss: 0.1404 - acc: 0.9902\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1356 - acc: 0.9922\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1321 - acc: 0.9900\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1271 - acc: 0.9922\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1256 - acc: 0.9907\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1219 - acc: 0.9908\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1169 - acc: 0.9930\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1132 - acc: 0.9930\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1108 - acc: 0.9945\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1089 - acc: 0.9937\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1055 - acc: 0.9938\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1028 - acc: 0.9945\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1027 - acc: 0.9938\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0960 - acc: 0.9958\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0958 - acc: 0.9923\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED71C550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5699 - acc: 0.7150\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6928 - acc: 0.5117\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6770 - acc: 0.7060\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6643 - acc: 0.7707\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6530 - acc: 0.8185\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6408 - acc: 0.8453\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6306 - acc: 0.8650\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6187 - acc: 0.8795\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6091 - acc: 0.8955\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5986 - acc: 0.9115\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5866 - acc: 0.9205\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5772 - acc: 0.9253\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5662 - acc: 0.9340\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5558 - acc: 0.9393\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5472 - acc: 0.9380\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5367 - acc: 0.9437\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5271 - acc: 0.9468\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5173 - acc: 0.9528\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5098 - acc: 0.9515\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4983 - acc: 0.9515\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4902 - acc: 0.9548\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4813 - acc: 0.9580\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4708 - acc: 0.9583\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4644 - acc: 0.9615\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4518 - acc: 0.9678\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4495 - acc: 0.9632\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4385 - acc: 0.9653\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4294 - acc: 0.9705\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4213 - acc: 0.9715\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4148 - acc: 0.9728\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4052 - acc: 0.9702\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3929 - acc: 0.9720\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3882 - acc: 0.9758\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3804 - acc: 0.9773\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3717 - acc: 0.9797\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3660 - acc: 0.9772\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3596 - acc: 0.9792\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3501 - acc: 0.9805\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3455 - acc: 0.9843\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3375 - acc: 0.9823\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3300 - acc: 0.9845\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3219 - acc: 0.9852\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3160 - acc: 0.9832\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3123 - acc: 0.984 - 0s 11ms/step - loss: 0.3111 - acc: 0.9838\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3033 - acc: 0.9832\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2966 - acc: 0.9838\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2910 - acc: 0.9852\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2852 - acc: 0.9840\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2732 - acc: 0.988 - 0s 10ms/step - loss: 0.2766 - acc: 0.9860\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2731 - acc: 0.9875\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2682 - acc: 0.9870\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2601 - acc: 0.9877\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2555 - acc: 0.9870\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2482 - acc: 0.9883\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2427 - acc: 0.9872\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2387 - acc: 0.9872\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2327 - acc: 0.9878\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2262 - acc: 0.9892\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2229 - acc: 0.9878\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2165 - acc: 0.9885\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2121 - acc: 0.9892\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2068 - acc: 0.9907\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2024 - acc: 0.9907\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1959 - acc: 0.9930\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1917 - acc: 0.9930\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1873 - acc: 0.9937\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1833 - acc: 0.9937\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1785 - acc: 0.9932\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1748 - acc: 0.9947\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1699 - acc: 0.9960\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1664 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0FB9BDA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5633 - acc: 0.7150\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6934 - acc: 0.5040\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6754 - acc: 0.6977\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6615 - acc: 0.7838\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6485 - acc: 0.8358\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6349 - acc: 0.8570\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6225 - acc: 0.8840\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6085 - acc: 0.9055\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5976 - acc: 0.9115\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5848 - acc: 0.9228\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5723 - acc: 0.9287\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5609 - acc: 0.9295\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5499 - acc: 0.9318\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5368 - acc: 0.9367\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5258 - acc: 0.9453\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5147 - acc: 0.9482\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5058 - acc: 0.9528\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4952 - acc: 0.9498\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4850 - acc: 0.9528\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4729 - acc: 0.9530\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4640 - acc: 0.9563\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4543 - acc: 0.9598\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4453 - acc: 0.9602\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4350 - acc: 0.9643\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4263 - acc: 0.9627\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4185 - acc: 0.9647\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4077 - acc: 0.9660\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3986 - acc: 0.9682\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3909 - acc: 0.9655\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3805 - acc: 0.9697\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3719 - acc: 0.9733\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3640 - acc: 0.9708\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3564 - acc: 0.9725\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3491 - acc: 0.9725\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3382 - acc: 0.9760\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3334 - acc: 0.9747\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3207 - acc: 0.9807\n",
      "Epoch 37/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3141 - acc: 0.9782\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3090 - acc: 0.9755\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3009 - acc: 0.9788\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2958 - acc: 0.9783\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2883 - acc: 0.9778\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2792 - acc: 0.9792\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2739 - acc: 0.9810\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2687 - acc: 0.9797\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2617 - acc: 0.9847\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2533 - acc: 0.9847\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2479 - acc: 0.9868\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2426 - acc: 0.9863\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2359 - acc: 0.9877\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2312 - acc: 0.9857\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2244 - acc: 0.9898\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2207 - acc: 0.9872\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2114 - acc: 0.9885\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2090 - acc: 0.9900\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2038 - acc: 0.9887\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1986 - acc: 0.9900\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1910 - acc: 0.9920\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1892 - acc: 0.9887\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1816 - acc: 0.9900\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1787 - acc: 0.9900\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1730 - acc: 0.9908\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1680 - acc: 0.9935\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1664 - acc: 0.9902\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1618 - acc: 0.9915\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1567 - acc: 0.9915\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1516 - acc: 0.9928\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1487 - acc: 0.9908\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1428 - acc: 0.9915\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1434 - acc: 0.9902\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1390 - acc: 0.9902\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED71C940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5664 - acc: 0.7125\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6906 - acc: 0.5400\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6590 - acc: 0.8168\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6375 - acc: 0.8877\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6186 - acc: 0.9108\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6029 - acc: 0.9222\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5875 - acc: 0.9310\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5714 - acc: 0.9313\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5598 - acc: 0.9415\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5453 - acc: 0.9457\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5341 - acc: 0.9430\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5213 - acc: 0.9472\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5100 - acc: 0.9520\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5002 - acc: 0.9493\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4882 - acc: 0.9503\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4770 - acc: 0.9502\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4660 - acc: 0.9577\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4548 - acc: 0.9602\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4436 - acc: 0.9608\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4346 - acc: 0.9622\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4238 - acc: 0.9667\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4164 - acc: 0.9670\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4036 - acc: 0.9667\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3950 - acc: 0.9698\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3850 - acc: 0.9750\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3793 - acc: 0.9718\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3691 - acc: 0.9752\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3622 - acc: 0.9740\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3541 - acc: 0.9755\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3437 - acc: 0.9790\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3376 - acc: 0.9757\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3311 - acc: 0.9768\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3223 - acc: 0.9763\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3137 - acc: 0.9805\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3078 - acc: 0.9828\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2982 - acc: 0.9823\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2959 - acc: 0.9797\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2861 - acc: 0.9838\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2780 - acc: 0.9835\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2710 - acc: 0.9880\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2654 - acc: 0.9832\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2597 - acc: 0.9853\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2552 - acc: 0.9847\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2456 - acc: 0.9853\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2416 - acc: 0.9867\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2370 - acc: 0.9883\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2295 - acc: 0.9870\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2250 - acc: 0.9883\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2200 - acc: 0.9855\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2165 - acc: 0.9862\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2099 - acc: 0.9892\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2053 - acc: 0.9878\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2005 - acc: 0.9898\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1965 - acc: 0.9878\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1932 - acc: 0.9878\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1839 - acc: 0.9900\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1803 - acc: 0.9938\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1765 - acc: 0.9932\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1710 - acc: 0.9953\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1680 - acc: 0.9962\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1639 - acc: 0.9962\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1595 - acc: 0.9977\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1562 - acc: 0.9970\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1529 - acc: 0.9977\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1497 - acc: 0.9970\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1430 - acc: 0.9970\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1400 - acc: 0.9983\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1385 - acc: 0.9970\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1324 - acc: 0.9970\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1312 - acc: 0.9977\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1269 - acc: 0.9977\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F22D58B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5546 - acc: 0.7212\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6938 - acc: 0.4997\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6581 - acc: 0.8315\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6352 - acc: 0.8718\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6134 - acc: 0.8950\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5973 - acc: 0.9127\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5800 - acc: 0.9140\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 0.5636 - acc: 0.9240\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5485 - acc: 0.9300\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.5330 - acc: 0.9345\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5214 - acc: 0.9387\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5069 - acc: 0.9422\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4938 - acc: 0.9465\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4823 - acc: 0.9510\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4700 - acc: 0.9475\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4600 - acc: 0.9507\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4459 - acc: 0.9555\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4365 - acc: 0.9515\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4251 - acc: 0.9542\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4152 - acc: 0.9562\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4047 - acc: 0.9562\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3962 - acc: 0.9535\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3841 - acc: 0.9577\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3769 - acc: 0.9597\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3647 - acc: 0.9593\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3594 - acc: 0.9652\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3491 - acc: 0.9642\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3369 - acc: 0.9697\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3303 - acc: 0.9700\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3246 - acc: 0.9713\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3126 - acc: 0.9747\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3057 - acc: 0.9753\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2968 - acc: 0.9787\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2927 - acc: 0.9748\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2882 - acc: 0.9748\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2800 - acc: 0.9755\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2692 - acc: 0.9788\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2645 - acc: 0.9777\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2607 - acc: 0.9777\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2511 - acc: 0.9817\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2467 - acc: 0.9797\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2376 - acc: 0.9822\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2317 - acc: 0.9867\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2250 - acc: 0.9860\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2238 - acc: 0.9855\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2163 - acc: 0.9862\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2110 - acc: 0.9868\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2057 - acc: 0.9868\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2009 - acc: 0.9848\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1950 - acc: 0.9842\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1919 - acc: 0.9870\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1878 - acc: 0.9885\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1820 - acc: 0.9892\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1785 - acc: 0.9885\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1714 - acc: 0.9878\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1668 - acc: 0.9892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1613 - acc: 0.9907\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1597 - acc: 0.9913\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1511 - acc: 0.9913\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1500 - acc: 0.9915\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1468 - acc: 0.9928\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1437 - acc: 0.9915\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1411 - acc: 0.9902\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1351 - acc: 0.9928\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1302 - acc: 0.9945\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1260 - acc: 0.9952\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1257 - acc: 0.9938\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1241 - acc: 0.9938\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1181 - acc: 0.9923\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1159 - acc: 0.9945\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1118 - acc: 0.9932\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC3D9430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5662 - acc: 0.7025\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 0.6933 - acc: 0.5145\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6863 - acc: 0.8007\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6792 - acc: 0.8692\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6717 - acc: 0.8943\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6631 - acc: 0.9115\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6529 - acc: 0.9268\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6433 - acc: 0.9365\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6325 - acc: 0.9467\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6205 - acc: 0.9522\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6098 - acc: 0.9557\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5977 - acc: 0.9597\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5843 - acc: 0.9680\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5728 - acc: 0.9665\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5586 - acc: 0.9720\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5456 - acc: 0.9735\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5311 - acc: 0.9723\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5173 - acc: 0.9740\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5020 - acc: 0.9762\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4867 - acc: 0.9753\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4729 - acc: 0.9728\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4564 - acc: 0.9775\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4441 - acc: 0.9778\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4284 - acc: 0.9837\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4140 - acc: 0.9845\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3997 - acc: 0.9832\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3851 - acc: 0.9832\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3694 - acc: 0.9845\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3571 - acc: 0.9847\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3431 - acc: 0.9847\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3293 - acc: 0.9840\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3143 - acc: 0.9855\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3031 - acc: 0.9862\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2881 - acc: 0.9868\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2762 - acc: 0.9877\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2654 - acc: 0.9900\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2537 - acc: 0.9885\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2412 - acc: 0.9893\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2338 - acc: 0.9907\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2217 - acc: 0.9913\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2129 - acc: 0.9902\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2016 - acc: 0.9902\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1934 - acc: 0.9908\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1821 - acc: 0.9930\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1733 - acc: 0.9932\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1653 - acc: 0.9945\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1548 - acc: 0.9938\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1502 - acc: 0.9940\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1400 - acc: 0.9967\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1347 - acc: 0.9955\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1263 - acc: 0.9962\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1199 - acc: 0.9968\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1139 - acc: 0.9977\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1088 - acc: 0.9977\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1005 - acc: 0.9977\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0980 - acc: 0.9970\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0917 - acc: 0.9970\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0863 - acc: 0.9977\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0808 - acc: 0.9977\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0780 - acc: 0.9970\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0734 - acc: 0.9977\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0689 - acc: 0.9977\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0652 - acc: 0.9977\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0610 - acc: 0.9992\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0581 - acc: 0.9992\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0549 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0501 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0484 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0448 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0423 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0405 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E897CAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6141 - acc: 0.7188\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6930 - acc: 0.5078\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6830 - acc: 0.8083\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6735 - acc: 0.8867\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6629 - acc: 0.9113\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6515 - acc: 0.9338\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6390 - acc: 0.9487\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6257 - acc: 0.9573\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6119 - acc: 0.9567\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5982 - acc: 0.9642\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5837 - acc: 0.9667\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5693 - acc: 0.9693\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5538 - acc: 0.9708\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5390 - acc: 0.9740\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5241 - acc: 0.9760\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5083 - acc: 0.9757\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4935 - acc: 0.9793\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4786 - acc: 0.9787\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4614 - acc: 0.9815\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4460 - acc: 0.9852\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4316 - acc: 0.9825\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4149 - acc: 0.9853\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4018 - acc: 0.9833\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3864 - acc: 0.9840\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3715 - acc: 0.9847\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3579 - acc: 0.9833\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3431 - acc: 0.9867\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3286 - acc: 0.9913\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3159 - acc: 0.9893\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3030 - acc: 0.9923\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2933 - acc: 0.9910\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2760 - acc: 0.9937\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2677 - acc: 0.9923\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2571 - acc: 0.9923\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2424 - acc: 0.9937\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2335 - acc: 0.9923\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2236 - acc: 0.9917\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2139 - acc: 0.9937\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2017 - acc: 0.9937\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1951 - acc: 0.9910\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1835 - acc: 0.9922\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1778 - acc: 0.9923\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1693 - acc: 0.9917\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1621 - acc: 0.9930\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1540 - acc: 0.9938\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1469 - acc: 0.9923\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1379 - acc: 0.9952\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1328 - acc: 0.9945\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1280 - acc: 0.9940\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1208 - acc: 0.9953\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1152 - acc: 0.9953\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1088 - acc: 0.9938\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1033 - acc: 0.9960\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0998 - acc: 0.9947\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0921 - acc: 0.9938\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0887 - acc: 0.9953\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0858 - acc: 0.9947\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0810 - acc: 0.9947\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0781 - acc: 0.994 - 0s 10ms/step - loss: 0.0772 - acc: 0.9947\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0731 - acc: 0.9953\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0711 - acc: 0.9940\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0651 - acc: 0.9975\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0624 - acc: 0.9953\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0599 - acc: 0.9962\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0574 - acc: 0.9955\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0526 - acc: 0.9960\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0512 - acc: 0.9962\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0499 - acc: 0.9947\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0470 - acc: 0.9962\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0450 - acc: 0.9962\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0425 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC27D040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6563 - acc: 0.6975\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6897 - acc: 0.5543\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6503 - acc: 0.8065\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6190 - acc: 0.8763\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5912 - acc: 0.9102\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5654 - acc: 0.9160\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5398 - acc: 0.9347\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5158 - acc: 0.9380\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4930 - acc: 0.9452\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4714 - acc: 0.9548\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4502 - acc: 0.9642\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4318 - acc: 0.9643\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4138 - acc: 0.9632\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3938 - acc: 0.9648\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3768 - acc: 0.9698\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3603 - acc: 0.9702\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3438 - acc: 0.9730\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3299 - acc: 0.9740\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3150 - acc: 0.9763\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2985 - acc: 0.9782\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2855 - acc: 0.9813\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2725 - acc: 0.9808\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2605 - acc: 0.9843\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2473 - acc: 0.9850\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2380 - acc: 0.9857\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2250 - acc: 0.9863\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2151 - acc: 0.9883\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2056 - acc: 0.9893\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1952 - acc: 0.9908\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1846 - acc: 0.9908\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1779 - acc: 0.9902\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1673 - acc: 0.9923\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1595 - acc: 0.9938\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1538 - acc: 0.9947\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1459 - acc: 0.9947\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1376 - acc: 0.9955\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1296 - acc: 0.9975\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1236 - acc: 0.9977\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1185 - acc: 0.9970\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1135 - acc: 0.9970\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1067 - acc: 0.9970\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1016 - acc: 0.9977\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0961 - acc: 0.9977\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0920 - acc: 0.9977\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0874 - acc: 0.9992\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0832 - acc: 0.9985\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0771 - acc: 0.998 - 0s 9ms/step - loss: 0.0779 - acc: 0.9985\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0752 - acc: 1.0000\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0714 - acc: 1.0000\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0672 - acc: 1.0000\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0628 - acc: 1.0000\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0601 - acc: 1.0000\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0570 - acc: 1.0000\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0544 - acc: 1.0000\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0511 - acc: 1.0000\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0489 - acc: 1.0000\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0459 - acc: 1.0000\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0440 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0412 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0392 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0379 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0341 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0317 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0299 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0284 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0260 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0232 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0219 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F36418B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7099 - acc: 0.7063\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6917 - acc: 0.5230\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6456 - acc: 0.7968\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6111 - acc: 0.8700\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5770 - acc: 0.8952\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5451 - acc: 0.9077\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5183 - acc: 0.9365\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4911 - acc: 0.9365\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4653 - acc: 0.9458\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4409 - acc: 0.9482\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4178 - acc: 0.9508\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3987 - acc: 0.9562\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3804 - acc: 0.9572\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3604 - acc: 0.9578\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3381 - acc: 0.9628\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3250 - acc: 0.9632\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3061 - acc: 0.9668\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2925 - acc: 0.9705\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2754 - acc: 0.9737\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2622 - acc: 0.9727\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2461 - acc: 0.9805\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2374 - acc: 0.9823\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2248 - acc: 0.9838\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2143 - acc: 0.9855\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2029 - acc: 0.9847\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1932 - acc: 0.9877\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1831 - acc: 0.9897\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1778 - acc: 0.9887\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1665 - acc: 0.9895\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1575 - acc: 0.9930\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1511 - acc: 0.9938\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1413 - acc: 0.9915\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1350 - acc: 0.9932\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1257 - acc: 0.9952\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1208 - acc: 0.9930\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1163 - acc: 0.9945\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1103 - acc: 0.9938\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1049 - acc: 0.9945\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0988 - acc: 0.9915\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0953 - acc: 0.9932\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0895 - acc: 0.9945\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0873 - acc: 0.9932\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0824 - acc: 0.9925\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0765 - acc: 0.9930\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0743 - acc: 0.9938\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0704 - acc: 0.9923\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0665 - acc: 0.9938\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0631 - acc: 0.9947\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0610 - acc: 0.9947\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0566 - acc: 0.9960\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0566 - acc: 0.9940\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0511 - acc: 0.9960\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0507 - acc: 0.9962\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0482 - acc: 0.9968\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0462 - acc: 0.9962\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0442 - acc: 0.9962\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0413 - acc: 0.9962\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0399 - acc: 0.9962\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0399 - acc: 0.9947\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0348 - acc: 0.9960\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0343 - acc: 0.9962\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0335 - acc: 0.9962\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0340 - acc: 0.9955\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0321 - acc: 0.9962\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0299 - acc: 0.9962\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0288 - acc: 0.9962\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0275 - acc: 0.9962\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0268 - acc: 0.9962\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0246 - acc: 0.9968\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0243 - acc: 0.9962\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0233 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D8F3ADC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7427 - acc: 0.6988\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6920 - acc: 0.5375\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6805 - acc: 0.7490\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6675 - acc: 0.8423\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6532 - acc: 0.8782\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6369 - acc: 0.9043\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6200 - acc: 0.9202\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5992 - acc: 0.9353\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5810 - acc: 0.9445\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5605 - acc: 0.9478\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5381 - acc: 0.9612\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5152 - acc: 0.9645\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4949 - acc: 0.9705\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4721 - acc: 0.9688\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4485 - acc: 0.9745\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4246 - acc: 0.9777\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4063 - acc: 0.9793\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3835 - acc: 0.9822\n",
      "Epoch 18/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3626 - acc: 0.9810\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3436 - acc: 0.9817\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3195 - acc: 0.9848\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3012 - acc: 0.9892\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2824 - acc: 0.9907\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2644 - acc: 0.9937\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2463 - acc: 0.9940\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2309 - acc: 0.9940\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2134 - acc: 0.9953\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1999 - acc: 0.9947\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1838 - acc: 0.9953\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1724 - acc: 0.9975\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1580 - acc: 0.9970\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1462 - acc: 0.9970\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1336 - acc: 0.9983\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1236 - acc: 0.9970\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1154 - acc: 0.9977\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1057 - acc: 0.9970\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0957 - acc: 0.9977\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0879 - acc: 0.9977\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0806 - acc: 0.9977\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0750 - acc: 0.9985\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0685 - acc: 0.9985\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0639 - acc: 1.0000\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0576 - acc: 1.0000\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0512 - acc: 1.0000\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0426 - acc: 1.0000\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0390 - acc: 1.0000\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0328 - acc: 1.0000\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0300 - acc: 1.0000\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0199 - acc: 1.0000\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0037 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC2FD820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9298 - acc: 0.7188\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6924 - acc: 0.5403\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6850 - acc: 0.7458\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6748 - acc: 0.7897\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6624 - acc: 0.8742\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6496 - acc: 0.9092\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6357 - acc: 0.9155\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6205 - acc: 0.9413\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6050 - acc: 0.9453\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5884 - acc: 0.9520\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5724 - acc: 0.9555\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5544 - acc: 0.9648\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5388 - acc: 0.9663\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5194 - acc: 0.9717\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5023 - acc: 0.9755\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4836 - acc: 0.9762\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4649 - acc: 0.9787\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4463 - acc: 0.9808\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4283 - acc: 0.9757\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4083 - acc: 0.9793\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3911 - acc: 0.9838\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3734 - acc: 0.9853\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3545 - acc: 0.9903\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3374 - acc: 0.9907\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3225 - acc: 0.9913\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3055 - acc: 0.9893\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2881 - acc: 0.9907\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2739 - acc: 0.9907\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2580 - acc: 0.9915\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2459 - acc: 0.9908\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2302 - acc: 0.9908\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2168 - acc: 0.9908\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2037 - acc: 0.9922\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1900 - acc: 0.9922\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1800 - acc: 0.9922\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1688 - acc: 0.9915\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1569 - acc: 0.9922\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1471 - acc: 0.9930\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1360 - acc: 0.9922\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1285 - acc: 0.9937\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1202 - acc: 0.9922\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1126 - acc: 0.9923\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1041 - acc: 0.9945\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1000 - acc: 0.9932\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0944 - acc: 0.9940\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0859 - acc: 0.9947\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0790 - acc: 0.9967\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0755 - acc: 0.9953\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0692 - acc: 0.9962\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0657 - acc: 0.9947\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0597 - acc: 0.9968\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0572 - acc: 0.9947\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0526 - acc: 0.9947\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0487 - acc: 0.9962\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0451 - acc: 0.9953\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0418 - acc: 0.9968\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0399 - acc: 0.9947\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0385 - acc: 0.9955\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0351 - acc: 0.9968\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0338 - acc: 0.9947\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0308 - acc: 0.9968\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0277 - acc: 0.9968\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0282 - acc: 0.9955\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0264 - acc: 0.9947\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0239 - acc: 0.9962\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0215 - acc: 0.9960\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0205 - acc: 0.9968\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0201 - acc: 0.9955\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0192 - acc: 0.9953\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0168 - acc: 0.9968\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0172 - acc: 0.9955\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED9EDE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7590 - acc: 0.7075\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6996 - acc: 0.4475\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6618 - acc: 0.8098\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6281 - acc: 0.8938\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5924 - acc: 0.9293\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5555 - acc: 0.9358\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5212 - acc: 0.9503\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4882 - acc: 0.9612\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4542 - acc: 0.9637\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4238 - acc: 0.9765\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3943 - acc: 0.9770\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3686 - acc: 0.9803\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3418 - acc: 0.9765\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3199 - acc: 0.9808\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2977 - acc: 0.9837\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2770 - acc: 0.9882\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2593 - acc: 0.9878\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2408 - acc: 0.9885\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2246 - acc: 0.9902\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2064 - acc: 0.9937\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1953 - acc: 0.9938\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1814 - acc: 0.9955\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1674 - acc: 0.9962\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1550 - acc: 0.9962\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1447 - acc: 0.9977\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1337 - acc: 0.9977\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1243 - acc: 0.9977\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1164 - acc: 0.9977\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1082 - acc: 0.9977\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1006 - acc: 0.9985\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0931 - acc: 0.9985\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0871 - acc: 0.9985\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0797 - acc: 0.9992\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0759 - acc: 1.0000\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0702 - acc: 1.0000\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0664 - acc: 1.0000\n",
      "Epoch 36/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0622 - acc: 1.0000\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0581 - acc: 1.0000\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0537 - acc: 1.0000\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0511 - acc: 1.0000\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0474 - acc: 1.0000\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0447 - acc: 1.0000\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0420 - acc: 1.0000\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0388 - acc: 1.0000\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0370 - acc: 1.0000\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0346 - acc: 1.0000\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0324 - acc: 1.0000\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0275 - acc: 1.0000\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0258 - acc: 1.0000\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0243 - acc: 1.0000\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0232 - acc: 1.0000\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0205 - acc: 1.0000\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0194 - acc: 1.0000\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0129 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0124 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0118 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0108 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0093 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E897C5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9356 - acc: 0.7075\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6921 - acc: 0.5227\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6556 - acc: 0.7632\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6200 - acc: 0.8477\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5813 - acc: 0.9042\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5428 - acc: 0.9315\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5094 - acc: 0.9462\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4740 - acc: 0.9537\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4415 - acc: 0.9583\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4147 - acc: 0.9538\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3838 - acc: 0.9572\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3579 - acc: 0.9690\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3326 - acc: 0.9735\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3137 - acc: 0.9688\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2904 - acc: 0.9788\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2731 - acc: 0.9755\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2532 - acc: 0.9823\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2356 - acc: 0.9840\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2213 - acc: 0.9870\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2092 - acc: 0.986 - 0s 9ms/step - loss: 0.2062 - acc: 0.9870\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1928 - acc: 0.9855\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1784 - acc: 0.9900\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1672 - acc: 0.9887\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1576 - acc: 0.9895\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1412 - acc: 0.994 - 0s 10ms/step - loss: 0.1439 - acc: 0.9922\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1371 - acc: 0.9902\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1278 - acc: 0.9917\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1192 - acc: 0.9923\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1124 - acc: 0.9910\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1050 - acc: 0.9923\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0976 - acc: 0.9930\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0925 - acc: 0.9938\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0856 - acc: 0.9952\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0817 - acc: 0.9945\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0775 - acc: 0.9932\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0715 - acc: 0.9952\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0705 - acc: 0.9947\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0655 - acc: 0.9962\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0625 - acc: 0.9962\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0589 - acc: 0.9962\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0567 - acc: 0.9962\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0536 - acc: 0.9955\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0512 - acc: 0.9962\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0483 - acc: 0.9947\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0462 - acc: 0.9955\n",
      "Epoch 45/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0426 - acc: 0.9968\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0411 - acc: 0.9953\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0386 - acc: 0.9962\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0388 - acc: 0.9955\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0358 - acc: 0.9968\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0341 - acc: 0.9953\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0336 - acc: 0.9947\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0309 - acc: 0.9962\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0299 - acc: 0.9962\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0280 - acc: 0.9968\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0276 - acc: 0.9962\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0265 - acc: 0.9947\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0250 - acc: 0.9953\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0237 - acc: 0.9968\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0223 - acc: 0.9968\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0220 - acc: 0.9968\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0198 - acc: 0.9968\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0205 - acc: 0.9962\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0199 - acc: 0.9970\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0183 - acc: 0.9977\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0171 - acc: 0.9983\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0169 - acc: 0.9977\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0165 - acc: 0.9970\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0154 - acc: 0.9977\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0147 - acc: 0.9977\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0136 - acc: 0.9983\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F22D5F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9280 - acc: 0.7013\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6938 - acc: 0.4845\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6769 - acc: 0.7618\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6642 - acc: 0.8503\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6526 - acc: 0.8822\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6392 - acc: 0.8998\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6264 - acc: 0.9210\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6140 - acc: 0.9287\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6032 - acc: 0.9343\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5911 - acc: 0.9448\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5800 - acc: 0.9448\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5666 - acc: 0.9562\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5550 - acc: 0.9610\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5437 - acc: 0.9560\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5325 - acc: 0.9577\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5214 - acc: 0.9613\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5113 - acc: 0.9608\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5013 - acc: 0.9590\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4881 - acc: 0.9702\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4783 - acc: 0.9662\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4672 - acc: 0.9647\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4581 - acc: 0.9682\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4482 - acc: 0.9672\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4389 - acc: 0.9683\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4279 - acc: 0.9683\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4194 - acc: 0.9672\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4082 - acc: 0.9720\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3977 - acc: 0.9758\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3891 - acc: 0.9753\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3816 - acc: 0.9792\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3714 - acc: 0.9770\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3613 - acc: 0.9798\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3520 - acc: 0.9777\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3469 - acc: 0.9778\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3386 - acc: 0.9785\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3298 - acc: 0.9785\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3204 - acc: 0.9785\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3126 - acc: 0.9810\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3073 - acc: 0.9823\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2991 - acc: 0.9855\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2896 - acc: 0.9868\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2826 - acc: 0.9852\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2760 - acc: 0.9855\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2712 - acc: 0.9848\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2623 - acc: 0.9842\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2567 - acc: 0.9868\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2490 - acc: 0.9862\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2407 - acc: 0.9868\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2350 - acc: 0.9875\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2307 - acc: 0.9870\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2261 - acc: 0.9872\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2173 - acc: 0.9885\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2129 - acc: 0.9907\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2089 - acc: 0.9880\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2003 - acc: 0.9907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1956 - acc: 0.9902\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1905 - acc: 0.9902\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1886 - acc: 0.9908\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1799 - acc: 0.9922\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1759 - acc: 0.9943\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1719 - acc: 0.9938\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC558550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5464 - acc: 0.7287\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6941 - acc: 0.4977\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6739 - acc: 0.8015\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6587 - acc: 0.9063\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6441 - acc: 0.9430\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6303 - acc: 0.9550\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6170 - acc: 0.9592\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6027 - acc: 0.9632\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5894 - acc: 0.9638\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5761 - acc: 0.9640\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5625 - acc: 0.9668\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5502 - acc: 0.9663\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5373 - acc: 0.9688\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5236 - acc: 0.9757\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5130 - acc: 0.9695\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5009 - acc: 0.9738\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4889 - acc: 0.9732\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4771 - acc: 0.9752\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4655 - acc: 0.9752\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4553 - acc: 0.9732\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4436 - acc: 0.9767\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4335 - acc: 0.9732\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4225 - acc: 0.9747\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4125 - acc: 0.9740\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4057 - acc: 0.9748\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3925 - acc: 0.9767\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3823 - acc: 0.9768\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3726 - acc: 0.9787\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3633 - acc: 0.9798\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3555 - acc: 0.9800\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3465 - acc: 0.9813\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3394 - acc: 0.9780\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3290 - acc: 0.9813\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3201 - acc: 0.9835\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3123 - acc: 0.9815\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3040 - acc: 0.9838\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2958 - acc: 0.9837\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2883 - acc: 0.9845\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2811 - acc: 0.9838\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2758 - acc: 0.9832\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2639 - acc: 0.9852\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2597 - acc: 0.9847\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2522 - acc: 0.9840\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2470 - acc: 0.9855\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2391 - acc: 0.9847\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2333 - acc: 0.9855\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2277 - acc: 0.9862\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2222 - acc: 0.9855\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2147 - acc: 0.9877\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2085 - acc: 0.9892\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2046 - acc: 0.9885\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1983 - acc: 0.9878\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1930 - acc: 0.9878\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1866 - acc: 0.9878\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1795 - acc: 0.9898\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1751 - acc: 0.9898\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1716 - acc: 0.9900\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1679 - acc: 0.9900\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1627 - acc: 0.9893\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1595 - acc: 0.9893\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1536 - acc: 0.9900\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F22D5CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5536 - acc: 0.7025\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6890 - acc: 0.5473\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6453 - acc: 0.8233\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6172 - acc: 0.8753\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5936 - acc: 0.8898\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5730 - acc: 0.9123\n",
      "Epoch 6/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5542 - acc: 0.9187\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5359 - acc: 0.9310\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5213 - acc: 0.9418\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5048 - acc: 0.9425\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4920 - acc: 0.9440\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4768 - acc: 0.9513\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4635 - acc: 0.9555\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4507 - acc: 0.9635\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4359 - acc: 0.9643\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4282 - acc: 0.9648\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4149 - acc: 0.9665\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4040 - acc: 0.9655\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3916 - acc: 0.9700\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3797 - acc: 0.9722\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3713 - acc: 0.9730\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3612 - acc: 0.9745\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3514 - acc: 0.9752\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3425 - acc: 0.9767\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3357 - acc: 0.9743\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3231 - acc: 0.9775\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3176 - acc: 0.9750\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3063 - acc: 0.9797\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2979 - acc: 0.9777\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2882 - acc: 0.9820\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2822 - acc: 0.9815\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2760 - acc: 0.9802\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2675 - acc: 0.9823\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2626 - acc: 0.9830\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2513 - acc: 0.9837\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2464 - acc: 0.9847\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2401 - acc: 0.9862\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2323 - acc: 0.9862\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2275 - acc: 0.9875\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2188 - acc: 0.9890\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2133 - acc: 0.9885\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2091 - acc: 0.9907\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2048 - acc: 0.9887\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1984 - acc: 0.9915\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1919 - acc: 0.9900\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1856 - acc: 0.9915\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1806 - acc: 0.9923\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1786 - acc: 0.9938\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1706 - acc: 0.9938\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1671 - acc: 0.9947\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1627 - acc: 0.9955\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1563 - acc: 0.9962\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1525 - acc: 0.9962\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1491 - acc: 0.9968\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1441 - acc: 0.9975\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1418 - acc: 0.9962\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1377 - acc: 0.9955\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1366 - acc: 0.996 - 0s 9ms/step - loss: 0.1345 - acc: 0.9962\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1290 - acc: 0.9955\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1265 - acc: 0.9962\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1221 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED806310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5549 - acc: 0.7212\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6906 - acc: 0.5568\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6631 - acc: 0.8058\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6440 - acc: 0.8488\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6272 - acc: 0.8832\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6111 - acc: 0.8870\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5967 - acc: 0.9015\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5836 - acc: 0.9102\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5691 - acc: 0.9185\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5563 - acc: 0.9320\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5432 - acc: 0.9363\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5343 - acc: 0.9407\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5191 - acc: 0.9432\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5099 - acc: 0.9427\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4967 - acc: 0.9440\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4868 - acc: 0.9483\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4768 - acc: 0.9465\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4671 - acc: 0.9465\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4541 - acc: 0.9492\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4455 - acc: 0.9445\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4343 - acc: 0.9480\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4258 - acc: 0.9473\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4159 - acc: 0.9528\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4059 - acc: 0.9543\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3948 - acc: 0.9563\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3856 - acc: 0.9603\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3783 - acc: 0.9593\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3702 - acc: 0.9648\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3598 - acc: 0.9638\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3531 - acc: 0.9640\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3443 - acc: 0.9660\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3360 - acc: 0.9708\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3285 - acc: 0.9727\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3210 - acc: 0.9738\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3130 - acc: 0.9752\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3086 - acc: 0.9728\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2964 - acc: 0.9775\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2880 - acc: 0.9755\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2836 - acc: 0.9768\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2778 - acc: 0.9765\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2703 - acc: 0.9790\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 22ms/step - loss: 0.2636 - acc: 0.9807\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2581 - acc: 0.9800\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2505 - acc: 0.9815\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2472 - acc: 0.9845\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2426 - acc: 0.9825\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2344 - acc: 0.9860\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2299 - acc: 0.9847\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2213 - acc: 0.9860\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2191 - acc: 0.9853\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2116 - acc: 0.9877\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2063 - acc: 0.9877\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2031 - acc: 0.9878\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1991 - acc: 0.9878\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1918 - acc: 0.9907\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1872 - acc: 0.9887\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1795 - acc: 0.9913\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1779 - acc: 0.9907\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1760 - acc: 0.9893\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1673 - acc: 0.9913\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1673 - acc: 0.9880\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D6716280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5592 - acc: 0.7063\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6930 - acc: 0.5050\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6772 - acc: 0.6370\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6651 - acc: 0.7173\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6522 - acc: 0.7928\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6410 - acc: 0.8522\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6291 - acc: 0.8885\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6169 - acc: 0.9068\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6061 - acc: 0.9250\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5932 - acc: 0.9348\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5841 - acc: 0.9452\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5720 - acc: 0.9530\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5605 - acc: 0.9517\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5503 - acc: 0.9545\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5401 - acc: 0.9538\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5310 - acc: 0.9615\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5198 - acc: 0.9592\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5098 - acc: 0.9607\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4983 - acc: 0.9693\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.4890 - acc: 0.9695\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4813 - acc: 0.9713\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4703 - acc: 0.9722\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4621 - acc: 0.9745\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4558 - acc: 0.9742\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4465 - acc: 0.9747\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4377 - acc: 0.9735\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4275 - acc: 0.9775\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4214 - acc: 0.9770\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.4119 - acc: 0.9763\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4040 - acc: 0.9770\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3973 - acc: 0.9783\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3907 - acc: 0.9763\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3814 - acc: 0.9793\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3720 - acc: 0.9820\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3667 - acc: 0.9807\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3589 - acc: 0.9820\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3521 - acc: 0.9838\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3436 - acc: 0.9833\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3368 - acc: 0.9853\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3316 - acc: 0.9840\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3259 - acc: 0.9840\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3164 - acc: 0.9860\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3109 - acc: 0.9860\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3026 - acc: 0.9868\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2973 - acc: 0.9870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2919 - acc: 0.9868\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2857 - acc: 0.9893\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2800 - acc: 0.9878\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2753 - acc: 0.9892\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.2682 - acc: 0.9907\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2618 - acc: 0.9887\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2585 - acc: 0.9900\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2517 - acc: 0.9900\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2447 - acc: 0.9927\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2390 - acc: 0.9915\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2359 - acc: 0.9937\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2303 - acc: 0.9937\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2267 - acc: 0.9938\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2212 - acc: 0.9938\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2145 - acc: 0.9945\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2096 - acc: 0.9968\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0DA780C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5723 - acc: 0.7250\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6936 - acc: 0.4755\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6791 - acc: 0.7575\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6676 - acc: 0.8473\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6554 - acc: 0.8650\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6436 - acc: 0.8903\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6327 - acc: 0.9043\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6199 - acc: 0.9147\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6089 - acc: 0.9130\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5972 - acc: 0.9193\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5853 - acc: 0.9222\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5753 - acc: 0.9387\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5632 - acc: 0.9373\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5532 - acc: 0.9443\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5404 - acc: 0.9495\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5309 - acc: 0.9505\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5197 - acc: 0.9550\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5092 - acc: 0.9640\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5010 - acc: 0.9572\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4896 - acc: 0.9592\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4804 - acc: 0.9607\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4709 - acc: 0.9593\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4597 - acc: 0.9593\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4520 - acc: 0.9610\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4419 - acc: 0.9623\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4346 - acc: 0.9637\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4244 - acc: 0.9608\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4152 - acc: 0.9652\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4064 - acc: 0.9655\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3987 - acc: 0.9673\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3889 - acc: 0.9670\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3814 - acc: 0.9673\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3742 - acc: 0.9665\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3731 - acc: 0.966 - 0s 10ms/step - loss: 0.3680 - acc: 0.9695\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3587 - acc: 0.9703\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3510 - acc: 0.9717\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3437 - acc: 0.9748\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3331 - acc: 0.9802\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3268 - acc: 0.9793\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3236 - acc: 0.9787\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3109 - acc: 0.9815\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3033 - acc: 0.9838\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2999 - acc: 0.9842\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2919 - acc: 0.9847\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2843 - acc: 0.9875\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2781 - acc: 0.9877\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2738 - acc: 0.9885\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2635 - acc: 0.9898\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2587 - acc: 0.9920\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2534 - acc: 0.9900\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2483 - acc: 0.9915\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2423 - acc: 0.9902\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.2410 - acc: 0.990 - 0s 10ms/step - loss: 0.2376 - acc: 0.9908\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2295 - acc: 0.9908\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2258 - acc: 0.9902\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2205 - acc: 0.9902\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2139 - acc: 0.9915\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2100 - acc: 0.9902\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2044 - acc: 0.9915\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1973 - acc: 0.9922\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1938 - acc: 0.9915\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F256A3A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5691 - acc: 0.7113\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6942 - acc: 0.5008\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6501 - acc: 0.8447\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6203 - acc: 0.9002\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5955 - acc: 0.9205\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5757 - acc: 0.9253\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5542 - acc: 0.9378\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5360 - acc: 0.9387\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5171 - acc: 0.9483\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5032 - acc: 0.9480\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4890 - acc: 0.9537\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4720 - acc: 0.9560\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4599 - acc: 0.9582\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4452 - acc: 0.9627\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4327 - acc: 0.9620\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4220 - acc: 0.9667\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4080 - acc: 0.9625\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3981 - acc: 0.9668\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3857 - acc: 0.9683\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3743 - acc: 0.9698\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3659 - acc: 0.9685\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3550 - acc: 0.9730\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3425 - acc: 0.9737\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3315 - acc: 0.9758\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3251 - acc: 0.9748\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3167 - acc: 0.9733\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3066 - acc: 0.9780\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2982 - acc: 0.9800\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2897 - acc: 0.9793\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2820 - acc: 0.9787\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2724 - acc: 0.9808\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2640 - acc: 0.9837\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2580 - acc: 0.9815\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2523 - acc: 0.9810\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2448 - acc: 0.9832\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2346 - acc: 0.9845\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2326 - acc: 0.9848\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2241 - acc: 0.9848\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2183 - acc: 0.9877\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2117 - acc: 0.9863\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2059 - acc: 0.9857\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1972 - acc: 0.9898\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1940 - acc: 0.9900\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1873 - acc: 0.9893\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1832 - acc: 0.9922\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1749 - acc: 0.9913\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1711 - acc: 0.9922\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1671 - acc: 0.9917\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1627 - acc: 0.9923\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1588 - acc: 0.9930\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1539 - acc: 0.9915\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1481 - acc: 0.9938\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1438 - acc: 0.9932\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1403 - acc: 0.9938\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1381 - acc: 0.9940\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1326 - acc: 0.9952\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1291 - acc: 0.9955\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1249 - acc: 0.9975\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1208 - acc: 0.9962\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1192 - acc: 0.9955\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1150 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0FBB2B0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5544 - acc: 0.7163\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6951 - acc: 0.4752\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6666 - acc: 0.8167\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6471 - acc: 0.8835\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6297 - acc: 0.9018\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6138 - acc: 0.9170\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5997 - acc: 0.9282\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5844 - acc: 0.9318\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5709 - acc: 0.9365\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5574 - acc: 0.9418\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5474 - acc: 0.9440\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5341 - acc: 0.9467\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5213 - acc: 0.9438\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5099 - acc: 0.9463\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4988 - acc: 0.9522\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4877 - acc: 0.9515\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4778 - acc: 0.9510\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4666 - acc: 0.9550\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4541 - acc: 0.9517\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4438 - acc: 0.9550\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4345 - acc: 0.9562\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4245 - acc: 0.9603\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4149 - acc: 0.9577\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4043 - acc: 0.9563\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3938 - acc: 0.9670\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3867 - acc: 0.9625\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3757 - acc: 0.9650\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3681 - acc: 0.9668\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3591 - acc: 0.9668\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.3495 - acc: 0.9675\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3415 - acc: 0.9642\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3338 - acc: 0.9677\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 0.3255 - acc: 0.9683\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3208 - acc: 0.9685\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3102 - acc: 0.9682\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3045 - acc: 0.9695\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2947 - acc: 0.9715\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2904 - acc: 0.9708\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2830 - acc: 0.9717\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2761 - acc: 0.9738\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2702 - acc: 0.9770\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2622 - acc: 0.9792\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2566 - acc: 0.9837\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2515 - acc: 0.9823\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2428 - acc: 0.9830\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2356 - acc: 0.9830\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2322 - acc: 0.9823\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2276 - acc: 0.9838\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2177 - acc: 0.9867\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2144 - acc: 0.9848\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2067 - acc: 0.9882\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2061 - acc: 0.9877\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1996 - acc: 0.9877\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1951 - acc: 0.9893\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1917 - acc: 0.9893\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1855 - acc: 0.9878\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1802 - acc: 0.9892\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1747 - acc: 0.9908\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1694 - acc: 0.9928\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1640 - acc: 0.9915\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1634 - acc: 0.9908\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED9DEB80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5605 - acc: 0.6988\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6934 - acc: 0.5150\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6814 - acc: 0.8050\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6699 - acc: 0.8892\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6571 - acc: 0.9370\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6431 - acc: 0.9550\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6274 - acc: 0.9688\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6120 - acc: 0.9677\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5954 - acc: 0.9735\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5788 - acc: 0.9755\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5618 - acc: 0.9802\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5427 - acc: 0.9792\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5248 - acc: 0.9800\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5062 - acc: 0.9795\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4876 - acc: 0.9855\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4694 - acc: 0.9802\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4507 - acc: 0.9822\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 0.4329 - acc: 0.9830\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.4177 - acc: 0.990 - 0s 11ms/step - loss: 0.4158 - acc: 0.9867\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3986 - acc: 0.9870\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3808 - acc: 0.9860\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3655 - acc: 0.9875\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3483 - acc: 0.9877\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3308 - acc: 0.9898\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3146 - acc: 0.9882\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3024 - acc: 0.9885\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2859 - acc: 0.9922\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2743 - acc: 0.9923\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2591 - acc: 0.9945\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2477 - acc: 0.9962\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2315 - acc: 0.9953\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2219 - acc: 0.9947\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2100 - acc: 0.9955\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1979 - acc: 0.9955\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1872 - acc: 0.9962\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1746 - acc: 0.998 - 0s 8ms/step - loss: 0.1754 - acc: 0.9968\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1652 - acc: 0.9968\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1577 - acc: 0.9970\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1477 - acc: 0.9970\n",
      "Epoch 39/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1386 - acc: 0.9977\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1310 - acc: 0.9970\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1243 - acc: 0.9970\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1162 - acc: 0.9970\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1101 - acc: 0.9970\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1023 - acc: 0.9977\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0964 - acc: 0.9977\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0888 - acc: 0.9983\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0858 - acc: 0.9970\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0793 - acc: 0.9970\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0748 - acc: 0.9970\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0698 - acc: 0.9983\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0664 - acc: 0.9985\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0607 - acc: 0.9985\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0582 - acc: 0.9992\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0534 - acc: 0.9992\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0510 - acc: 0.9985\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0478 - acc: 0.9992\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0448 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0427 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0385 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0375 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E9CC8280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6265 - acc: 0.7088\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 0.6933 - acc: 0.5142\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6827 - acc: 0.7825\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6722 - acc: 0.8587\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6608 - acc: 0.8932\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6479 - acc: 0.9165\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6339 - acc: 0.9345\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6204 - acc: 0.9528\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6044 - acc: 0.9533\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5902 - acc: 0.9570\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5741 - acc: 0.9638\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5575 - acc: 0.9630\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5404 - acc: 0.9708\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5254 - acc: 0.9663\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5073 - acc: 0.9708\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4894 - acc: 0.9725\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4730 - acc: 0.9762\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4545 - acc: 0.9775\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4416 - acc: 0.9765\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4219 - acc: 0.9785\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4045 - acc: 0.9802\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3881 - acc: 0.9822\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3745 - acc: 0.9823\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3581 - acc: 0.9850\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3403 - acc: 0.9843\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3250 - acc: 0.9852\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3118 - acc: 0.9865\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2987 - acc: 0.9833\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2865 - acc: 0.9847\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2735 - acc: 0.9877\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2615 - acc: 0.9848\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2499 - acc: 0.9907\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2364 - acc: 0.9878\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2257 - acc: 0.9892\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2149 - acc: 0.9900\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2039 - acc: 0.9900\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1933 - acc: 0.9898\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1830 - acc: 0.9915\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1759 - acc: 0.9928\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1686 - acc: 0.9895\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1596 - acc: 0.9908\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1500 - acc: 0.9930\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1442 - acc: 0.9923\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1367 - acc: 0.9932\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1274 - acc: 0.9938\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1221 - acc: 0.9945\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1132 - acc: 0.9945\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1089 - acc: 0.9953\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1029 - acc: 0.9923\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0959 - acc: 0.9938\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0918 - acc: 0.9945\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0894 - acc: 0.9923\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0829 - acc: 0.9923\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0791 - acc: 0.9932\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0744 - acc: 0.9953\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0709 - acc: 0.9947\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0664 - acc: 0.9953\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0642 - acc: 0.9953\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0582 - acc: 0.9968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0568 - acc: 0.9947\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0532 - acc: 0.9962\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDB9B5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6425 - acc: 0.6988\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6925 - acc: 0.5163\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6413 - acc: 0.8157\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5998 - acc: 0.8805\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5625 - acc: 0.9147\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5242 - acc: 0.9413\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4944 - acc: 0.9478\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4611 - acc: 0.9513\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4287 - acc: 0.9587\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3997 - acc: 0.9652\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3762 - acc: 0.9670\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3508 - acc: 0.9690\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3305 - acc: 0.9723\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3087 - acc: 0.9740\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2893 - acc: 0.9738\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2701 - acc: 0.9748\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2541 - acc: 0.9768\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2409 - acc: 0.9780\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2223 - acc: 0.9825\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2102 - acc: 0.9862\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1962 - acc: 0.9892\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1830 - acc: 0.9900\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1707 - acc: 0.9907\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1617 - acc: 0.9925\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1520 - acc: 0.9932\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1400 - acc: 0.9947\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1314 - acc: 0.9968\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1221 - acc: 0.9983\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1158 - acc: 0.9968\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1073 - acc: 0.9977\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1003 - acc: 0.9977\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0938 - acc: 0.9970\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0890 - acc: 0.9970\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0824 - acc: 0.9977\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0772 - acc: 0.9992\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0722 - acc: 1.0000\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0664 - acc: 0.9992\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0630 - acc: 1.0000\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0585 - acc: 1.0000\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0553 - acc: 1.0000\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0510 - acc: 1.0000\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0492 - acc: 1.0000\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0447 - acc: 1.0000\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0421 - acc: 1.0000\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0396 - acc: 1.0000\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0373 - acc: 1.0000\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0340 - acc: 1.0000\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0324 - acc: 1.0000\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0299 - acc: 1.0000\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0279 - acc: 1.0000\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0257 - acc: 1.0000\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0240 - acc: 1.0000\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0212 - acc: 1.0000\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0133 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0FB9BDE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7597 - acc: 0.7063\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6894 - acc: 0.5312\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6491 - acc: 0.8012\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6131 - acc: 0.8553\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5814 - acc: 0.8927\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5489 - acc: 0.9120\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5202 - acc: 0.9318\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4915 - acc: 0.9415\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4659 - acc: 0.9408\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4399 - acc: 0.9502\n",
      "Epoch 10/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4159 - acc: 0.9508\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3951 - acc: 0.9522\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3734 - acc: 0.9562\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3550 - acc: 0.9600\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3335 - acc: 0.9628\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3161 - acc: 0.9713\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2996 - acc: 0.9745\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2828 - acc: 0.9703\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2679 - acc: 0.9783\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2536 - acc: 0.9807\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2389 - acc: 0.9852\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2273 - acc: 0.9843\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2142 - acc: 0.9855\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2019 - acc: 0.9875\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1913 - acc: 0.9853\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1801 - acc: 0.9890\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1729 - acc: 0.9900\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1596 - acc: 0.9900\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1539 - acc: 0.9922\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1459 - acc: 0.9922\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1377 - acc: 0.9923\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1314 - acc: 0.9930\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1228 - acc: 0.9923\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1153 - acc: 0.9922\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1098 - acc: 0.9923\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1025 - acc: 0.9932\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0977 - acc: 0.9915\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0937 - acc: 0.9922\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0880 - acc: 0.9938\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0840 - acc: 0.9938\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0791 - acc: 0.9932\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0742 - acc: 0.9945\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0713 - acc: 0.9945\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0670 - acc: 0.9938\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0660 - acc: 0.9923\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0601 - acc: 0.9945\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0564 - acc: 0.9945\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0538 - acc: 0.9953\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0518 - acc: 0.9947\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0492 - acc: 0.9962\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0456 - acc: 0.9968\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0465 - acc: 0.9962\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0438 - acc: 0.9962\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0416 - acc: 0.9962\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0378 - acc: 0.9960\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0378 - acc: 0.9962\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0358 - acc: 0.9947\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0315 - acc: 0.9968\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0310 - acc: 0.9975\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0307 - acc: 0.9962\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0282 - acc: 0.9968\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D8F3AA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6906 - acc: 0.6963\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 0.6932 - acc: 0.4875\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6888 - acc: 0.7232\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6831 - acc: 0.7838\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6753 - acc: 0.8417\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6661 - acc: 0.9075\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6555 - acc: 0.9252\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6436 - acc: 0.9440\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6306 - acc: 0.9547\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6160 - acc: 0.9588\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6011 - acc: 0.9618\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5834 - acc: 0.9697\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5664 - acc: 0.9757\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5483 - acc: 0.9745\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5282 - acc: 0.9783\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 0.5081 - acc: 0.9778\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4870 - acc: 0.9798\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4672 - acc: 0.9823\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4441 - acc: 0.9883\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4227 - acc: 0.9847\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4010 - acc: 0.9872\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3789 - acc: 0.9893\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3568 - acc: 0.9893\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3375 - acc: 0.9900\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3141 - acc: 0.9943\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2963 - acc: 0.9930\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2751 - acc: 0.9947\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2571 - acc: 0.9945\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2400 - acc: 0.9955\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2241 - acc: 0.9962\n",
      "Epoch 30/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2074 - acc: 0.9962\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1889 - acc: 0.9975\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1744 - acc: 0.9968\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1632 - acc: 0.9962\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1504 - acc: 0.9983\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1364 - acc: 0.9962\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1257 - acc: 0.9977\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1163 - acc: 0.9970\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1085 - acc: 0.998 - 0s 10ms/step - loss: 0.1064 - acc: 0.9977\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0965 - acc: 0.9977\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0878 - acc: 0.9992\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0800 - acc: 1.0000\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0738 - acc: 1.0000\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0677 - acc: 1.0000\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0626 - acc: 1.0000\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0553 - acc: 1.0000\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0514 - acc: 1.0000\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0465 - acc: 1.0000\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0419 - acc: 1.0000\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0383 - acc: 1.0000\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0350 - acc: 1.0000\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0314 - acc: 1.0000\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0280 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0212 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0127 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F22D50D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7641 - acc: 0.7163\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6923 - acc: 0.5402\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6814 - acc: 0.8230\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6678 - acc: 0.9072\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6540 - acc: 0.9245\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6360 - acc: 0.9413\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6177 - acc: 0.9423\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5965 - acc: 0.9552\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5757 - acc: 0.9662\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5548 - acc: 0.9728\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5335 - acc: 0.9698\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5110 - acc: 0.9738\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4892 - acc: 0.9740\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4650 - acc: 0.9763\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4431 - acc: 0.9815\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4190 - acc: 0.9810\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3986 - acc: 0.9852\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3783 - acc: 0.9847\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3579 - acc: 0.9848\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3342 - acc: 0.9867\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3160 - acc: 0.9868\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2949 - acc: 0.9863\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2773 - acc: 0.9900\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2586 - acc: 0.9900\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2427 - acc: 0.9908\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2260 - acc: 0.9908\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2110 - acc: 0.9902\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1950 - acc: 0.9915\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1818 - acc: 0.9930\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1675 - acc: 0.9923\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1561 - acc: 0.9930\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1447 - acc: 0.9952\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1337 - acc: 0.9938\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1231 - acc: 0.9947\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1144 - acc: 0.9945\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1040 - acc: 0.9953\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1000 - acc: 0.9932\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0910 - acc: 0.9947\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0831 - acc: 0.9953\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0757 - acc: 0.9960\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0722 - acc: 0.9945\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0665 - acc: 0.9947\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0620 - acc: 0.9947\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0555 - acc: 0.9967\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0537 - acc: 0.9938\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0504 - acc: 0.9932\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0463 - acc: 0.9947\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0434 - acc: 0.9945\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0390 - acc: 0.9962\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0374 - acc: 0.9955\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0351 - acc: 0.9962\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0306 - acc: 0.9968\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0303 - acc: 0.9968\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0278 - acc: 0.9968\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0274 - acc: 0.9955\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0251 - acc: 0.9962\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0239 - acc: 0.9955\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0211 - acc: 0.9953\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0212 - acc: 0.9955\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0194 - acc: 0.9962\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0224 - acc: 0.994 - 0s 9ms/step - loss: 0.0195 - acc: 0.9955\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EBE320D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7592 - acc: 0.6925\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6905 - acc: 0.5382\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6385 - acc: 0.8230\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5926 - acc: 0.8988\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5511 - acc: 0.9203\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5148 - acc: 0.9353\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4783 - acc: 0.9510\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.4438 - acc: 0.9630\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4136 - acc: 0.9637\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3862 - acc: 0.9730\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3597 - acc: 0.9733\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3346 - acc: 0.9778\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3105 - acc: 0.9772\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2918 - acc: 0.9847\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2701 - acc: 0.9897\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2496 - acc: 0.9885\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2322 - acc: 0.9892\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2150 - acc: 0.9920\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2009 - acc: 0.9945\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1882 - acc: 0.9962\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1726 - acc: 0.9977\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1617 - acc: 0.9977\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1491 - acc: 0.9977\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1368 - acc: 0.9977\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1285 - acc: 0.9970\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1198 - acc: 0.9977\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1115 - acc: 0.9970\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1038 - acc: 0.9970\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0958 - acc: 0.9977\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0888 - acc: 0.9992\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0833 - acc: 0.9992\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0769 - acc: 1.0000\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0710 - acc: 1.0000\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0653 - acc: 1.0000\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0626 - acc: 1.0000\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0582 - acc: 1.0000\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0535 - acc: 1.0000\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0497 - acc: 1.0000\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0460 - acc: 1.0000\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0436 - acc: 1.0000\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0399 - acc: 1.0000\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0380 - acc: 1.0000\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0358 - acc: 1.0000\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0327 - acc: 1.0000\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0270 - acc: 1.0000\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0252 - acc: 1.0000\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0236 - acc: 1.0000\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0212 - acc: 1.0000\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0198 - acc: 1.0000\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0132 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0124 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0119 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC2FD1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8592 - acc: 0.7088\n",
      "Epoch 1/60\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6874 - acc: 0.5602\n",
      "Epoch 2/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6500 - acc: 0.7195\n",
      "Epoch 3/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6111 - acc: 0.8713\n",
      "Epoch 4/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5677 - acc: 0.9113\n",
      "Epoch 5/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5254 - acc: 0.9392\n",
      "Epoch 6/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4862 - acc: 0.9458\n",
      "Epoch 7/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4490 - acc: 0.9480\n",
      "Epoch 8/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4116 - acc: 0.9537\n",
      "Epoch 9/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3797 - acc: 0.9562\n",
      "Epoch 10/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3486 - acc: 0.9640\n",
      "Epoch 11/60\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3231 - acc: 0.968 - 0s 10ms/step - loss: 0.3200 - acc: 0.9660\n",
      "Epoch 12/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2945 - acc: 0.9725\n",
      "Epoch 13/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2704 - acc: 0.9752\n",
      "Epoch 14/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2483 - acc: 0.9808\n",
      "Epoch 15/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2307 - acc: 0.9818\n",
      "Epoch 16/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2086 - acc: 0.9852\n",
      "Epoch 17/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1936 - acc: 0.9875\n",
      "Epoch 18/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1767 - acc: 0.9862\n",
      "Epoch 19/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1646 - acc: 0.9870\n",
      "Epoch 20/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1482 - acc: 0.9892\n",
      "Epoch 21/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1382 - acc: 0.9898\n",
      "Epoch 22/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1287 - acc: 0.9915\n",
      "Epoch 23/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1174 - acc: 0.9900\n",
      "Epoch 24/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1086 - acc: 0.9922\n",
      "Epoch 25/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0990 - acc: 0.9928\n",
      "Epoch 26/60\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.0938 - acc: 0.9910\n",
      "Epoch 27/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0857 - acc: 0.9923\n",
      "Epoch 28/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0797 - acc: 0.9922\n",
      "Epoch 29/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0740 - acc: 0.9930\n",
      "Epoch 30/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0689 - acc: 0.9938\n",
      "Epoch 31/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0649 - acc: 0.9930\n",
      "Epoch 32/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0591 - acc: 0.9968\n",
      "Epoch 33/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0551 - acc: 0.9968\n",
      "Epoch 34/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0523 - acc: 0.9968\n",
      "Epoch 35/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0509 - acc: 0.9955\n",
      "Epoch 36/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0465 - acc: 0.9962\n",
      "Epoch 37/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0432 - acc: 0.9953\n",
      "Epoch 38/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0420 - acc: 0.9955\n",
      "Epoch 39/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0391 - acc: 0.9955\n",
      "Epoch 40/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0346 - acc: 0.9975\n",
      "Epoch 41/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0353 - acc: 0.9955\n",
      "Epoch 42/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0316 - acc: 0.9962\n",
      "Epoch 43/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0297 - acc: 0.9968\n",
      "Epoch 44/60\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0289 - acc: 0.9962\n",
      "Epoch 45/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0271 - acc: 0.9968\n",
      "Epoch 46/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0258 - acc: 0.9962\n",
      "Epoch 47/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0243 - acc: 0.9962\n",
      "Epoch 48/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0233 - acc: 0.9953\n",
      "Epoch 49/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0230 - acc: 0.9955\n",
      "Epoch 50/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0198 - acc: 0.9968\n",
      "Epoch 51/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0186 - acc: 0.9960\n",
      "Epoch 52/60\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0181 - acc: 0.9968\n",
      "Epoch 53/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0187 - acc: 0.9955\n",
      "Epoch 54/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0172 - acc: 0.9947\n",
      "Epoch 55/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0167 - acc: 0.9955\n",
      "Epoch 56/60\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0143 - acc: 0.9960\n",
      "Epoch 57/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0154 - acc: 0.9962\n",
      "Epoch 58/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0145 - acc: 0.9970\n",
      "Epoch 59/60\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0133 - acc: 0.9962\n",
      "Epoch 60/60\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0122 - acc: 0.9977\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED7F9AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9084 - acc: 0.7050\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6931 - acc: 0.5192\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6752 - acc: 0.6907\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6606 - acc: 0.7615\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6469 - acc: 0.8145\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6321 - acc: 0.8590\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6187 - acc: 0.8815\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6067 - acc: 0.8988\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5938 - acc: 0.9047\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5823 - acc: 0.9045\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5692 - acc: 0.9187\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5570 - acc: 0.9287\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5465 - acc: 0.9310\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5332 - acc: 0.9407\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5209 - acc: 0.9437\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5108 - acc: 0.9440\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4997 - acc: 0.9473\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4896 - acc: 0.9538\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4778 - acc: 0.9535\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4668 - acc: 0.9600\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4578 - acc: 0.9610\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4462 - acc: 0.9638\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4371 - acc: 0.9660\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4260 - acc: 0.9683\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4199 - acc: 0.9670\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4085 - acc: 0.9683\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3997 - acc: 0.9685\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3902 - acc: 0.9725\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3793 - acc: 0.9752\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3718 - acc: 0.9738\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3640 - acc: 0.9760\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3576 - acc: 0.9750\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3454 - acc: 0.9777\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3376 - acc: 0.9798\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3263 - acc: 0.9827\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3240 - acc: 0.9808\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3131 - acc: 0.9808\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3071 - acc: 0.9853\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2970 - acc: 0.9858\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2922 - acc: 0.9847\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2864 - acc: 0.9842\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2772 - acc: 0.9875\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2691 - acc: 0.9890\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2643 - acc: 0.9878\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2544 - acc: 0.9918\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2508 - acc: 0.9915\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2457 - acc: 0.9908\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2382 - acc: 0.9915\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2316 - acc: 0.9937\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2262 - acc: 0.9952\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2223 - acc: 0.9953\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2144 - acc: 0.9952\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2086 - acc: 0.9960\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2036 - acc: 0.9953\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2013 - acc: 0.9940\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1939 - acc: 0.9947\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1882 - acc: 0.9960\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1843 - acc: 0.9947\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1799 - acc: 0.9940\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1736 - acc: 0.9953\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1695 - acc: 0.9953\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1639 - acc: 0.9940\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1611 - acc: 0.9953\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1564 - acc: 0.9947\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1521 - acc: 0.9947\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1470 - acc: 0.9947\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1436 - acc: 0.9953\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1405 - acc: 0.9960\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1371 - acc: 0.9953\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1318 - acc: 0.9953\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1295 - acc: 0.9947\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E897C1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5639 - acc: 0.7113\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6942 - acc: 0.4853\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6757 - acc: 0.7902\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6616 - acc: 0.8793\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6480 - acc: 0.8973\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6331 - acc: 0.9100\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6194 - acc: 0.9262\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6061 - acc: 0.9323\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5927 - acc: 0.9257\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5797 - acc: 0.9302\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5655 - acc: 0.9408\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5537 - acc: 0.9477\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5402 - acc: 0.9495\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5282 - acc: 0.9525\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5144 - acc: 0.9588\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5044 - acc: 0.9570\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4916 - acc: 0.9565\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4826 - acc: 0.9567\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4700 - acc: 0.9587\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4578 - acc: 0.9612\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4466 - acc: 0.9615\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4366 - acc: 0.9623\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4260 - acc: 0.9632\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4162 - acc: 0.9657\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4067 - acc: 0.9638\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3958 - acc: 0.9655\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3866 - acc: 0.9642\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3759 - acc: 0.9677\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3667 - acc: 0.9705\n",
      "Epoch 29/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3578 - acc: 0.9732\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3520 - acc: 0.9717\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3405 - acc: 0.9753\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3297 - acc: 0.9747\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3224 - acc: 0.9783\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3130 - acc: 0.9800\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3067 - acc: 0.9822\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2971 - acc: 0.9800\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2897 - acc: 0.9823\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2817 - acc: 0.9845\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2739 - acc: 0.9855\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2677 - acc: 0.9853\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2598 - acc: 0.9868\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2516 - acc: 0.9868\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2474 - acc: 0.9855\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2404 - acc: 0.9868\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2336 - acc: 0.9868\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2253 - acc: 0.9890\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2217 - acc: 0.9883\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2141 - acc: 0.9905\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2095 - acc: 0.9900\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2050 - acc: 0.9893\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1978 - acc: 0.9900\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1935 - acc: 0.9900\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1888 - acc: 0.9900\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1833 - acc: 0.9900\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1773 - acc: 0.9893\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1735 - acc: 0.9895\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1680 - acc: 0.9908\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1627 - acc: 0.9902\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1593 - acc: 0.9908\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1535 - acc: 0.9930\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1502 - acc: 0.9915\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1431 - acc: 0.9930\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1415 - acc: 0.9923\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1384 - acc: 0.9923\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1343 - acc: 0.9923\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1305 - acc: 0.9930\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1257 - acc: 0.9923\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1238 - acc: 0.9923\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1183 - acc: 0.9937\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1166 - acc: 0.9923\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDB9BAF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5632 - acc: 0.7038\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6905 - acc: 0.5570\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6524 - acc: 0.8282\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6261 - acc: 0.8848\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6040 - acc: 0.9100\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5845 - acc: 0.9278\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5672 - acc: 0.9322\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5507 - acc: 0.9442\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5345 - acc: 0.9547\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5207 - acc: 0.9505\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5058 - acc: 0.9523\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4950 - acc: 0.9533\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4819 - acc: 0.9537\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4681 - acc: 0.9575\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4560 - acc: 0.9593\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4451 - acc: 0.9598\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4300 - acc: 0.9667\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4225 - acc: 0.9680\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4110 - acc: 0.9700\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3982 - acc: 0.9710\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3911 - acc: 0.9703\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3799 - acc: 0.9713\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3671 - acc: 0.9740\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3588 - acc: 0.9747\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3488 - acc: 0.9770\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3414 - acc: 0.9755\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3344 - acc: 0.9750\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3236 - acc: 0.9790\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3144 - acc: 0.9790\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3071 - acc: 0.9785\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2987 - acc: 0.9792\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2913 - acc: 0.9800\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2823 - acc: 0.9802\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2764 - acc: 0.9822\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2706 - acc: 0.9795\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.2605 - acc: 0.9823\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2527 - acc: 0.9837\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2482 - acc: 0.9868\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2404 - acc: 0.9867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2364 - acc: 0.9862\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2272 - acc: 0.9883\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2213 - acc: 0.9897\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2151 - acc: 0.9912\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2105 - acc: 0.9892\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2070 - acc: 0.9878\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1974 - acc: 0.9898\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1937 - acc: 0.9908\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1882 - acc: 0.9922\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1822 - acc: 0.9945\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1776 - acc: 0.9923\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1728 - acc: 0.9945\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1718 - acc: 0.9932\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1644 - acc: 0.9952\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1628 - acc: 0.9940\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1539 - acc: 0.9938\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1528 - acc: 0.9953\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1465 - acc: 0.9962\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1457 - acc: 0.9955\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1401 - acc: 0.9968\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1362 - acc: 0.9970\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1327 - acc: 0.9970\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1275 - acc: 0.9962\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1244 - acc: 0.9977\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1211 - acc: 0.9970\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1179 - acc: 0.9983\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1147 - acc: 0.9970\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1116 - acc: 0.9977\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1080 - acc: 0.9970\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1047 - acc: 0.9977\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1033 - acc: 0.9970\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1000 - acc: 0.9983\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0E9D6F700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5608 - acc: 0.7175\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6896 - acc: 0.5333\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6554 - acc: 0.8013\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6328 - acc: 0.8690\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6132 - acc: 0.9047\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5951 - acc: 0.9157\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5771 - acc: 0.9217\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5626 - acc: 0.9287\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5482 - acc: 0.9340\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5338 - acc: 0.9413\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5189 - acc: 0.9437\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5058 - acc: 0.9422\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4929 - acc: 0.9468\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4795 - acc: 0.9497\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4666 - acc: 0.9535\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4564 - acc: 0.9535\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4472 - acc: 0.9498\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4322 - acc: 0.9532\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4232 - acc: 0.9548\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4112 - acc: 0.9605\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4019 - acc: 0.9587\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3913 - acc: 0.9563\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3812 - acc: 0.9607\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3727 - acc: 0.9608\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3613 - acc: 0.9635\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3510 - acc: 0.9623\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3433 - acc: 0.9645\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3346 - acc: 0.9660\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3265 - acc: 0.9700\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3169 - acc: 0.9713\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3083 - acc: 0.9713\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3011 - acc: 0.9750\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2955 - acc: 0.9745\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2871 - acc: 0.9732\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2785 - acc: 0.9742\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2720 - acc: 0.9768\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2665 - acc: 0.9822\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2573 - acc: 0.9813\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2516 - acc: 0.9830\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2430 - acc: 0.9817\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2376 - acc: 0.9830\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2342 - acc: 0.9825\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2239 - acc: 0.9825\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2195 - acc: 0.9838\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2131 - acc: 0.9882\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2089 - acc: 0.9875\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.2016 - acc: 0.9875\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1991 - acc: 0.9870\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1934 - acc: 0.9870\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1875 - acc: 0.9877\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1806 - acc: 0.9905\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1773 - acc: 0.9892\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1746 - acc: 0.9892\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1667 - acc: 0.9907\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1646 - acc: 0.9893\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1607 - acc: 0.9900\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1566 - acc: 0.9922\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1501 - acc: 0.9922\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1477 - acc: 0.9902\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1465 - acc: 0.9902\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1400 - acc: 0.9908\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1356 - acc: 0.9915\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1325 - acc: 0.9917\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1277 - acc: 0.9937\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1254 - acc: 0.9930\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1198 - acc: 0.9930\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1183 - acc: 0.9917\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1150 - acc: 0.9923\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1130 - acc: 0.9917\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1105 - acc: 0.9932\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1081 - acc: 0.9923\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC0731F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5622 - acc: 0.6963\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6934 - acc: 0.5068\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6790 - acc: 0.7757\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6663 - acc: 0.8690\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6546 - acc: 0.9105\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6432 - acc: 0.9225\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6307 - acc: 0.9280\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6191 - acc: 0.9347\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6074 - acc: 0.9423\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5943 - acc: 0.9457\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5828 - acc: 0.9538\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5731 - acc: 0.9540\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5617 - acc: 0.9563\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5520 - acc: 0.9560\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5405 - acc: 0.9595\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5298 - acc: 0.9638\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5192 - acc: 0.9582\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5079 - acc: 0.9663\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4970 - acc: 0.9705\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4887 - acc: 0.9702\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4774 - acc: 0.9702\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4664 - acc: 0.9723\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4570 - acc: 0.9752\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4454 - acc: 0.9788\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4358 - acc: 0.9777\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4291 - acc: 0.9777\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4191 - acc: 0.9792\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4075 - acc: 0.9798\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4022 - acc: 0.9772\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3921 - acc: 0.9772\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3808 - acc: 0.9813\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3725 - acc: 0.9800\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3646 - acc: 0.9793\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3583 - acc: 0.9787\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3474 - acc: 0.9813\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3408 - acc: 0.9815\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3332 - acc: 0.9817\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3242 - acc: 0.9817\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3159 - acc: 0.9837\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3054 - acc: 0.9843\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2998 - acc: 0.9830\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2927 - acc: 0.9838\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2893 - acc: 0.9853\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2802 - acc: 0.9860\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2735 - acc: 0.9847\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2665 - acc: 0.9855\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2604 - acc: 0.9842\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2536 - acc: 0.9848\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2476 - acc: 0.9875\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2416 - acc: 0.9890\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2345 - acc: 0.9857\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2295 - acc: 0.9870\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2207 - acc: 0.9892\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2158 - acc: 0.9885\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2119 - acc: 0.9885\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2059 - acc: 0.9885\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2035 - acc: 0.9887\n",
      "Epoch 57/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1952 - acc: 0.9900\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1903 - acc: 0.9900\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1848 - acc: 0.9907\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1831 - acc: 0.9900\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1760 - acc: 0.9893\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1732 - acc: 0.9900\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1657 - acc: 0.9900\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1613 - acc: 0.9937\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1605 - acc: 0.9908\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1543 - acc: 0.9937\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1500 - acc: 0.9923\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1460 - acc: 0.9932\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1412 - acc: 0.9925\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1374 - acc: 0.9952\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC4B8C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5498 - acc: 0.7275\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6947 - acc: 0.4870\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6752 - acc: 0.8433\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6607 - acc: 0.9058\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6460 - acc: 0.9393\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6311 - acc: 0.9530\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6159 - acc: 0.9515\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6018 - acc: 0.9553\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5886 - acc: 0.9597\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5737 - acc: 0.9555\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5605 - acc: 0.9597\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5457 - acc: 0.9622\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5347 - acc: 0.9662\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5217 - acc: 0.9662\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5088 - acc: 0.9662\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4978 - acc: 0.9712\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4851 - acc: 0.9672\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4730 - acc: 0.9668\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4635 - acc: 0.9683\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4523 - acc: 0.9677\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4403 - acc: 0.9690\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4302 - acc: 0.9737\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4165 - acc: 0.9743\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4090 - acc: 0.9700\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3982 - acc: 0.9722\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3886 - acc: 0.9730\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3784 - acc: 0.9763\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3705 - acc: 0.9775\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3621 - acc: 0.9762\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3505 - acc: 0.9807\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3422 - acc: 0.9807\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3342 - acc: 0.9822\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3265 - acc: 0.9837\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3182 - acc: 0.9832\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3067 - acc: 0.9863\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2994 - acc: 0.9823\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2954 - acc: 0.9860\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2850 - acc: 0.9875\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2784 - acc: 0.9862\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2728 - acc: 0.9862\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2617 - acc: 0.9882\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2579 - acc: 0.9870\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2500 - acc: 0.9870\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2443 - acc: 0.9877\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2384 - acc: 0.9883\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2299 - acc: 0.9878\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2277 - acc: 0.9878\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2204 - acc: 0.9872\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2129 - acc: 0.9892\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2093 - acc: 0.9872\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2027 - acc: 0.9892\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1994 - acc: 0.9865\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1919 - acc: 0.9898\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1879 - acc: 0.9885\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1823 - acc: 0.9878\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1770 - acc: 0.9872\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1736 - acc: 0.9892\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1684 - acc: 0.9892\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1637 - acc: 0.9885\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1584 - acc: 0.9878\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1537 - acc: 0.9892\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1508 - acc: 0.9900\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1457 - acc: 0.9887\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1404 - acc: 0.9907\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1376 - acc: 0.9885\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1329 - acc: 0.9887\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1309 - acc: 0.9887\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1259 - acc: 0.9893\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1227 - acc: 0.9913\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1212 - acc: 0.9902\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.1179 - acc: 0.990 - 0s 10ms/step - loss: 0.1173 - acc: 0.9908\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0FB9BDA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5656 - acc: 0.7063\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6929 - acc: 0.5310\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6599 - acc: 0.8395\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6380 - acc: 0.9073\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6188 - acc: 0.9178\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6020 - acc: 0.9318\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5862 - acc: 0.9395\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5713 - acc: 0.9398\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5570 - acc: 0.9477\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5444 - acc: 0.9538\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5298 - acc: 0.9587\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5196 - acc: 0.9585\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5071 - acc: 0.9583\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4940 - acc: 0.9612\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4842 - acc: 0.9567\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4722 - acc: 0.9597\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4636 - acc: 0.9603\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4500 - acc: 0.9667\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4386 - acc: 0.9660\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4289 - acc: 0.9668\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4197 - acc: 0.9642\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4090 - acc: 0.9690\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4000 - acc: 0.9678\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3906 - acc: 0.9677\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3807 - acc: 0.9727\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3727 - acc: 0.9707\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3624 - acc: 0.9728\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3561 - acc: 0.9745\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3475 - acc: 0.9762\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3361 - acc: 0.9783\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3310 - acc: 0.9800\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3209 - acc: 0.9858\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3114 - acc: 0.9815\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3055 - acc: 0.9853\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3023 - acc: 0.9840\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2894 - acc: 0.9873\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2847 - acc: 0.9858\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2780 - acc: 0.9860\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2711 - acc: 0.9862\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2662 - acc: 0.9855\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2600 - acc: 0.9855\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2544 - acc: 0.9862\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2455 - acc: 0.9862\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2395 - acc: 0.9848\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2314 - acc: 0.9883\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2272 - acc: 0.9905\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2227 - acc: 0.9908\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2178 - acc: 0.9898\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2092 - acc: 0.9908\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2043 - acc: 0.9930\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1998 - acc: 0.9938\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1953 - acc: 0.9938\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1921 - acc: 0.9940\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1843 - acc: 0.9953\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1799 - acc: 0.9947\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1762 - acc: 0.9945\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1706 - acc: 0.9953\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1672 - acc: 0.9960\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1616 - acc: 0.9968\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1591 - acc: 0.9955\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1561 - acc: 0.9962\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1505 - acc: 0.9968\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1466 - acc: 0.9970\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1436 - acc: 0.9977\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1379 - acc: 0.9977\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1352 - acc: 0.9970\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1318 - acc: 0.9977\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1294 - acc: 0.9970\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1259 - acc: 0.9970\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1210 - acc: 0.9977\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1185 - acc: 0.9977\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D307E670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5582 - acc: 0.7163\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6936 - acc: 0.5012\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6575 - acc: 0.8010\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6326 - acc: 0.8778\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6119 - acc: 0.9038\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5922 - acc: 0.9145\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5759 - acc: 0.9132\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5602 - acc: 0.9235\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5436 - acc: 0.9283\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5294 - acc: 0.9383\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5137 - acc: 0.9455\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5030 - acc: 0.9422\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4879 - acc: 0.9477\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4755 - acc: 0.9463\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4629 - acc: 0.9447\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4509 - acc: 0.9477\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4375 - acc: 0.9518\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4283 - acc: 0.9492\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4150 - acc: 0.9490\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4059 - acc: 0.9458\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3974 - acc: 0.9482\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3840 - acc: 0.9525\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3750 - acc: 0.9515\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3664 - acc: 0.9513\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3551 - acc: 0.9545\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3456 - acc: 0.9575\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3355 - acc: 0.9625\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3277 - acc: 0.9653\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3200 - acc: 0.9653\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3126 - acc: 0.9662\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3043 - acc: 0.9685\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2951 - acc: 0.9713\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2897 - acc: 0.9692\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2783 - acc: 0.9750\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2718 - acc: 0.9753\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2628 - acc: 0.9775\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2574 - acc: 0.9768\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2517 - acc: 0.9778\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2468 - acc: 0.9772\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2385 - acc: 0.9817\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2326 - acc: 0.9830\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2287 - acc: 0.9817\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2216 - acc: 0.9838\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2125 - acc: 0.9858\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2088 - acc: 0.9853\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2061 - acc: 0.9840\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1972 - acc: 0.9853\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1914 - acc: 0.9868\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1899 - acc: 0.9862\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1836 - acc: 0.9905\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1775 - acc: 0.9885\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1734 - acc: 0.9892\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1670 - acc: 0.9892\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1647 - acc: 0.9902\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1590 - acc: 0.9908\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1530 - acc: 0.9913\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1520 - acc: 0.9902\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1440 - acc: 0.9922\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1449 - acc: 0.9902\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1366 - acc: 0.9922\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1367 - acc: 0.9902\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1326 - acc: 0.9922\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1295 - acc: 0.9917\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1282 - acc: 0.9910\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1213 - acc: 0.9930\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1203 - acc: 0.9923\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1145 - acc: 0.9938\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1118 - acc: 0.9930\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1095 - acc: 0.9938\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1054 - acc: 0.9945\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1043 - acc: 0.9945\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0D8F3AA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5682 - acc: 0.7000\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6941 - acc: 0.4933\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6784 - acc: 0.5010\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6637 - acc: 0.5185\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6495 - acc: 0.5888\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6352 - acc: 0.6570\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6189 - acc: 0.7063\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6051 - acc: 0.7688\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5889 - acc: 0.7982\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5712 - acc: 0.8392\n",
      "Epoch 10/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5558 - acc: 0.8555\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5419 - acc: 0.8725\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5277 - acc: 0.8740\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5097 - acc: 0.8932\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5003 - acc: 0.9093\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4848 - acc: 0.9082\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4681 - acc: 0.9275\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4564 - acc: 0.9347\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4406 - acc: 0.9470\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4291 - acc: 0.9485\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4192 - acc: 0.9570\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4053 - acc: 0.9533\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3922 - acc: 0.9575\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3839 - acc: 0.9667\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3679 - acc: 0.9673\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3564 - acc: 0.9725\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3455 - acc: 0.9758\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3361 - acc: 0.9792\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3208 - acc: 0.9828\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3139 - acc: 0.9840\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3023 - acc: 0.9853\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2925 - acc: 0.9885\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2854 - acc: 0.9877\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2725 - acc: 0.9915\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2577 - acc: 0.9945\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2510 - acc: 0.9953\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2409 - acc: 0.9968\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2299 - acc: 0.9955\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2198 - acc: 0.9962\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2112 - acc: 0.9962\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2013 - acc: 0.9962\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1916 - acc: 0.9968\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1832 - acc: 0.9968\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1760 - acc: 0.9975\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1693 - acc: 0.9970\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1577 - acc: 0.9977\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1519 - acc: 0.9970\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1454 - acc: 0.9970\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1380 - acc: 0.9977\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1309 - acc: 0.9985\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1232 - acc: 0.9992\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1197 - acc: 0.9992\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1116 - acc: 0.9985\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1068 - acc: 1.0000\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1002 - acc: 0.9985\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0950 - acc: 1.0000\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0885 - acc: 1.0000\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0833 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0802 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0744 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0706 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 18ms/step - loss: 0.0676 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0623 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0582 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0557 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0517 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0495 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0469 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0430 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0420 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0379 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EC2FD8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7495 - acc: 0.6850\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6928 - acc: 0.5262\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6800 - acc: 0.6987\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6683 - acc: 0.8093\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6538 - acc: 0.8382\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6391 - acc: 0.8715\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6219 - acc: 0.8898\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6056 - acc: 0.9200\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5873 - acc: 0.9385\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5689 - acc: 0.9435\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5511 - acc: 0.9508\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5318 - acc: 0.9583\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5127 - acc: 0.9625\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4951 - acc: 0.9657\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4733 - acc: 0.9708\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4537 - acc: 0.9775\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4361 - acc: 0.9778\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4186 - acc: 0.9792\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3996 - acc: 0.9823\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3809 - acc: 0.9847\n",
      "Epoch 20/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3636 - acc: 0.9868\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3463 - acc: 0.9877\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3290 - acc: 0.9890\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3149 - acc: 0.9885\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2990 - acc: 0.9878\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2822 - acc: 0.9902\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2690 - acc: 0.9915\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2547 - acc: 0.9908\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2409 - acc: 0.9915\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2296 - acc: 0.9908\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2170 - acc: 0.9908\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2046 - acc: 0.9915\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1936 - acc: 0.9908\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1831 - acc: 0.9922\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1715 - acc: 0.9915\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1642 - acc: 0.9915\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1573 - acc: 0.9895\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1461 - acc: 0.9915\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1383 - acc: 0.9902\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1292 - acc: 0.9923\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1233 - acc: 0.9908\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1158 - acc: 0.9917\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1095 - acc: 0.9917\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1030 - acc: 0.9923\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0957 - acc: 0.9932\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0907 - acc: 0.9945\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0870 - acc: 0.9923\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0795 - acc: 0.9938\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0782 - acc: 0.9932\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0710 - acc: 0.9938\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0681 - acc: 0.9953\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0657 - acc: 0.9940\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 19ms/step - loss: 0.0604 - acc: 0.9953\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0558 - acc: 0.9952\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0536 - acc: 0.9938\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0512 - acc: 0.9947\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0500 - acc: 0.9940\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0466 - acc: 0.9947\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0427 - acc: 0.9953\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0411 - acc: 0.9953\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0386 - acc: 0.9947\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0383 - acc: 0.9932\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0356 - acc: 0.9938\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0352 - acc: 0.9940\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0318 - acc: 0.9938\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0288 - acc: 0.9960\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0278 - acc: 0.9945\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0267 - acc: 0.9953\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0269 - acc: 0.9940\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0262 - acc: 0.9940\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0226 - acc: 0.9953\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDEF1A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7096 - acc: 0.7050\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6942 - acc: 0.5003\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6497 - acc: 0.8002\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6160 - acc: 0.8898\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5827 - acc: 0.9127\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5524 - acc: 0.9295\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5236 - acc: 0.9368\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4966 - acc: 0.9433\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4718 - acc: 0.9460\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4463 - acc: 0.9503\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4227 - acc: 0.9605\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4035 - acc: 0.9625\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3826 - acc: 0.9698\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3590 - acc: 0.9742\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3441 - acc: 0.9747\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3257 - acc: 0.9752\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3088 - acc: 0.9760\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2947 - acc: 0.9783\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2791 - acc: 0.9763\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2636 - acc: 0.9778\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2531 - acc: 0.9788\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2364 - acc: 0.9815\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2261 - acc: 0.9838\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2108 - acc: 0.9853\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2033 - acc: 0.9915\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1884 - acc: 0.9915\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1792 - acc: 0.9915\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1704 - acc: 0.9922\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1633 - acc: 0.9910\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1533 - acc: 0.9923\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1445 - acc: 0.9970\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1354 - acc: 0.9975\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1281 - acc: 0.9983\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1227 - acc: 0.9970\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1154 - acc: 0.9977\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1091 - acc: 0.9977\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1015 - acc: 0.9977\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0975 - acc: 0.9985\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0926 - acc: 0.9992\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0876 - acc: 0.9985\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0819 - acc: 0.9985\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0760 - acc: 0.9985\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0711 - acc: 0.9992\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0665 - acc: 0.9992\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0636 - acc: 1.0000\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0603 - acc: 1.0000\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0571 - acc: 1.0000\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0535 - acc: 1.0000\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0507 - acc: 1.0000\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0483 - acc: 1.0000\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0451 - acc: 1.0000\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0432 - acc: 1.0000\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0405 - acc: 1.0000\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0379 - acc: 1.0000\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0360 - acc: 1.0000\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0337 - acc: 1.0000\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0297 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0285 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0268 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0232 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0223 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0189 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0173 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0168 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0158 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0141 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED925040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7673 - acc: 0.7088\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 10ms/step - loss: 0.6923 - acc: 0.5285\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6437 - acc: 0.8255\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6061 - acc: 0.8843\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5731 - acc: 0.9172\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5417 - acc: 0.9317\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5123 - acc: 0.9420\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4868 - acc: 0.9477\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4611 - acc: 0.9522\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4368 - acc: 0.9492\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4149 - acc: 0.9542\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3927 - acc: 0.9570\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3737 - acc: 0.9615\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3540 - acc: 0.9608\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3381 - acc: 0.9608\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3183 - acc: 0.9693\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3036 - acc: 0.9710\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2856 - acc: 0.9762\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2728 - acc: 0.9785\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2579 - acc: 0.9808\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2444 - acc: 0.9823\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2336 - acc: 0.9853\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2189 - acc: 0.9855\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2093 - acc: 0.9877\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1992 - acc: 0.9913\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1886 - acc: 0.9893\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1796 - acc: 0.9915\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1683 - acc: 0.9900\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1592 - acc: 0.9885\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1535 - acc: 0.9900\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1424 - acc: 0.9907\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1348 - acc: 0.9923\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1307 - acc: 0.9917\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1209 - acc: 0.9937\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1176 - acc: 0.9923\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1112 - acc: 0.9938\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1045 - acc: 0.9930\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0996 - acc: 0.9932\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0939 - acc: 0.9915\n",
      "Epoch 39/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0890 - acc: 0.9945\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0844 - acc: 0.9937\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0813 - acc: 0.9930\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0749 - acc: 0.9945\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0725 - acc: 0.9945\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0686 - acc: 0.9938\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0664 - acc: 0.9955\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0639 - acc: 0.9962\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0594 - acc: 0.9962\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0568 - acc: 0.9947\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0543 - acc: 0.9962\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0512 - acc: 0.9962\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0485 - acc: 0.9962\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0464 - acc: 0.9968\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0443 - acc: 0.9947\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0413 - acc: 0.9968\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0411 - acc: 0.9947\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0374 - acc: 0.9968\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0387 - acc: 0.9955\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0359 - acc: 0.9962\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0331 - acc: 0.9975\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0323 - acc: 0.9962\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0312 - acc: 0.9953\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0316 - acc: 0.9955\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0282 - acc: 0.9962\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0251 - acc: 0.9975\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0272 - acc: 0.9955\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0250 - acc: 0.9962\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0220 - acc: 0.9960\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0220 - acc: 0.9968\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0226 - acc: 0.9947\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0209 - acc: 0.9953\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0EDB9B9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.7582 - acc: 0.7025\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6931 - acc: 0.5123\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6870 - acc: 0.7700\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6802 - acc: 0.8315\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6721 - acc: 0.8782\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6610 - acc: 0.8982\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6492 - acc: 0.9312\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6355 - acc: 0.9430\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6194 - acc: 0.9552\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6028 - acc: 0.9520\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5836 - acc: 0.9603\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5631 - acc: 0.9655\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5411 - acc: 0.9662\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5200 - acc: 0.9718\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4948 - acc: 0.9752\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4719 - acc: 0.9787\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4475 - acc: 0.9815\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4210 - acc: 0.9842\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3987 - acc: 0.9867\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3714 - acc: 0.9867\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3513 - acc: 0.9908\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3272 - acc: 0.9870\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3025 - acc: 0.9915\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2815 - acc: 0.9908\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2626 - acc: 0.9902\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2429 - acc: 0.9917\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2225 - acc: 0.9930\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2040 - acc: 0.9917\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.1886 - acc: 0.9923\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1714 - acc: 0.9932\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1589 - acc: 0.9947\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1447 - acc: 0.9968\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1331 - acc: 0.9955\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1220 - acc: 0.9955\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1107 - acc: 0.9962\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0996 - acc: 0.9970\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0912 - acc: 0.9977\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0847 - acc: 0.9970\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0764 - acc: 0.9970\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0706 - acc: 0.9970\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0629 - acc: 0.9983\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0577 - acc: 0.9970\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0546 - acc: 0.998 - 0s 11ms/step - loss: 0.0529 - acc: 0.9985\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0481 - acc: 0.9992\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0428 - acc: 0.9985\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0397 - acc: 1.0000\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0357 - acc: 1.0000\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0323 - acc: 1.0000\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0294 - acc: 1.0000\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0265 - acc: 1.0000\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0230 - acc: 1.0000\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0206 - acc: 1.000 - 0s 10ms/step - loss: 0.0199 - acc: 1.0000\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0181 - acc: 1.0000\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0118 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0033 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0F22D5E50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9481 - acc: 0.7038\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6928 - acc: 0.5185\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.6858 - acc: 0.5283\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6770 - acc: 0.5317\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6645 - acc: 0.5507\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6500 - acc: 0.5957\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6338 - acc: 0.6492\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6167 - acc: 0.6997\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5985 - acc: 0.7552\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5782 - acc: 0.8150\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5606 - acc: 0.8578\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5407 - acc: 0.8765\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5273 - acc: 0.9095\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5084 - acc: 0.9045\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4913 - acc: 0.9225\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.4756 - acc: 0.9288\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4549 - acc: 0.9373\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4402 - acc: 0.9460\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4264 - acc: 0.9533\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.4066 - acc: 0.9612\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3963 - acc: 0.9670\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3769 - acc: 0.9683\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3698 - acc: 0.9693\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.3522 - acc: 0.9717\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3400 - acc: 0.9765\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3284 - acc: 0.9758\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3170 - acc: 0.9867\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2990 - acc: 0.9845\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2865 - acc: 0.9912\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2754 - acc: 0.9892\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2652 - acc: 0.9908\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2519 - acc: 0.9908\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2441 - acc: 0.9938\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2259 - acc: 0.9945\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2174 - acc: 0.9945\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2075 - acc: 0.9945\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1938 - acc: 0.9932\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1836 - acc: 0.9938\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1727 - acc: 0.9947\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1630 - acc: 0.9953\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1515 - acc: 0.9952\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1405 - acc: 0.9953\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1329 - acc: 0.9953\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1241 - acc: 0.9947\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1153 - acc: 0.9947\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1054 - acc: 0.9947\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1000 - acc: 0.9932\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0926 - acc: 0.9955\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0864 - acc: 0.9968\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0784 - acc: 0.9975\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0727 - acc: 0.9968\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0689 - acc: 0.9947\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0629 - acc: 0.9947\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0589 - acc: 0.9968\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0542 - acc: 0.9962\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0501 - acc: 0.9962\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0450 - acc: 0.9968\n",
      "Epoch 57/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0434 - acc: 0.9962\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0393 - acc: 0.9962\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0363 - acc: 0.9968\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0343 - acc: 0.9953\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0325 - acc: 0.9955\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0295 - acc: 0.9962\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0292 - acc: 0.994 - 0s 12ms/step - loss: 0.0282 - acc: 0.9947\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0265 - acc: 0.9947\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0233 - acc: 0.9968\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0229 - acc: 0.9955\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0203 - acc: 0.9953\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0174 - acc: 0.9975\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0171 - acc: 0.9975\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0175 - acc: 0.9977\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0DA780CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8088 - acc: 0.7088\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 8ms/step - loss: 0.6918 - acc: 0.5268\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6539 - acc: 0.8380\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6159 - acc: 0.9038\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5770 - acc: 0.9210\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5364 - acc: 0.9267\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4987 - acc: 0.9483\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4601 - acc: 0.9578\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4267 - acc: 0.9633\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3954 - acc: 0.9678\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3639 - acc: 0.9703\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.3373 - acc: 0.9723\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3135 - acc: 0.9732\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2876 - acc: 0.9768\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2614 - acc: 0.9850\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2449 - acc: 0.9822\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2253 - acc: 0.9883\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2103 - acc: 0.9908\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1923 - acc: 0.9917\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1772 - acc: 0.9930\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1637 - acc: 0.9923\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1514 - acc: 0.9955\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1389 - acc: 0.9955\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1267 - acc: 0.9962\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1177 - acc: 0.9977\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1096 - acc: 0.9968\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1000 - acc: 0.9977\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0905 - acc: 0.9983\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0851 - acc: 1.0000\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0793 - acc: 1.0000\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0725 - acc: 1.0000\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0672 - acc: 1.0000\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0618 - acc: 1.0000\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0568 - acc: 1.0000\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0522 - acc: 1.0000\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0488 - acc: 1.0000\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0449 - acc: 1.0000\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0417 - acc: 1.0000\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0385 - acc: 1.0000\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0359 - acc: 1.0000\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0266 - acc: 1.0000\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0252 - acc: 1.000 - 0s 11ms/step - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0233 - acc: 1.0000\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0165 - acc: 1.0000\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0119 - acc: 1.0000\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0113 - acc: 1.0000\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 66/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0051 - acc: 1.0000\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED806280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.0037 - acc: 0.7138\n",
      "Epoch 1/70\n",
      "2/2 [==============================] - 1s 9ms/step - loss: 0.6922 - acc: 0.5218\n",
      "Epoch 2/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.6698 - acc: 0.6680\n",
      "Epoch 3/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6423 - acc: 0.7962\n",
      "Epoch 4/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.6107 - acc: 0.8823\n",
      "Epoch 5/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.5786 - acc: 0.9135\n",
      "Epoch 6/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.5453 - acc: 0.9333\n",
      "Epoch 7/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.5107 - acc: 0.9433\n",
      "Epoch 8/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4794 - acc: 0.9467\n",
      "Epoch 9/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4460 - acc: 0.9487\n",
      "Epoch 10/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4166 - acc: 0.9587\n",
      "Epoch 11/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3885 - acc: 0.9662\n",
      "Epoch 12/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3623 - acc: 0.9652\n",
      "Epoch 13/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3345 - acc: 0.9723\n",
      "Epoch 14/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3124 - acc: 0.9710\n",
      "Epoch 15/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2890 - acc: 0.9775\n",
      "Epoch 16/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2696 - acc: 0.9830\n",
      "Epoch 17/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2489 - acc: 0.9867\n",
      "Epoch 18/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2340 - acc: 0.9863\n",
      "Epoch 19/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2151 - acc: 0.9863\n",
      "Epoch 20/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1983 - acc: 0.9892\n",
      "Epoch 21/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1881 - acc: 0.9893\n",
      "Epoch 22/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1724 - acc: 0.9915\n",
      "Epoch 23/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1619 - acc: 0.9923\n",
      "Epoch 24/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1510 - acc: 0.9917\n",
      "Epoch 25/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1383 - acc: 0.9952\n",
      "Epoch 26/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1276 - acc: 0.9952\n",
      "Epoch 27/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1209 - acc: 0.9938\n",
      "Epoch 28/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1133 - acc: 0.9945\n",
      "Epoch 29/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1049 - acc: 0.9945\n",
      "Epoch 30/70\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.0986 - acc: 0.992 - 0s 10ms/step - loss: 0.0981 - acc: 0.9923\n",
      "Epoch 31/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0911 - acc: 0.9945\n",
      "Epoch 32/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0870 - acc: 0.9917\n",
      "Epoch 33/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0799 - acc: 0.9945\n",
      "Epoch 34/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0754 - acc: 0.9947\n",
      "Epoch 35/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0699 - acc: 0.9960\n",
      "Epoch 36/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0662 - acc: 0.9953\n",
      "Epoch 37/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0637 - acc: 0.9955\n",
      "Epoch 38/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0585 - acc: 0.9953\n",
      "Epoch 39/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0567 - acc: 0.9955\n",
      "Epoch 40/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0530 - acc: 0.9962\n",
      "Epoch 41/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0477 - acc: 0.9975\n",
      "Epoch 42/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0469 - acc: 0.9962\n",
      "Epoch 43/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0439 - acc: 0.9968\n",
      "Epoch 44/70\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0429 - acc: 0.9955\n",
      "Epoch 45/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0401 - acc: 0.9962\n",
      "Epoch 46/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0362 - acc: 0.9968\n",
      "Epoch 47/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0368 - acc: 0.9955\n",
      "Epoch 48/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0334 - acc: 0.9968\n",
      "Epoch 49/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0330 - acc: 0.9955\n",
      "Epoch 50/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0299 - acc: 0.9968\n",
      "Epoch 51/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0299 - acc: 0.9955\n",
      "Epoch 52/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0288 - acc: 0.9955\n",
      "Epoch 53/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0261 - acc: 0.9968\n",
      "Epoch 54/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0263 - acc: 0.9955\n",
      "Epoch 55/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0247 - acc: 0.9962\n",
      "Epoch 56/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0225 - acc: 0.9962\n",
      "Epoch 57/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0217 - acc: 0.9962\n",
      "Epoch 58/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0215 - acc: 0.9947\n",
      "Epoch 59/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0186 - acc: 0.9983\n",
      "Epoch 60/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0196 - acc: 0.9970\n",
      "Epoch 61/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0182 - acc: 0.9970\n",
      "Epoch 62/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0170 - acc: 0.9977\n",
      "Epoch 63/70\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.0158 - acc: 0.9977\n",
      "Epoch 64/70\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.0161 - acc: 0.9970\n",
      "Epoch 65/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0152 - acc: 0.9977\n",
      "Epoch 66/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0142 - acc: 0.9977\n",
      "Epoch 67/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0135 - acc: 0.9968\n",
      "Epoch 68/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0129 - acc: 0.9977\n",
      "Epoch 69/70\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0117 - acc: 0.9968\n",
      "Epoch 70/70\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0123 - acc: 0.9985\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED925DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 0.9724 - acc: 0.6925\n",
      "Epoch 1/70\n",
      "4/4 [==============================] - 1s 9ms/step - loss: 0.6931 - acc: 0.5004\n",
      "Epoch 2/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6769 - acc: 0.6722\n",
      "Epoch 3/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6628 - acc: 0.7483\n",
      "Epoch 4/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6487 - acc: 0.7937\n",
      "Epoch 5/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6365 - acc: 0.8082\n",
      "Epoch 6/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6235 - acc: 0.8439\n",
      "Epoch 7/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.6111 - acc: 0.8475\n",
      "Epoch 8/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5977 - acc: 0.8748\n",
      "Epoch 9/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5848 - acc: 0.8758\n",
      "Epoch 10/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5738 - acc: 0.8709\n",
      "Epoch 11/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5610 - acc: 0.8905\n",
      "Epoch 12/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5519 - acc: 0.8887\n",
      "Epoch 13/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5383 - acc: 0.8960\n",
      "Epoch 14/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5252 - acc: 0.9097\n",
      "Epoch 15/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.5163 - acc: 0.9114\n",
      "Epoch 16/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.5061 - acc: 0.9115\n",
      "Epoch 17/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4928 - acc: 0.9195\n",
      "Epoch 18/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4851 - acc: 0.9216\n",
      "Epoch 19/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4706 - acc: 0.9271\n",
      "Epoch 20/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4640 - acc: 0.9276\n",
      "Epoch 21/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.4490 - acc: 0.9342\n",
      "Epoch 22/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4387 - acc: 0.9359\n",
      "Epoch 23/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4339 - acc: 0.9323\n",
      "Epoch 24/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4205 - acc: 0.9389\n",
      "Epoch 25/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.4101 - acc: 0.9387\n",
      "Epoch 26/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3996 - acc: 0.9452\n",
      "Epoch 27/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3880 - acc: 0.9457\n",
      "Epoch 28/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3862 - acc: 0.9482\n",
      "Epoch 29/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3740 - acc: 0.9479\n",
      "Epoch 30/70\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.3613 - acc: 0.9505\n",
      "Epoch 31/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3542 - acc: 0.9528\n",
      "Epoch 32/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3506 - acc: 0.9493\n",
      "Epoch 33/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3355 - acc: 0.9554\n",
      "Epoch 34/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3310 - acc: 0.9530\n",
      "Epoch 35/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3226 - acc: 0.9532\n",
      "Epoch 36/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3154 - acc: 0.9564\n",
      "Epoch 37/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.3054 - acc: 0.9569\n",
      "Epoch 38/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2970 - acc: 0.9595\n",
      "Epoch 39/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2903 - acc: 0.9604\n",
      "Epoch 40/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2823 - acc: 0.9546\n",
      "Epoch 41/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2735 - acc: 0.9609\n",
      "Epoch 42/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2680 - acc: 0.9596\n",
      "Epoch 43/70\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2600 - acc: 0.9626\n",
      "Epoch 44/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2507 - acc: 0.9651\n",
      "Epoch 45/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2514 - acc: 0.9650\n",
      "Epoch 46/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2413 - acc: 0.9656\n",
      "Epoch 47/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2342 - acc: 0.9683\n",
      "Epoch 48/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2285 - acc: 0.9695\n",
      "Epoch 49/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2238 - acc: 0.9709\n",
      "Epoch 50/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2196 - acc: 0.9679\n",
      "Epoch 51/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2125 - acc: 0.9741\n",
      "Epoch 52/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.2039 - acc: 0.9756\n",
      "Epoch 53/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.2044 - acc: 0.9706\n",
      "Epoch 54/70\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.1929 - acc: 0.9742\n",
      "Epoch 55/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1926 - acc: 0.9748\n",
      "Epoch 56/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1834 - acc: 0.9767\n",
      "Epoch 57/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1809 - acc: 0.9767\n",
      "Epoch 58/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1785 - acc: 0.9767\n",
      "Epoch 59/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1729 - acc: 0.9780\n",
      "Epoch 60/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1688 - acc: 0.9792\n",
      "Epoch 61/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1655 - acc: 0.9818\n",
      "Epoch 62/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1606 - acc: 0.9804\n",
      "Epoch 63/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1530 - acc: 0.9822\n",
      "Epoch 64/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1508 - acc: 0.9826\n",
      "Epoch 65/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1456 - acc: 0.9858\n",
      "Epoch 66/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1430 - acc: 0.9818\n",
      "Epoch 67/70\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1401 - acc: 0.9833\n",
      "Epoch 68/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1363 - acc: 0.9851\n",
      "Epoch 69/70\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1307 - acc: 0.9858\n",
      "Epoch 70/70\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.1303 - acc: 0.9856\n"
     ]
    }
   ],
   "source": [
    "model_ann = KerasClassifier(build_fn=create_model, epochs=20, batch_size=500)\n",
    "\n",
    "layer=[0,1,2,3]\n",
    "param_grid = dict(layer=layer)\n",
    "activation = [ 'relu', 'tanh']\n",
    "param_grid['layer_activation'] = activation\n",
    "\n",
    "optimizer = ['RMSprop']\n",
    "param_grid['optimizer'] = optimizer  \n",
    "dense=[10,15,16,18,20]\n",
    "param_grid['dense']=dense\n",
    "param_grid['epochs'] =[60,70]\n",
    "\n",
    "\n",
    "yy=to_categorical(y_train2,2)\n",
    "grid = GridSearchCV(estimator=model_ann, param_grid=param_grid,cv=2)\n",
    "grid_result = grid.fit(X_train2,yy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7325"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = grid.predict(X_test2)\n",
    "accuracy_score(x,y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deep NN were trained by gridsearch model. Here we create a model generate function and then put into gridsearch function to find the parameters with highest validation accuracy. Here we can see that the accuracy is around 72%, which is acceptable for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.765"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_log = [{'max_iter': [10000],\n",
    "             'penalty' : ['none', 'l2'],\n",
    "             'tol':[0.0001,0.0002]\n",
    "            }]\n",
    "\n",
    "\n",
    "grid_log = GridSearchCV(LogisticRegression( random_state=0), para_log,cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0))\n",
    "\n",
    "\n",
    "grid_log.fit(X_train2, y_train2)\n",
    "best_Log_l2_model = grid_log.best_estimator_\n",
    "best_Log_l2_model.score(X_test2,y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the logistic regression was used for the prediction. Both panelty with l1 and l2 were used and we found that l2 would generate better predict result. Thus, we only us l2 in the gridsearch function. The result suggested that the accuracy is around 0.765 in validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7475\n"
     ]
    }
   ],
   "source": [
    "para_svc = [{'C':[0.5, 1, 2],\n",
    "             'kernel':('linear', 'rbf', 'sigmoid')\n",
    "            }]\n",
    "grid_svm = GridSearchCV( svm.SVC(probability=True, class_weight=\"balanced\"), para_svc, cv=2, scoring=\"accuracy\",n_jobs=-1, verbose=1) \n",
    "grid_svm.fit(X_train2, np.array(y_train2))\n",
    "best = grid_svm.best_params_\n",
    "best1 = grid_svm.best_score_\n",
    "print(grid_svm.score(X_test2, np.array(y_test2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastely, the SVM function was conducted. The best val accuracy is around 0.75. Thus, combine with two RNN related models, we'll estimate the noncomplaint with all five models and only the text with all positive outcome we'll category it as noncomplaint sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we finished the model training, we can see that for most of models, they would have around 70% accuracy only. Thus, we may want to emsemble the model together to predict whether the sentence was the complaint or not. Here we only pick up the sentence which all five models predict it as noncomplaint and then randomly pick up 500 positive and 500 negative to have quick glance about the prediction power of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"customertweets.csv\",header=None)\n",
    "test.columns = [\"index\",\"text\"]\n",
    "test =test.loc[[len(re.sub(\"[^@]\",'',x))<2 for x in test[\"text\"]]]\n",
    "tet = clean(test[\"text\"])\n",
    "sequences = tokenizer.texts_to_sequences(tet)\n",
    "XXX = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "test1 = doc2vec(tet,wordlist)\n",
    "x = grid.predict(test1)\n",
    "x1 = best_Log_l2_model.predict(test1)\n",
    "x2 = grid_svm.predict(test1)\n",
    "x3 =np.around(model1.predict(XXX),decimals=0).argmax(axis=1)\n",
    "x4 = np.around(model2.predict(XXX),decimals=0).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = x ==1\n",
    "b = x1==1\n",
    "c = x2==1\n",
    "#d = x3==1\n",
    "#e = x4==1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s = [x for x in a if (x in b and x in c and x in d and x in e)]\n",
    "#l = [ x for x in test[\"index\"] if x in s ]\n",
    "\n",
    "#d = test.loc[[x in  l for x in test[\"index\"]]]\n",
    "#pp= []\n",
    "#sia = SentimentIntensityAnalyzer()\n",
    "#sentences = d[\"text\"].tolist()\n",
    "#for sentence in sentences:\n",
    "#    ss = sia.polarity_scores(sentence)\n",
    "#    pp.append(ss[\"compound\"])\n",
    "#dd = pd.concat([d.reset_index(drop = True), pd.DataFrame(pp,columns=[\"rate\"])],axis=1)\n",
    "#df_final =dd.sort_values(\"rate\", ascending=False)\n",
    "#df_final.to_csv(\"temp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the text in predicted positive and negative with the rule based model score, some issues could be identified. Firstly, the false positive rate is around 50% from the sample. For false negative, it's only around 20%. Meanwhile, the rule based score might be a great indicater while the number is small enough. For instance, in our sample, the score under -7 would always be false positive category. Thus, we may consider setting up threshold using rule based model and then reduce those have higher probability to be complaint text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meanwhile, as more data were labeled during the process, we tried to imporve our models by including more training data set.However, after running the models, only rnn related models shown improvement on the original val accuracy( since we afraid the new data might be labeled in different standard, the original validation set were used rather than regenerate the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"Positive.csv\")\n",
    "df2.columns = [\"text\",\"sentiment\",\"rate\"]\n",
    "df1 = pd.read_csv(\"Negative.csv\")\n",
    "df1.columns = [\"text\",\"sentiment\",\"rate\"]\n",
    "data2 = pd.concat([df2[[\"text\",\"sentiment\"]].reset_index(drop=True),df1[[\"text\",\"sentiment\"]].reset_index(drop=True)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = clean(data2[\"text\"].tolist())\n",
    "\n",
    "max_words = 10000\n",
    "max_len = 30\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(words)\n",
    "sequences = tokenizer.texts_to_sequences(words2)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "y = data2[\"sentiment\"]\n",
    "X_train_f, X_test, y_train_f, y_test = train_test_split(tweets, y, test_size=0.2, random_state=23)\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(words)\n",
    "ts = pad_sequences(sequences, maxlen=max_len)\n",
    "y_2 = data[\"sentiment\"]\n",
    "X_train_s, X_test,y_train_s, y_test = train_test_split(ts, y_2, test_size=0.2, random_state=23)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(pd.concat([pd.DataFrame(X_train_f),pd.DataFrame(X_train_s)]))\n",
    "y_train = pd.concat([pd.DataFrame(y_train_f),pd.DataFrame(y_train_s)])\n",
    "y_train= to_categorical(y_train, 2)\n",
    "y_test= to_categorical(y_test, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "73/76 [===========================>..] - ETA: 0s - loss: 0.7085 - accuracy: 0.4474WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F0ED79C280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "76/76 [==============================] - 4s 15ms/step - loss: 0.7081 - accuracy: 0.4491 - val_loss: 0.6973 - val_accuracy: 0.4650\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.46500, saving model to best_model1.hdf5\n",
      "Epoch 2/70\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.6858 - accuracy: 0.5728 - val_loss: 0.6923 - val_accuracy: 0.4650\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.46500\n",
      "Epoch 3/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.6745 - accuracy: 0.5563 - val_loss: 0.6773 - val_accuracy: 0.4650\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.46500\n",
      "Epoch 4/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.6510 - accuracy: 0.5722 - val_loss: 0.6654 - val_accuracy: 0.5575\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.46500 to 0.55750, saving model to best_model1.hdf5\n",
      "Epoch 5/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.6320 - accuracy: 0.7246 - val_loss: 0.6428 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.55750 to 0.69000, saving model to best_model1.hdf5\n",
      "Epoch 6/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.5991 - accuracy: 0.8194 - val_loss: 0.6218 - val_accuracy: 0.7375\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.69000 to 0.73750, saving model to best_model1.hdf5\n",
      "Epoch 7/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.5583 - accuracy: 0.8433 - val_loss: 0.6169 - val_accuracy: 0.7075\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73750\n",
      "Epoch 8/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.5168 - accuracy: 0.8597 - val_loss: 0.5728 - val_accuracy: 0.7425\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.73750 to 0.74250, saving model to best_model1.hdf5\n",
      "Epoch 9/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.4623 - accuracy: 0.8813 - val_loss: 0.5914 - val_accuracy: 0.7125\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74250\n",
      "Epoch 10/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.4169 - accuracy: 0.8944 - val_loss: 0.6037 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74250\n",
      "Epoch 11/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.3816 - accuracy: 0.9006 - val_loss: 0.5447 - val_accuracy: 0.7375\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74250\n",
      "Epoch 12/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.3382 - accuracy: 0.9142 - val_loss: 0.5696 - val_accuracy: 0.7425\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74250\n",
      "Epoch 13/70\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.3021 - accuracy: 0.9218 - val_loss: 0.6375 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74250\n",
      "Epoch 14/70\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.2809 - accuracy: 0.9245 - val_loss: 0.5595 - val_accuracy: 0.7475\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.74250 to 0.74750, saving model to best_model1.hdf5\n",
      "Epoch 15/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.2708 - accuracy: 0.9259 - val_loss: 0.5983 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74750\n",
      "Epoch 16/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.2354 - accuracy: 0.9370 - val_loss: 0.6007 - val_accuracy: 0.7250\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74750\n",
      "Epoch 17/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.2165 - accuracy: 0.9419 - val_loss: 0.6361 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74750\n",
      "Epoch 18/70\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.2295 - accuracy: 0.9330 - val_loss: 0.6485 - val_accuracy: 0.7150\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74750\n",
      "Epoch 19/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.2074 - accuracy: 0.9416 - val_loss: 0.6812 - val_accuracy: 0.7200\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74750\n",
      "Epoch 20/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.1852 - accuracy: 0.9497 - val_loss: 0.6923 - val_accuracy: 0.7125\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74750\n",
      "Epoch 21/70\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.1842 - accuracy: 0.9486 - val_loss: 0.7297 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74750\n",
      "Epoch 22/70\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.1698 - accuracy: 0.9521 - val_loss: 0.7628 - val_accuracy: 0.6925\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74750\n",
      "Epoch 23/70\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.1629 - accuracy: 0.9553 - val_loss: 0.7842 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74750\n",
      "Epoch 24/70\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.1598 - accuracy: 0.9535 - val_loss: 0.7772 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74750\n",
      "Epoch 25/70\n",
      "76/76 [==============================] - 1s 8ms/step - loss: 0.1355 - accuracy: 0.9624 - val_loss: 0.8094 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74750\n",
      "Epoch 26/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.1322 - accuracy: 0.9664 - val_loss: 0.8063 - val_accuracy: 0.6925\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74750\n",
      "Epoch 27/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.1125 - accuracy: 0.9723 - val_loss: 0.8014 - val_accuracy: 0.6825\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74750\n",
      "Epoch 28/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.1187 - accuracy: 0.9698 - val_loss: 0.8286 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74750\n",
      "Epoch 29/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.1183 - accuracy: 0.9645 - val_loss: 0.8263 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74750\n",
      "Epoch 30/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.1014 - accuracy: 0.9712 - val_loss: 0.9139 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74750\n",
      "Epoch 31/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.1039 - accuracy: 0.9716 - val_loss: 0.8971 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74750\n",
      "Epoch 32/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.1104 - accuracy: 0.9741 - val_loss: 0.8987 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74750\n",
      "Epoch 33/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0851 - accuracy: 0.9772 - val_loss: 0.9653 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74750\n",
      "Epoch 34/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0949 - accuracy: 0.9744 - val_loss: 0.9218 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74750\n",
      "Epoch 35/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0783 - accuracy: 0.9797 - val_loss: 0.9465 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74750\n",
      "Epoch 36/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0822 - accuracy: 0.9787 - val_loss: 0.9848 - val_accuracy: 0.6800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74750\n",
      "Epoch 37/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0848 - accuracy: 0.9729 - val_loss: 0.9822 - val_accuracy: 0.6875\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74750\n",
      "Epoch 38/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0762 - accuracy: 0.9810 - val_loss: 1.0282 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74750\n",
      "Epoch 39/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0680 - accuracy: 0.9821 - val_loss: 1.0152 - val_accuracy: 0.6825\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74750\n",
      "Epoch 40/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0733 - accuracy: 0.9809 - val_loss: 1.0140 - val_accuracy: 0.6825\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74750\n",
      "Epoch 41/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0671 - accuracy: 0.9849 - val_loss: 1.0232 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74750\n",
      "Epoch 42/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0661 - accuracy: 0.9824 - val_loss: 1.0645 - val_accuracy: 0.6825\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74750\n",
      "Epoch 43/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0686 - accuracy: 0.9830 - val_loss: 1.1301 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74750\n",
      "Epoch 44/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0559 - accuracy: 0.9859 - val_loss: 1.0737 - val_accuracy: 0.6925\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74750\n",
      "Epoch 45/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0581 - accuracy: 0.9819 - val_loss: 1.0583 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74750\n",
      "Epoch 46/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0460 - accuracy: 0.9875 - val_loss: 1.0937 - val_accuracy: 0.7025\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74750\n",
      "Epoch 47/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0539 - accuracy: 0.9862 - val_loss: 1.0999 - val_accuracy: 0.6925\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74750\n",
      "Epoch 48/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0524 - accuracy: 0.9846 - val_loss: 1.1309 - val_accuracy: 0.6925\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74750\n",
      "Epoch 49/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0455 - accuracy: 0.9896 - val_loss: 1.1322 - val_accuracy: 0.6875\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74750\n",
      "Epoch 50/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0482 - accuracy: 0.9883 - val_loss: 1.1606 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74750\n",
      "Epoch 51/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0550 - accuracy: 0.9828 - val_loss: 1.1854 - val_accuracy: 0.6875\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.74750\n",
      "Epoch 52/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0460 - accuracy: 0.9866 - val_loss: 1.2011 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.74750\n",
      "Epoch 53/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0407 - accuracy: 0.9867 - val_loss: 1.1818 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.74750\n",
      "Epoch 54/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0369 - accuracy: 0.9899 - val_loss: 1.3201 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.74750\n",
      "Epoch 55/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0498 - accuracy: 0.9888 - val_loss: 1.2207 - val_accuracy: 0.6925\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.74750\n",
      "Epoch 56/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0505 - accuracy: 0.9876 - val_loss: 1.1977 - val_accuracy: 0.6825\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.74750\n",
      "Epoch 57/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0516 - accuracy: 0.9867 - val_loss: 1.2480 - val_accuracy: 0.6825\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.74750\n",
      "Epoch 58/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0335 - accuracy: 0.9920 - val_loss: 1.2435 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.74750\n",
      "Epoch 59/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0389 - accuracy: 0.9906 - val_loss: 1.2326 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.74750\n",
      "Epoch 60/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0395 - accuracy: 0.9867 - val_loss: 1.3018 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.74750\n",
      "Epoch 61/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0404 - accuracy: 0.9891 - val_loss: 1.2671 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.74750\n",
      "Epoch 62/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0475 - accuracy: 0.9886 - val_loss: 1.2755 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.74750\n",
      "Epoch 63/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0540 - accuracy: 0.9865 - val_loss: 1.2566 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.74750\n",
      "Epoch 64/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0374 - accuracy: 0.9896 - val_loss: 1.2469 - val_accuracy: 0.6875\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.74750\n",
      "Epoch 65/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0358 - accuracy: 0.9910 - val_loss: 1.3170 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.74750\n",
      "Epoch 66/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0286 - accuracy: 0.9920 - val_loss: 1.2613 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.74750\n",
      "Epoch 67/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0331 - accuracy: 0.9911 - val_loss: 1.3495 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.74750\n",
      "Epoch 68/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0291 - accuracy: 0.9938 - val_loss: 1.3082 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.74750\n",
      "Epoch 69/70\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0280 - accuracy: 0.9928 - val_loss: 1.3256 - val_accuracy: 0.6975\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.74750\n",
      "Epoch 70/70\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0432 - accuracy: 0.9904 - val_loss: 1.3391 - val_accuracy: 0.6875\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.74750\n"
     ]
    }
   ],
   "source": [
    "model1n = Sequential()\n",
    "model1n.add(layers.Embedding(max_words, 25)) #The embedding layer\n",
    "model1n.add(layers.LSTM(20,dropout=0.5)) #Our LSTM layer\n",
    "model1n.add(layers.Dense(10,activation='softmax'))\n",
    "model1n.add(layers.Dense(5,activation='softmax'))\n",
    "model1n.add(layers.Dense(2,activation='softmax'))\n",
    "model1n.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model1n.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "76/76 [==============================] - 5s 22ms/step - loss: 0.6859 - accuracy: 0.5323 - val_loss: 0.6763 - val_accuracy: 0.4875\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.48750, saving model to best_model2.hdf5\n",
      "Epoch 2/70\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.5830 - accuracy: 0.6533 - val_loss: 0.5290 - val_accuracy: 0.7525\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.48750 to 0.75250, saving model to best_model2.hdf5\n",
      "Epoch 3/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.4186 - accuracy: 0.8064 - val_loss: 0.5353 - val_accuracy: 0.7575\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.75250 to 0.75750, saving model to best_model2.hdf5\n",
      "Epoch 4/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.3248 - accuracy: 0.8628 - val_loss: 0.5588 - val_accuracy: 0.7025\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75750\n",
      "Epoch 5/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2776 - accuracy: 0.8853 - val_loss: 0.5918 - val_accuracy: 0.7100\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75750\n",
      "Epoch 6/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2260 - accuracy: 0.9069 - val_loss: 0.6020 - val_accuracy: 0.7475\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75750\n",
      "Epoch 7/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.1952 - accuracy: 0.9211 - val_loss: 0.6650 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75750\n",
      "Epoch 8/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.2037 - accuracy: 0.9205 - val_loss: 0.7643 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75750\n",
      "Epoch 9/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.1828 - accuracy: 0.9362 - val_loss: 0.7374 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75750\n",
      "Epoch 10/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.1613 - accuracy: 0.9338 - val_loss: 0.7788 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75750\n",
      "Epoch 11/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.1414 - accuracy: 0.9475 - val_loss: 0.9329 - val_accuracy: 0.6825\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75750\n",
      "Epoch 12/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.1329 - accuracy: 0.9550 - val_loss: 0.7695 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75750\n",
      "Epoch 13/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.1060 - accuracy: 0.9587 - val_loss: 0.9070 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75750\n",
      "Epoch 14/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0944 - accuracy: 0.9711 - val_loss: 0.8768 - val_accuracy: 0.6950\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75750\n",
      "Epoch 15/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0784 - accuracy: 0.9750 - val_loss: 0.8054 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75750\n",
      "Epoch 16/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0853 - accuracy: 0.9707 - val_loss: 0.9872 - val_accuracy: 0.7100\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75750\n",
      "Epoch 17/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0860 - accuracy: 0.9720 - val_loss: 0.9753 - val_accuracy: 0.6950\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75750\n",
      "Epoch 18/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0717 - accuracy: 0.9788 - val_loss: 1.1339 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75750\n",
      "Epoch 19/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0767 - accuracy: 0.9722 - val_loss: 1.0983 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75750\n",
      "Epoch 20/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0714 - accuracy: 0.9756 - val_loss: 1.0596 - val_accuracy: 0.6925\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75750\n",
      "Epoch 21/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0586 - accuracy: 0.9794 - val_loss: 1.1240 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75750\n",
      "Epoch 22/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0469 - accuracy: 0.9867 - val_loss: 1.0425 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75750\n",
      "Epoch 23/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0463 - accuracy: 0.9842 - val_loss: 1.4092 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75750\n",
      "Epoch 24/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0425 - accuracy: 0.9848 - val_loss: 1.1730 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75750\n",
      "Epoch 25/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0397 - accuracy: 0.9851 - val_loss: 1.1471 - val_accuracy: 0.6825\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75750\n",
      "Epoch 26/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0363 - accuracy: 0.9894 - val_loss: 1.2318 - val_accuracy: 0.6950\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75750\n",
      "Epoch 27/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0417 - accuracy: 0.9860 - val_loss: 1.5658 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75750\n",
      "Epoch 28/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0296 - accuracy: 0.9892 - val_loss: 1.2233 - val_accuracy: 0.6925\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75750\n",
      "Epoch 29/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0219 - accuracy: 0.9911 - val_loss: 1.3389 - val_accuracy: 0.6925\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75750\n",
      "Epoch 30/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0205 - accuracy: 0.9913 - val_loss: 1.6446 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75750\n",
      "Epoch 31/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0172 - accuracy: 0.9936 - val_loss: 1.4943 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75750\n",
      "Epoch 32/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0198 - accuracy: 0.9943 - val_loss: 1.5289 - val_accuracy: 0.6875\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75750\n",
      "Epoch 33/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0177 - accuracy: 0.9939 - val_loss: 1.5365 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75750\n",
      "Epoch 34/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0109 - accuracy: 0.9949 - val_loss: 1.4773 - val_accuracy: 0.7075\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75750\n",
      "Epoch 35/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 1.6231 - val_accuracy: 0.6950\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75750\n",
      "Epoch 36/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0084 - accuracy: 0.9972 - val_loss: 1.6163 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75750\n",
      "Epoch 37/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 1.8239 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75750\n",
      "Epoch 38/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0170 - accuracy: 0.9957 - val_loss: 1.7983 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75750\n",
      "Epoch 39/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0119 - accuracy: 0.9963 - val_loss: 2.1095 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75750\n",
      "Epoch 40/70\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.0095 - accuracy: 0.9964 - val_loss: 1.8809 - val_accuracy: 0.6675\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75750\n",
      "Epoch 41/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0101 - accuracy: 0.9966 - val_loss: 1.6749 - val_accuracy: 0.6575\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75750\n",
      "Epoch 42/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0102 - accuracy: 0.9962 - val_loss: 1.7784 - val_accuracy: 0.6525\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75750\n",
      "Epoch 43/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0075 - accuracy: 0.9961 - val_loss: 1.9487 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75750\n",
      "Epoch 44/70\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 1.8892 - val_accuracy: 0.6625\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75750\n",
      "Epoch 45/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 1.8775 - val_accuracy: 0.6850\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75750\n",
      "Epoch 46/70\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.0097 - accuracy: 0.9964 - val_loss: 1.9780 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75750\n",
      "Epoch 47/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0059 - accuracy: 0.9971 - val_loss: 2.1099 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75750\n",
      "Epoch 48/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 2.0061 - val_accuracy: 0.6950\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75750\n",
      "Epoch 49/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 1.9303 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75750\n",
      "Epoch 50/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0065 - accuracy: 0.9978 - val_loss: 1.9530 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75750\n",
      "Epoch 51/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 2.4185 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.75750\n",
      "Epoch 52/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0050 - accuracy: 0.9989 - val_loss: 2.1653 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.75750\n",
      "Epoch 53/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 2.0351 - val_accuracy: 0.6725\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.75750\n",
      "Epoch 54/70\n",
      "76/76 [==============================] - 1s 18ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 2.2218 - val_accuracy: 0.6925\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.75750\n",
      "Epoch 55/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0039 - accuracy: 0.9979 - val_loss: 2.2536 - val_accuracy: 0.6925\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.75750\n",
      "Epoch 56/70\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.0048 - accuracy: 0.9982 - val_loss: 2.1105 - val_accuracy: 0.6800\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.75750\n",
      "Epoch 57/70\n",
      "76/76 [==============================] - 1s 15ms/step - loss: 0.0038 - accuracy: 0.9984 - val_loss: 2.0099 - val_accuracy: 0.6900\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.75750\n",
      "Epoch 58/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 2.2326 - val_accuracy: 0.6750\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.75750\n",
      "Epoch 59/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 2.3466 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.75750\n",
      "Epoch 60/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 2.2626 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.75750\n",
      "Epoch 61/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 5.9184e-04 - accuracy: 0.9999 - val_loss: 2.6968 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.75750\n",
      "Epoch 62/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0052 - accuracy: 0.9980 - val_loss: 2.3181 - val_accuracy: 0.6825\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.75750\n",
      "Epoch 63/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0021 - accuracy: 0.9989 - val_loss: 2.3309 - val_accuracy: 0.6825\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.75750\n",
      "Epoch 64/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0030 - accuracy: 0.9977 - val_loss: 2.6548 - val_accuracy: 0.6625\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.75750\n",
      "Epoch 65/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0069 - accuracy: 0.9985 - val_loss: 2.5239 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.75750\n",
      "Epoch 66/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 2.4175 - val_accuracy: 0.6600\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.75750\n",
      "Epoch 67/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 2.8381 - val_accuracy: 0.6625\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.75750\n",
      "Epoch 68/70\n",
      "76/76 [==============================] - 1s 13ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 2.5845 - val_accuracy: 0.6825\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.75750\n",
      "Epoch 69/70\n",
      "76/76 [==============================] - 1s 14ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 2.5140 - val_accuracy: 0.6775\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.75750\n",
      "Epoch 70/70\n",
      "76/76 [==============================] - 1s 12ms/step - loss: 0.0025 - accuracy: 0.9989 - val_loss: 2.5701 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.75750\n"
     ]
    }
   ],
   "source": [
    "model2n = Sequential()\n",
    "model2n.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "model2n.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
    "model2n.add(layers.Dense(2,activation='softmax'))\n",
    "model2n.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model2n.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6875"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.around(model1n.predict(X_test),decimals=0).argmax(axis=1)\n",
    "accuracy_score(X,y_test.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.around(model2n.predict(X_test),decimals=0).argmax(axis=1)\n",
    "accuracy_score(X,y_test.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see roughly 0.02 improvement on val accuracy. THis may also indicate that the model still has large potential to improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying different threshold in our training dataset, we decided to use -0.5 as thershold for rule based model. If we observe that the score is below -0.5 then we classfy it as complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = clean(data[\"text\"].iloc[:1000,])\n",
    "pp= []\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "for sentence in sentences:\n",
    "    ss = sia.polarity_scores(sentence)\n",
    "    pp.append(ss[\"compound\"])\n",
    "len([x for x in  pp if x>-0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "score= []\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "for sentence in tet:\n",
    "    ss = sia.polarity_scores(sentence)\n",
    "    score.append(ss[\"compound\"])\n",
    "raw = pd.DataFrame([tet,score],index= [\"text\",'score']).T\n",
    "tet =raw[\"text\"].loc[raw[\"score\"]>-0.5]\n",
    "\n",
    "#sequences = tokenizer.texts_to_sequences(tet)\n",
    "#XXX = pad_sequences(sequences, maxlen=max_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After getting the update models and the test set, we can predict our final noncomplaint dataset. Different from last time, we would predict the noncomplaint text if the majority models suggest that the text is noncomplaint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 =np.around(model1n.predict(XXX),decimals=0).argmax(axis=1)\n",
    "x4 = np.around(model2n.predict(XXX),decimals=0).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = x3==1\n",
    "e = x4==1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "final =np.array(pd.concat([pd.DataFrame(a),pd.DataFrame(b),pd.DataFrame(c),pd.DataFrame(d),pd.DataFrame(e)],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 5, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra = data2[\"text\"].loc[data2[\"sentiment\"]==1]\n",
    "final_df = test.loc[final.sum(1)>2]\n",
    "final2=test.loc[[x in extra.to_list() for x in test[\"text\"].tolist()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =pd.concat([final_df,final2])\n",
    "final_df =final_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"project.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"project.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp= []\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "sentences = df[\"text\"].tolist()\n",
    "for sentence in sentences:\n",
    "    ss = sia.polarity_scores(sentence)\n",
    "    pp.append(ss[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = df[[\"index\",\"text\"]].loc[[x> -0.5 for x in pp]]\n",
    "output.to_csv(\"Wei_ChenLee.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
